{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "from performance_helper import get_performance_scores, get_finetuned_scores, compute_f1_scores_quad, compute_scores_single\n",
    "# from table_helper import create_tabular\n",
    "# from table_boldener import bolden_table_max_values_with_hline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import itertools\n",
    "# import shutil\n",
    "# import io, re\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEEDS = 5\n",
    "TASKS = [\"tasd\", \"asqp\"]\n",
    "DATASETS = [\"rest15\", \"rest16\", \"flightabsa\", \"hotels\", \"coursera\"]\n",
    "METHODS = [\"paraphrase\", \"dlo\"]\n",
    "AUG_TECHNIQUES = [\"eda\", \"llm_eda\", \"back_translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: previous scores\n",
    "# Todo: F1 * 100\n",
    "# Todo: class wise scores f√ºr alle berechnen\n",
    "# Paper dlo korrigieren sowohl tabelle als auch text\n",
    "# Todo: previous scores laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_element_scores(loaded_json, task):\n",
    "    labels = loaded_json[\"all_labels\"]\n",
    "    preds = loaded_json[\"all_preds\"]\n",
    "    seed_scores = compute_f1_scores_quad(preds, labels)\n",
    "    seed_scores_ac = compute_scores_single(preds, labels, \"single_ac\")\n",
    "    seed_scores_at = compute_scores_single(preds, labels, \"single_at\")\n",
    "    seed_scores_pol = compute_scores_single(preds, labels, \"single_pol\")\n",
    "\n",
    "    seed_scores[\"ac\"] = seed_scores_ac\n",
    "    seed_scores[\"at\"] = seed_scores_at\n",
    "    seed_scores[\"pol\"] = seed_scores_pol\n",
    "    if task == \"asqp\":\n",
    "        seed_scores_ot = compute_scores_single(preds, labels, \"single_ot\")\n",
    "        seed_scores[\"ot\"] = seed_scores_ot\n",
    "    return seed_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(scores):\n",
    "    averages = {}\n",
    "    for key in scores[0].keys():\n",
    "        if isinstance(scores[0][key], dict):  # Falls geschachtelte Dicts vorhanden sind\n",
    "            averages[key] = {subkey: np.mean([s[key][subkey] for s in scores]) for subkey in scores[0][key]}\n",
    "        else:\n",
    "            averages[key] = np.mean([s[key] for s in scores])\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load LLM-annotated fine-tuned scores\n",
    "scores_llm_ann_train = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for fs in [0, 10, 50]:\n",
    "                for n_ann_ex in [800, \"full\"]:\n",
    "\n",
    "                    scores = []\n",
    "                    for seed in range(N_SEEDS):\n",
    "                        with open(\n",
    "                            f\"../_out_fine_tunings/01_llm_annotate_train/{method}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                        ) as f:\n",
    "                            loaded_json = json.load(f)\n",
    "                            seed_scores = add_element_scores(loaded_json, task)\n",
    "                            scores.append(seed_scores)\n",
    "                    scores_llm_ann_train[\n",
    "                        f\"{method}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                    ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Augmented fine-tuned scores\n",
    "scores_traditional_aug = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for aug in AUG_TECHNIQUES:\n",
    "            for method in METHODS:\n",
    "                for fs in [10, 50]:\n",
    "                    for n_ann_ex in [1600, 800, \"full\"]:\n",
    "\n",
    "                        scores = []\n",
    "                        for seed in range(N_SEEDS):\n",
    "                            with open(\n",
    "                                f\"../_out_fine_tunings/03_traditional_augmentation/{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                            ) as f:\n",
    "                                loaded_json = json.load(f)\n",
    "                                seed_scores = add_element_scores(loaded_json, task)\n",
    "                                scores.append(seed_scores)\n",
    "                        scores_traditional_aug[\n",
    "                            f\"{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                        ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load Fine-tuned LLM scores\n",
    "scores_fine_tune_llm = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 50]:\n",
    "            for n_ann_ex in [800, \"full\"]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../_out_fine_tunings/02_fine_tune_llm/gemma-2-9b_{seed}_{task}_{fs}_{dataset}_{n_ann_ex}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "\n",
    "                        scores.append(seed_scores)\n",
    "                scores_fine_tune_llm[f\"gemma-2-9b_{task}_{fs}_{dataset}_{n_ann_ex}\"] = (\n",
    "                    calc_mean(scores)\n",
    "                )\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for n_ann_ex in [800, \"full\"]:\n",
    "            scores = []\n",
    "            for seed in range(N_SEEDS):\n",
    "                with open(\n",
    "                    f\"../_out_fine_tunings/02_fine_tune_llm/gemma-2-9b_{seed}_{task}_{dataset}_{n_ann_ex}.json\"\n",
    "                ) as f:\n",
    "                    loaded_json_raw = json.load(f)\n",
    "\n",
    "                    loaded_json = {\n",
    "                        \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                        \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                    }\n",
    "\n",
    "                    seed_scores = add_element_scores(loaded_json, task)\n",
    "\n",
    "                    scores.append(seed_scores)\n",
    "            scores_fine_tune_llm[f\"gemma-2-9b_{task}_{dataset}_{n_ann_ex}\"] = calc_mean(\n",
    "                scores\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load methods baselines\n",
    "scores_00_baseline = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for n_ann_ex in [10, 50, 800, \"full\"]:\n",
    "\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    if n_ann_ex == \"full\":\n",
    "                        file_path = f\"../_out_paper_1/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}.json\"\n",
    "                    else:\n",
    "                        file_path = f\"../_out_paper_1/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}_{n_ann_ex}.json\"\n",
    "                    with open(file_path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"] = calc_mean(\n",
    "                    scores\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 26.804586769359126,\n",
       " 'recall': 28.75471698113207,\n",
       " 'f1': 27.744852346748154,\n",
       " 'TP': 228.6,\n",
       " 'FP': 624.2,\n",
       " 'FN': 566.4,\n",
       " 'ac': {'precision': 59.23693621651279,\n",
       "  'recall': 60.000000000000014,\n",
       "  'f1': 59.614905449047896,\n",
       "  'TP': 418.8,\n",
       "  'FP': 288.2,\n",
       "  'FN': 279.2},\n",
       " 'at': {'precision': 57.02204743627701,\n",
       "  'recall': 77.23320158102766,\n",
       "  'f1': 65.60478414634807,\n",
       "  'TP': 390.8,\n",
       "  'FP': 294.6,\n",
       "  'FN': 115.2},\n",
       " 'pol': {'precision': 90.02188451093384,\n",
       "  'recall': 90.35897435897436,\n",
       "  'f1': 90.18913634650667,\n",
       "  'TP': 528.6,\n",
       "  'FP': 58.6,\n",
       "  'FN': 56.4},\n",
       " 'ot': {'precision': 60.45804514812634,\n",
       "  'recall': 64.73118279569891,\n",
       "  'f1': 62.52075821164622,\n",
       "  'TP': 481.6,\n",
       "  'FP': 315.0,\n",
       "  'FN': 262.4}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Load zero-shot scores\n",
    "scores_zeroshot = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 50]:\n",
    "            for n_ann_ex in [800, \"full\"]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../_out_paper_1/zeroshot/{task}_{dataset}_test_gemma2:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "\n",
    "                        scores.append(seed_scores)\n",
    "                scores_zeroshot[f\"{n_ann_ex}_{task}_{fs}_{dataset}\"] = (\n",
    "                    calc_mean(scores)\n",
    "                )\n",
    "                \n",
    "scores_zeroshot[\"full_asqp_0_rest15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
