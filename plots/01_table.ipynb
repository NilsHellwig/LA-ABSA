{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99b6dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Add paths for custom modules\n",
    "sys.path.append(os.path.abspath(\"../../zero-shot-absa-quad\"))\n",
    "sys.path.append(os.path.abspath(\"../../zero-shot-absa-quad/plots\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc8d51",
   "metadata": {},
   "source": [
    "* nur 5 bis 10 \n",
    "* gemma umstrukturieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dd97a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "from performance_helper import compute_f1_scores_quad, compute_scores_single, merge_aspect_lists\n",
    "from table_tool import round_numbers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import itertools\n",
    "# import shutil\n",
    "# import io, re\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb6d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEEDS = 5\n",
    "TASKS = [\"tasd\", \"asqp\"]\n",
    "DATASETS = [\"rest15\", \"rest16\", \"flightabsa\", \"coursera\", \"hotels\"]\n",
    "METHODS = [\"paraphrase\", \"dlo\"]\n",
    "AUG_TECHNIQUES = [\"eda\", \"qaie\"]\n",
    "\n",
    "raw_dataset_to_formatted = {\"rest16\": \"Rest16\", \"rest15\": \"Rest15\", \"flightabsa\": \"FlightABSA\", \"coursera\": \"OATS Coursera\", \"hotels\": \"OATS Hotels\"}\n",
    "format_dataset_to_raw = {\"Rest16\": \"rest16\", \"Rest15\": \"rest15\", \"FlightABSA\": \"flightabsa\", \"coursera\": \"OATS Coursera\", \"OATS Hotels\": \"hotels\"}\n",
    "raw_method_to_formatted = {\"paraphrase\": \"Paraphrase\", \"dlo\": \"DLO \\citep{hu2022improving}\"}\n",
    "format_method_to_raw = {\"Paraphrase\": \"paraphrase\", \"DLO \\citep{hu2022improving}\": \"dlo\"}\n",
    "raw_aug_to_formatted = {\"eda\": \"EDA\", \"QAIE\": \"QAIE\", \"llm_annotator\": \"LLM-Annotator\"}\n",
    "format_aug_to_raw = {\"EDA\": \"eda\", \"-\": \"-\", \"LLM-Annotator\": \"llm_annotator\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e504f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_ac_in_gold_label(labels):\n",
    "    unique_ac = set()\n",
    "    for label in labels:\n",
    "        for tuple in label:\n",
    "            unique_ac.add(tuple[0])\n",
    "    return list(unique_ac)\n",
    "\n",
    "def compute_f1_scores_quad(pred_pt, gold_pt):\n",
    "    \"\"\"\n",
    "    Function to compute F1 scores with pred and gold quads\n",
    "    The input needs to be already processed\n",
    "    \"\"\"\n",
    "    n_tp, n_fp, n_fn = 0, 0, 0\n",
    "    n_gold, n_pred = 0, 0\n",
    "\n",
    "    for i in range(len(pred_pt)):\n",
    "        n_gold += len(gold_pt[i])\n",
    "        n_pred += len(pred_pt[i])\n",
    "\n",
    "        # Compute True Positives and False Positives\n",
    "        for t in pred_pt[i]:\n",
    "            if t in gold_pt[i]:\n",
    "                n_tp += 1\n",
    "            else:\n",
    "                n_fp += 1\n",
    "\n",
    "        # Compute False Negatives\n",
    "        for t in gold_pt[i]:\n",
    "            if t not in pred_pt[i]:\n",
    "                n_fn += 1\n",
    "\n",
    "    precision = float(n_tp) / float(n_pred) if n_pred != 0 else 0\n",
    "    recall = float(n_tp) / float(n_gold) if n_gold != 0 else 0\n",
    "    f1 = 2 * precision * recall / \\\n",
    "        (precision + recall) if precision != 0 or recall != 0 else 0\n",
    "\n",
    "    scores = {\n",
    "        'precision': precision * 100,\n",
    "        'recall': recall * 100,\n",
    "        'f1': f1 * 100,\n",
    "        'TP': n_tp,\n",
    "        'FP': n_fp,\n",
    "        'FN': n_fn\n",
    "    }\n",
    "\n",
    "    return scores\n",
    "\n",
    "def calc_f1_macro(labels, preds, unique_ac):\n",
    "    \"\"\"\n",
    "    Calculate macro F1 score by computing F1 for each aspect category \n",
    "    and then taking the mean of all F1 scores.\n",
    "    \n",
    "    Args:\n",
    "        labels: Ground truth labels (list of lists of tuples)\n",
    "        preds: Predicted labels (list of lists of tuples) \n",
    "        unique_ac: List of unique aspect categories\n",
    "        \n",
    "    Returns:\n",
    "        float: Macro F1 score\n",
    "    \"\"\"\n",
    "    f1_scores = []\n",
    "    \n",
    "    for ac in unique_ac:\n",
    "        # Filter predictions and labels for current aspect category\n",
    "        pred_ac = []\n",
    "        label_ac = []\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            # Get predictions and labels for this sample\n",
    "            pred_tuples = preds[i] if i < len(preds) else []\n",
    "            label_tuples = labels[i]\n",
    "            \n",
    "            # Filter tuples for current aspect category\n",
    "            pred_ac_tuples = [t for t in pred_tuples if len(t) > 0 and t[0] == ac]\n",
    "            label_ac_tuples = [t for t in label_tuples if len(t) > 0 and t[0] == ac]\n",
    "            \n",
    "            pred_ac.append(pred_ac_tuples)\n",
    "            label_ac.append(label_ac_tuples)\n",
    "        \n",
    "        # Calculate F1 for this category using the provided function\n",
    "        scores = compute_f1_scores_quad(pred_ac, label_ac)\n",
    "        f1_scores.append(scores['f1'] / 100.0)  # Convert back from percentage\n",
    "    \n",
    "    # Return macro F1 (mean of all category F1 scores)\n",
    "    return sum(f1_scores) / len(f1_scores) if f1_scores else 0.0\n",
    "\n",
    "def add_element_scores(loaded_json, task):\n",
    "    labels = loaded_json[\"all_labels\"]\n",
    "    preds = loaded_json[\"all_preds\"]\n",
    "    seed_scores = compute_f1_scores_quad(preds, labels)\n",
    "    seed_scores_ac = compute_scores_single(preds, labels, \"single_ac\")\n",
    "    seed_scores_at = compute_scores_single(preds, labels, \"single_at\")\n",
    "    seed_scores_pol = compute_scores_single(preds, labels, \"single_pol\")\n",
    "    \n",
    "    unique_ac = unique_ac_in_gold_label(labels)\n",
    "    \n",
    "    seed_scores[\"f1_macro\"] = calc_f1_macro(labels, preds, unique_ac) * 100\n",
    "\n",
    "    seed_scores[\"ac\"] = seed_scores_ac\n",
    "    seed_scores[\"at\"] = seed_scores_at\n",
    "    seed_scores[\"pol\"] = seed_scores_pol\n",
    "    if task == \"asqp\":\n",
    "        seed_scores_ot = compute_scores_single(preds, labels, \"single_ot\")\n",
    "        seed_scores[\"ot\"] = seed_scores_ot\n",
    "    return seed_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e108dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(scores):\n",
    "    averages = {}\n",
    "    for key in scores[0].keys():\n",
    "        if isinstance(scores[0][key], dict):  # Falls geschachtelte Dicts vorhanden sind\n",
    "            averages[key] = {subkey: np.mean([s[key][subkey] for s in scores]) for subkey in scores[0][key]}\n",
    "        else:\n",
    "            averages[key] = np.mean([s[key] for s in scores])\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d542179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load LLM-annotated fine-tuned scores\n",
    "scores_llm_ann_train = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for fs in [0, 10, 50]:\n",
    "                for n_ann_ex in [\"full\"]:\n",
    "\n",
    "                    scores = []\n",
    "                    for seed in range(N_SEEDS):\n",
    "                        with open(\n",
    "                            f\"../_out_fine_tunings/01_llm_annotate_train/{method}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                        ) as f:\n",
    "                            loaded_json = json.load(f)\n",
    "                            seed_scores = add_element_scores(loaded_json, task)\n",
    "                            scores.append(seed_scores)\n",
    "                    scores_llm_ann_train[\n",
    "                        f\"{method}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                    ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77662aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 26.91211139836734,\n",
       " 'recall': 28.544378698224854,\n",
       " 'f1': 27.703719388792543,\n",
       " 'TP': 241.2,\n",
       " 'FP': 655.2,\n",
       " 'FN': 608.6,\n",
       " 'f1_macro': 22.876679625196964,\n",
       " 'ac': {'precision': 48.07105488314508,\n",
       "  'recall': 75.01845018450186,\n",
       "  'f1': 58.5938370321256,\n",
       "  'TP': 406.6,\n",
       "  'FP': 439.4,\n",
       "  'FN': 135.4},\n",
       " 'at': {'precision': 50.926661452649896,\n",
       "  'recall': 51.12258064516129,\n",
       "  'f1': 51.02419610573001,\n",
       "  'TP': 396.2,\n",
       "  'FP': 381.8,\n",
       "  'FN': 378.8},\n",
       " 'pol': {'precision': 86.40148234738679,\n",
       "  'recall': 86.3467492260062,\n",
       "  'f1': 86.37388737460738,\n",
       "  'TP': 557.8,\n",
       "  'FP': 87.8,\n",
       "  'FN': 88.2}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_llm_ann_train[\"paraphrase_full_tasd_0_rest15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d08fc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paraphrase_full_tasd_0_rest15', 'paraphrase_full_tasd_10_rest15', 'paraphrase_full_tasd_50_rest15', 'dlo_full_tasd_0_rest15', 'dlo_full_tasd_10_rest15', 'dlo_full_tasd_50_rest15', 'paraphrase_full_asqp_0_rest15', 'paraphrase_full_asqp_10_rest15', 'paraphrase_full_asqp_50_rest15', 'dlo_full_asqp_0_rest15', 'dlo_full_asqp_10_rest15', 'dlo_full_asqp_50_rest15', 'paraphrase_full_tasd_0_rest16', 'paraphrase_full_tasd_10_rest16', 'paraphrase_full_tasd_50_rest16', 'dlo_full_tasd_0_rest16', 'dlo_full_tasd_10_rest16', 'dlo_full_tasd_50_rest16', 'paraphrase_full_asqp_0_rest16', 'paraphrase_full_asqp_10_rest16', 'paraphrase_full_asqp_50_rest16', 'dlo_full_asqp_0_rest16', 'dlo_full_asqp_10_rest16', 'dlo_full_asqp_50_rest16', 'paraphrase_full_tasd_0_flightabsa', 'paraphrase_full_tasd_10_flightabsa', 'paraphrase_full_tasd_50_flightabsa', 'dlo_full_tasd_0_flightabsa', 'dlo_full_tasd_10_flightabsa', 'dlo_full_tasd_50_flightabsa', 'paraphrase_full_asqp_0_flightabsa', 'paraphrase_full_asqp_10_flightabsa', 'paraphrase_full_asqp_50_flightabsa', 'dlo_full_asqp_0_flightabsa', 'dlo_full_asqp_10_flightabsa', 'dlo_full_asqp_50_flightabsa', 'paraphrase_full_tasd_0_coursera', 'paraphrase_full_tasd_10_coursera', 'paraphrase_full_tasd_50_coursera', 'dlo_full_tasd_0_coursera', 'dlo_full_tasd_10_coursera', 'dlo_full_tasd_50_coursera', 'paraphrase_full_asqp_0_coursera', 'paraphrase_full_asqp_10_coursera', 'paraphrase_full_asqp_50_coursera', 'dlo_full_asqp_0_coursera', 'dlo_full_asqp_10_coursera', 'dlo_full_asqp_50_coursera', 'paraphrase_full_tasd_0_hotels', 'paraphrase_full_tasd_10_hotels', 'paraphrase_full_tasd_50_hotels', 'dlo_full_tasd_0_hotels', 'dlo_full_tasd_10_hotels', 'dlo_full_tasd_50_hotels', 'paraphrase_full_asqp_0_hotels', 'paraphrase_full_asqp_10_hotels', 'paraphrase_full_asqp_50_hotels', 'dlo_full_asqp_0_hotels', 'dlo_full_asqp_10_hotels', 'dlo_full_asqp_50_hotels'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_llm_ann_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3b699c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAIE\n",
    "scores_traditional_aug = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [10, 50]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    path = f\"../../QAIE-ABSA-2025-adaption/03_results/{task}_{dataset}_fs_{fs}_{seed}.json\"\n",
    "\n",
    "                    with open(path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_traditional_aug[\n",
    "                    f\"qaie_{task}_{fs}_{dataset}\"\n",
    "                ] = calc_mean(scores)\n",
    "                \n",
    "# DS2\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [10, 50]:\n",
    "            scores = []\n",
    "            for seed in range(5):\n",
    "                path = f\"../../SelfGen-ABSA/generations/trainings/paraphrase/{dataset}/fs_{fs}/{task}/training_{seed}.json\"\n",
    "                with open(path, \"r\") as f:\n",
    "                    loaded_json = json.load(f)\n",
    "                    seed_scores = add_element_scores(loaded_json, task)\n",
    "                    scores.append(seed_scores)\n",
    "            scores_llm_ann_train[\n",
    "                f\"ds2_{task}_{fs}_{dataset}\"\n",
    "            ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2130bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for aug in [\"eda\"]:\n",
    "            for method in METHODS:\n",
    "                for fs in [10, 50]:\n",
    "                    for n_ann_ex in [2, 5, 10, 15]:\n",
    "                        scores = []\n",
    "                        for seed in range(N_SEEDS):\n",
    "                            path = f\"../_out_fine_tunings/03_traditional_augmentation/{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                            with open(\n",
    "                                path\n",
    "                            ) as f:\n",
    "                                loaded_json = json.load(f)\n",
    "                                seed_scores = add_element_scores(loaded_json, task)\n",
    "                                scores.append(seed_scores)\n",
    "                        scores_traditional_aug[\n",
    "                            f\"{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                        ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70bdcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load methods baselines\n",
    "scores_00_baseline = {}\n",
    "\n",
    "with open(\"../../zero-shot-absa-quad/plots/past_results.json\") as f:\n",
    "    past_results = json.load(f)\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for n_ann_ex in [10, 50, \"full\"]:\n",
    "\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    if n_ann_ex == \"full\":\n",
    "                        file_path = f\"../../zero-shot-absa-quad/generations/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}.json\"\n",
    "                    else:\n",
    "                        file_path = f\"../../zero-shot-absa-quad/generations/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}_{n_ann_ex}.json\"\n",
    "                    with open(file_path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_mean = calc_mean(scores)\n",
    "\n",
    "                scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"] = (\n",
    "                    scores_mean\n",
    "                )\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for n_ann_ex in [\"full\"]:\n",
    "                for metric in [\"f1\", \"precision\", \"recall\"]:\n",
    "                    try:\n",
    "                            scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"] = (past_results[task][method][dataset])\n",
    "                            scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"][\"f1_macro\"] = \"-\"\n",
    "                    except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acaf7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load zero-shot scores\n",
    "scores_zeroshot = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 20, 30, 40, 50]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../../zero-shot-absa-quad/generations/zeroshot/{task}_{dataset}_test_gemma3:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "\n",
    "                        scores.append(seed_scores)\n",
    "                scores_zeroshot[f\"{task}_{fs}_{dataset}\"] = calc_mean(scores)\n",
    "\n",
    "# WITH SELF-Consistency\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 20, 30, 40, 50]:\n",
    "                all_example_data = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../../zero-shot-absa-quad/generations/zeroshot/{task}_{dataset}_test_gemma3:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        all_example_data.append(loaded_json)\n",
    "\n",
    "                all_labels = all_example_data[0][\"all_labels\"]\n",
    "                all_preds = [[] for _ in range(len(all_labels))]\n",
    "                for seed in range(0, N_SEEDS):\n",
    "                    for idx in range(len(all_labels)):\n",
    "                        all_preds[idx].append(all_example_data[seed][\"all_preds\"][idx])\n",
    "                        if seed == N_SEEDS - 1:\n",
    "                            all_preds[idx] = merge_aspect_lists(all_preds[idx])\n",
    "                            all_preds[idx] = [list(p) for p in all_preds[idx]]\n",
    "\n",
    "                loaded_json = {\n",
    "                    \"all_preds\": all_preds,\n",
    "                    \"all_labels\": all_labels,\n",
    "                }\n",
    "\n",
    "                scores = add_element_scores(loaded_json, task)\n",
    "                scores_zeroshot[f\"{task}_{fs}_{dataset}_sc\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aca7989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_train_qaie(task=\"tasd\", dataset=\"rest16\", fs=2):\n",
    "    path = f\"../../QAIE-ABSA-2025-adaption/01_augmentations/fs_examples/{task}/{dataset}/fs_{fs}/aug.txt\"\n",
    "    # count number of lines in the file\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        n_train = len(lines)\n",
    "    return n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88fce981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_train_ds2(task=\"tasd\", dataset=\"rest16\", fs=2):\n",
    "    path = f\"../../SelfGen-ABSA/generations/trainings/paraphrase/{dataset}/fs_{fs}/{task}/training_0.json\"\n",
    "    # load json and get key n_train_samples\n",
    "    with open(path, \"r\") as f:\n",
    "        loaded_json = json.load(f)\n",
    "        n_train = loaded_json[\"n_train_samples\"]\n",
    "    return n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72668d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tasd_0_rest15', 'tasd_10_rest15', 'tasd_20_rest15', 'tasd_30_rest15', 'tasd_40_rest15', 'tasd_50_rest15', 'asqp_0_rest15', 'asqp_10_rest15', 'asqp_20_rest15', 'asqp_30_rest15', 'asqp_40_rest15', 'asqp_50_rest15', 'tasd_0_rest16', 'tasd_10_rest16', 'tasd_20_rest16', 'tasd_30_rest16', 'tasd_40_rest16', 'tasd_50_rest16', 'asqp_0_rest16', 'asqp_10_rest16', 'asqp_20_rest16', 'asqp_30_rest16', 'asqp_40_rest16', 'asqp_50_rest16', 'tasd_0_flightabsa', 'tasd_10_flightabsa', 'tasd_20_flightabsa', 'tasd_30_flightabsa', 'tasd_40_flightabsa', 'tasd_50_flightabsa', 'asqp_0_flightabsa', 'asqp_10_flightabsa', 'asqp_20_flightabsa', 'asqp_30_flightabsa', 'asqp_40_flightabsa', 'asqp_50_flightabsa', 'tasd_0_coursera', 'tasd_10_coursera', 'tasd_20_coursera', 'tasd_30_coursera', 'tasd_40_coursera', 'tasd_50_coursera', 'asqp_0_coursera', 'asqp_10_coursera', 'asqp_20_coursera', 'asqp_30_coursera', 'asqp_40_coursera', 'asqp_50_coursera', 'tasd_0_hotels', 'tasd_10_hotels', 'tasd_20_hotels', 'tasd_30_hotels', 'tasd_40_hotels', 'tasd_50_hotels', 'asqp_0_hotels', 'asqp_10_hotels', 'asqp_20_hotels', 'asqp_30_hotels', 'asqp_40_hotels', 'asqp_50_hotels', 'tasd_0_rest15_sc', 'tasd_10_rest15_sc', 'tasd_20_rest15_sc', 'tasd_30_rest15_sc', 'tasd_40_rest15_sc', 'tasd_50_rest15_sc', 'asqp_0_rest15_sc', 'asqp_10_rest15_sc', 'asqp_20_rest15_sc', 'asqp_30_rest15_sc', 'asqp_40_rest15_sc', 'asqp_50_rest15_sc', 'tasd_0_rest16_sc', 'tasd_10_rest16_sc', 'tasd_20_rest16_sc', 'tasd_30_rest16_sc', 'tasd_40_rest16_sc', 'tasd_50_rest16_sc', 'asqp_0_rest16_sc', 'asqp_10_rest16_sc', 'asqp_20_rest16_sc', 'asqp_30_rest16_sc', 'asqp_40_rest16_sc', 'asqp_50_rest16_sc', 'tasd_0_flightabsa_sc', 'tasd_10_flightabsa_sc', 'tasd_20_flightabsa_sc', 'tasd_30_flightabsa_sc', 'tasd_40_flightabsa_sc', 'tasd_50_flightabsa_sc', 'asqp_0_flightabsa_sc', 'asqp_10_flightabsa_sc', 'asqp_20_flightabsa_sc', 'asqp_30_flightabsa_sc', 'asqp_40_flightabsa_sc', 'asqp_50_flightabsa_sc', 'tasd_0_coursera_sc', 'tasd_10_coursera_sc', 'tasd_20_coursera_sc', 'tasd_30_coursera_sc', 'tasd_40_coursera_sc', 'tasd_50_coursera_sc', 'asqp_0_coursera_sc', 'asqp_10_coursera_sc', 'asqp_20_coursera_sc', 'asqp_30_coursera_sc', 'asqp_40_coursera_sc', 'asqp_50_coursera_sc', 'tasd_0_hotels_sc', 'tasd_10_hotels_sc', 'tasd_20_hotels_sc', 'tasd_30_hotels_sc', 'tasd_40_hotels_sc', 'tasd_50_hotels_sc', 'asqp_0_hotels_sc', 'asqp_10_hotels_sc', 'asqp_20_hotels_sc', 'asqp_30_hotels_sc', 'asqp_40_hotels_sc', 'asqp_50_hotels_sc'])\n",
      "dict_keys(['paraphrase_10_tasd_rest15', 'paraphrase_50_tasd_rest15', 'paraphrase_full_tasd_rest15', 'dlo_10_tasd_rest15', 'dlo_50_tasd_rest15', 'dlo_full_tasd_rest15', 'paraphrase_10_asqp_rest15', 'paraphrase_50_asqp_rest15', 'paraphrase_full_asqp_rest15', 'dlo_10_asqp_rest15', 'dlo_50_asqp_rest15', 'dlo_full_asqp_rest15', 'paraphrase_10_tasd_rest16', 'paraphrase_50_tasd_rest16', 'paraphrase_full_tasd_rest16', 'dlo_10_tasd_rest16', 'dlo_50_tasd_rest16', 'dlo_full_tasd_rest16', 'paraphrase_10_asqp_rest16', 'paraphrase_50_asqp_rest16', 'paraphrase_full_asqp_rest16', 'dlo_10_asqp_rest16', 'dlo_50_asqp_rest16', 'dlo_full_asqp_rest16', 'paraphrase_10_tasd_flightabsa', 'paraphrase_50_tasd_flightabsa', 'paraphrase_full_tasd_flightabsa', 'dlo_10_tasd_flightabsa', 'dlo_50_tasd_flightabsa', 'dlo_full_tasd_flightabsa', 'paraphrase_10_asqp_flightabsa', 'paraphrase_50_asqp_flightabsa', 'paraphrase_full_asqp_flightabsa', 'dlo_10_asqp_flightabsa', 'dlo_50_asqp_flightabsa', 'dlo_full_asqp_flightabsa', 'paraphrase_10_tasd_coursera', 'paraphrase_50_tasd_coursera', 'paraphrase_full_tasd_coursera', 'dlo_10_tasd_coursera', 'dlo_50_tasd_coursera', 'dlo_full_tasd_coursera', 'paraphrase_10_asqp_coursera', 'paraphrase_50_asqp_coursera', 'paraphrase_full_asqp_coursera', 'dlo_10_asqp_coursera', 'dlo_50_asqp_coursera', 'dlo_full_asqp_coursera', 'paraphrase_10_tasd_hotels', 'paraphrase_50_tasd_hotels', 'paraphrase_full_tasd_hotels', 'dlo_10_tasd_hotels', 'dlo_50_tasd_hotels', 'dlo_full_tasd_hotels', 'paraphrase_10_asqp_hotels', 'paraphrase_50_asqp_hotels', 'paraphrase_full_asqp_hotels', 'dlo_10_asqp_hotels', 'dlo_50_asqp_hotels', 'dlo_full_asqp_hotels'])\n",
      "dict_keys(['paraphrase_full_tasd_0_rest15', 'paraphrase_full_tasd_10_rest15', 'paraphrase_full_tasd_50_rest15', 'dlo_full_tasd_0_rest15', 'dlo_full_tasd_10_rest15', 'dlo_full_tasd_50_rest15', 'paraphrase_full_asqp_0_rest15', 'paraphrase_full_asqp_10_rest15', 'paraphrase_full_asqp_50_rest15', 'dlo_full_asqp_0_rest15', 'dlo_full_asqp_10_rest15', 'dlo_full_asqp_50_rest15', 'paraphrase_full_tasd_0_rest16', 'paraphrase_full_tasd_10_rest16', 'paraphrase_full_tasd_50_rest16', 'dlo_full_tasd_0_rest16', 'dlo_full_tasd_10_rest16', 'dlo_full_tasd_50_rest16', 'paraphrase_full_asqp_0_rest16', 'paraphrase_full_asqp_10_rest16', 'paraphrase_full_asqp_50_rest16', 'dlo_full_asqp_0_rest16', 'dlo_full_asqp_10_rest16', 'dlo_full_asqp_50_rest16', 'paraphrase_full_tasd_0_flightabsa', 'paraphrase_full_tasd_10_flightabsa', 'paraphrase_full_tasd_50_flightabsa', 'dlo_full_tasd_0_flightabsa', 'dlo_full_tasd_10_flightabsa', 'dlo_full_tasd_50_flightabsa', 'paraphrase_full_asqp_0_flightabsa', 'paraphrase_full_asqp_10_flightabsa', 'paraphrase_full_asqp_50_flightabsa', 'dlo_full_asqp_0_flightabsa', 'dlo_full_asqp_10_flightabsa', 'dlo_full_asqp_50_flightabsa', 'paraphrase_full_tasd_0_coursera', 'paraphrase_full_tasd_10_coursera', 'paraphrase_full_tasd_50_coursera', 'dlo_full_tasd_0_coursera', 'dlo_full_tasd_10_coursera', 'dlo_full_tasd_50_coursera', 'paraphrase_full_asqp_0_coursera', 'paraphrase_full_asqp_10_coursera', 'paraphrase_full_asqp_50_coursera', 'dlo_full_asqp_0_coursera', 'dlo_full_asqp_10_coursera', 'dlo_full_asqp_50_coursera', 'paraphrase_full_tasd_0_hotels', 'paraphrase_full_tasd_10_hotels', 'paraphrase_full_tasd_50_hotels', 'dlo_full_tasd_0_hotels', 'dlo_full_tasd_10_hotels', 'dlo_full_tasd_50_hotels', 'paraphrase_full_asqp_0_hotels', 'paraphrase_full_asqp_10_hotels', 'paraphrase_full_asqp_50_hotels', 'dlo_full_asqp_0_hotels', 'dlo_full_asqp_10_hotels', 'dlo_full_asqp_50_hotels', 'ds2_tasd_10_rest15', 'ds2_tasd_50_rest15', 'ds2_asqp_10_rest15', 'ds2_asqp_50_rest15', 'ds2_tasd_10_rest16', 'ds2_tasd_50_rest16', 'ds2_asqp_10_rest16', 'ds2_asqp_50_rest16', 'ds2_tasd_10_flightabsa', 'ds2_tasd_50_flightabsa', 'ds2_asqp_10_flightabsa', 'ds2_asqp_50_flightabsa', 'ds2_tasd_10_coursera', 'ds2_tasd_50_coursera', 'ds2_asqp_10_coursera', 'ds2_asqp_50_coursera', 'ds2_tasd_10_hotels', 'ds2_tasd_50_hotels', 'ds2_asqp_10_hotels', 'ds2_asqp_50_hotels'])\n",
      "dict_keys(['qaie_tasd_10_rest15', 'qaie_tasd_50_rest15', 'qaie_asqp_10_rest15', 'qaie_asqp_50_rest15', 'qaie_tasd_10_rest16', 'qaie_tasd_50_rest16', 'qaie_asqp_10_rest16', 'qaie_asqp_50_rest16', 'qaie_tasd_10_flightabsa', 'qaie_tasd_50_flightabsa', 'qaie_asqp_10_flightabsa', 'qaie_asqp_50_flightabsa', 'qaie_tasd_10_coursera', 'qaie_tasd_50_coursera', 'qaie_asqp_10_coursera', 'qaie_asqp_50_coursera', 'qaie_tasd_10_hotels', 'qaie_tasd_50_hotels', 'qaie_asqp_10_hotels', 'qaie_asqp_50_hotels', 'paraphrase_eda_2_tasd_10_rest15', 'paraphrase_eda_5_tasd_10_rest15', 'paraphrase_eda_10_tasd_10_rest15', 'paraphrase_eda_15_tasd_10_rest15', 'paraphrase_eda_2_tasd_50_rest15', 'paraphrase_eda_5_tasd_50_rest15', 'paraphrase_eda_10_tasd_50_rest15', 'paraphrase_eda_15_tasd_50_rest15', 'dlo_eda_2_tasd_10_rest15', 'dlo_eda_5_tasd_10_rest15', 'dlo_eda_10_tasd_10_rest15', 'dlo_eda_15_tasd_10_rest15', 'dlo_eda_2_tasd_50_rest15', 'dlo_eda_5_tasd_50_rest15', 'dlo_eda_10_tasd_50_rest15', 'dlo_eda_15_tasd_50_rest15', 'paraphrase_eda_2_asqp_10_rest15', 'paraphrase_eda_5_asqp_10_rest15', 'paraphrase_eda_10_asqp_10_rest15', 'paraphrase_eda_15_asqp_10_rest15', 'paraphrase_eda_2_asqp_50_rest15', 'paraphrase_eda_5_asqp_50_rest15', 'paraphrase_eda_10_asqp_50_rest15', 'paraphrase_eda_15_asqp_50_rest15', 'dlo_eda_2_asqp_10_rest15', 'dlo_eda_5_asqp_10_rest15', 'dlo_eda_10_asqp_10_rest15', 'dlo_eda_15_asqp_10_rest15', 'dlo_eda_2_asqp_50_rest15', 'dlo_eda_5_asqp_50_rest15', 'dlo_eda_10_asqp_50_rest15', 'dlo_eda_15_asqp_50_rest15', 'paraphrase_eda_2_tasd_10_rest16', 'paraphrase_eda_5_tasd_10_rest16', 'paraphrase_eda_10_tasd_10_rest16', 'paraphrase_eda_15_tasd_10_rest16', 'paraphrase_eda_2_tasd_50_rest16', 'paraphrase_eda_5_tasd_50_rest16', 'paraphrase_eda_10_tasd_50_rest16', 'paraphrase_eda_15_tasd_50_rest16', 'dlo_eda_2_tasd_10_rest16', 'dlo_eda_5_tasd_10_rest16', 'dlo_eda_10_tasd_10_rest16', 'dlo_eda_15_tasd_10_rest16', 'dlo_eda_2_tasd_50_rest16', 'dlo_eda_5_tasd_50_rest16', 'dlo_eda_10_tasd_50_rest16', 'dlo_eda_15_tasd_50_rest16', 'paraphrase_eda_2_asqp_10_rest16', 'paraphrase_eda_5_asqp_10_rest16', 'paraphrase_eda_10_asqp_10_rest16', 'paraphrase_eda_15_asqp_10_rest16', 'paraphrase_eda_2_asqp_50_rest16', 'paraphrase_eda_5_asqp_50_rest16', 'paraphrase_eda_10_asqp_50_rest16', 'paraphrase_eda_15_asqp_50_rest16', 'dlo_eda_2_asqp_10_rest16', 'dlo_eda_5_asqp_10_rest16', 'dlo_eda_10_asqp_10_rest16', 'dlo_eda_15_asqp_10_rest16', 'dlo_eda_2_asqp_50_rest16', 'dlo_eda_5_asqp_50_rest16', 'dlo_eda_10_asqp_50_rest16', 'dlo_eda_15_asqp_50_rest16', 'paraphrase_eda_2_tasd_10_flightabsa', 'paraphrase_eda_5_tasd_10_flightabsa', 'paraphrase_eda_10_tasd_10_flightabsa', 'paraphrase_eda_15_tasd_10_flightabsa', 'paraphrase_eda_2_tasd_50_flightabsa', 'paraphrase_eda_5_tasd_50_flightabsa', 'paraphrase_eda_10_tasd_50_flightabsa', 'paraphrase_eda_15_tasd_50_flightabsa', 'dlo_eda_2_tasd_10_flightabsa', 'dlo_eda_5_tasd_10_flightabsa', 'dlo_eda_10_tasd_10_flightabsa', 'dlo_eda_15_tasd_10_flightabsa', 'dlo_eda_2_tasd_50_flightabsa', 'dlo_eda_5_tasd_50_flightabsa', 'dlo_eda_10_tasd_50_flightabsa', 'dlo_eda_15_tasd_50_flightabsa', 'paraphrase_eda_2_asqp_10_flightabsa', 'paraphrase_eda_5_asqp_10_flightabsa', 'paraphrase_eda_10_asqp_10_flightabsa', 'paraphrase_eda_15_asqp_10_flightabsa', 'paraphrase_eda_2_asqp_50_flightabsa', 'paraphrase_eda_5_asqp_50_flightabsa', 'paraphrase_eda_10_asqp_50_flightabsa', 'paraphrase_eda_15_asqp_50_flightabsa', 'dlo_eda_2_asqp_10_flightabsa', 'dlo_eda_5_asqp_10_flightabsa', 'dlo_eda_10_asqp_10_flightabsa', 'dlo_eda_15_asqp_10_flightabsa', 'dlo_eda_2_asqp_50_flightabsa', 'dlo_eda_5_asqp_50_flightabsa', 'dlo_eda_10_asqp_50_flightabsa', 'dlo_eda_15_asqp_50_flightabsa', 'paraphrase_eda_2_tasd_10_coursera', 'paraphrase_eda_5_tasd_10_coursera', 'paraphrase_eda_10_tasd_10_coursera', 'paraphrase_eda_15_tasd_10_coursera', 'paraphrase_eda_2_tasd_50_coursera', 'paraphrase_eda_5_tasd_50_coursera', 'paraphrase_eda_10_tasd_50_coursera', 'paraphrase_eda_15_tasd_50_coursera', 'dlo_eda_2_tasd_10_coursera', 'dlo_eda_5_tasd_10_coursera', 'dlo_eda_10_tasd_10_coursera', 'dlo_eda_15_tasd_10_coursera', 'dlo_eda_2_tasd_50_coursera', 'dlo_eda_5_tasd_50_coursera', 'dlo_eda_10_tasd_50_coursera', 'dlo_eda_15_tasd_50_coursera', 'paraphrase_eda_2_asqp_10_coursera', 'paraphrase_eda_5_asqp_10_coursera', 'paraphrase_eda_10_asqp_10_coursera', 'paraphrase_eda_15_asqp_10_coursera', 'paraphrase_eda_2_asqp_50_coursera', 'paraphrase_eda_5_asqp_50_coursera', 'paraphrase_eda_10_asqp_50_coursera', 'paraphrase_eda_15_asqp_50_coursera', 'dlo_eda_2_asqp_10_coursera', 'dlo_eda_5_asqp_10_coursera', 'dlo_eda_10_asqp_10_coursera', 'dlo_eda_15_asqp_10_coursera', 'dlo_eda_2_asqp_50_coursera', 'dlo_eda_5_asqp_50_coursera', 'dlo_eda_10_asqp_50_coursera', 'dlo_eda_15_asqp_50_coursera', 'paraphrase_eda_2_tasd_10_hotels', 'paraphrase_eda_5_tasd_10_hotels', 'paraphrase_eda_10_tasd_10_hotels', 'paraphrase_eda_15_tasd_10_hotels', 'paraphrase_eda_2_tasd_50_hotels', 'paraphrase_eda_5_tasd_50_hotels', 'paraphrase_eda_10_tasd_50_hotels', 'paraphrase_eda_15_tasd_50_hotels', 'dlo_eda_2_tasd_10_hotels', 'dlo_eda_5_tasd_10_hotels', 'dlo_eda_10_tasd_10_hotels', 'dlo_eda_15_tasd_10_hotels', 'dlo_eda_2_tasd_50_hotels', 'dlo_eda_5_tasd_50_hotels', 'dlo_eda_10_tasd_50_hotels', 'dlo_eda_15_tasd_50_hotels', 'paraphrase_eda_2_asqp_10_hotels', 'paraphrase_eda_5_asqp_10_hotels', 'paraphrase_eda_10_asqp_10_hotels', 'paraphrase_eda_15_asqp_10_hotels', 'paraphrase_eda_2_asqp_50_hotels', 'paraphrase_eda_5_asqp_50_hotels', 'paraphrase_eda_10_asqp_50_hotels', 'paraphrase_eda_15_asqp_50_hotels', 'dlo_eda_2_asqp_10_hotels', 'dlo_eda_5_asqp_10_hotels', 'dlo_eda_10_asqp_10_hotels', 'dlo_eda_15_asqp_10_hotels', 'dlo_eda_2_asqp_50_hotels', 'dlo_eda_5_asqp_50_hotels', 'dlo_eda_10_asqp_50_hotels', 'dlo_eda_15_asqp_50_hotels'])\n"
     ]
    }
   ],
   "source": [
    "print(scores_zeroshot.keys())\n",
    "print(scores_00_baseline.keys())\n",
    "print(scores_llm_ann_train.keys())\n",
    "print(scores_traditional_aug.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cf4baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FT_APPROACHES = [\"Paraphrase\", \"DLO\"]\n",
    "FT_ENCODING = {\"Paraphrase\": \"paraphrase\", \"DLO\": \"dlo\"}\n",
    "FT_ENCODING_REVERSE = {v: k for k, v in FT_ENCODING.items()}\n",
    "\n",
    "N_TRAIN_EDA = [2, 5, 10, 15]\n",
    "N_SHOTS = [10, 50]\n",
    "\n",
    "def get_mean_n_train_qaie(task, fs):\n",
    "    \"\"\"Calculate mean n_train across datasets for a given task and fs.\"\"\"\n",
    "    return str(np.round(np.mean([\n",
    "        get_n_train_qaie(task=task, dataset=ds, fs=fs) \n",
    "        for ds in DATASETS\n",
    "    ]), 1))\n",
    "    \n",
    "def to_k(num_str):\n",
    "    \"\"\"\n",
    "    Convert a European number string (comma decimal) into k-format.\n",
    "    Example: \"23343,54\" -> \"23,3k\"\n",
    "    \"\"\"\n",
    "    # Replace comma with dot for float conversion\n",
    "    num = float(str(num_str).replace(\",\", \".\"))\n",
    "\n",
    "    # Convert to k with 1 decimal\n",
    "    result = f\"{num / 1000:.1f}k\"\n",
    "\n",
    "    # Use comma instead of dot for decimal\n",
    "    result = result.replace(\".\", \",\")\n",
    "\n",
    "    # Remove ,0 if no decimal is needed\n",
    "    if result.endswith(\",0k\"):\n",
    "        result = result.replace(\",0k\", \"k\")\n",
    "\n",
    "    return result\n",
    "\n",
    "    \n",
    "def get_mean_n_train_ds2(task, fs):\n",
    "    \"\"\"Calculate mean n_train across datasets for a given task and fs.\"\"\"\n",
    "    return to_k(str(np.round(np.mean([\n",
    "        get_n_train_ds2(task=task, dataset=ds, fs=fs) \n",
    "        for ds in DATASETS\n",
    "    ]), 1)))\n",
    "\n",
    "def create_columns():\n",
    "    \"\"\"Create all column data for the DataFrame.\"\"\"\n",
    "    # Base pattern for one shot value\n",
    "    base_pattern_size = len(FT_APPROACHES) * 2 + len(N_TRAIN_EDA) * len(FT_APPROACHES) + 2 # 2 = qaie and ds2\n",
    "    \n",
    "    # Annotated examples column\n",
    "    n_annotated = ([0] * 3 + \n",
    "                  [10] * (1 + base_pattern_size) + \n",
    "                  [50] * (1 + base_pattern_size) + \n",
    "                  [\"full\"] * len(FT_APPROACHES))\n",
    "    \n",
    "    # Approaches column - base pattern\n",
    "    base_approaches = ([[\"k-shot Gemma\"]] + FT_APPROACHES + \n",
    "                      [f\"LLMA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES] +\n",
    "                      [f\"EDA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES for _ in N_TRAIN_EDA] +\n",
    "                      [\"QAIE\", \"DS2\"])\n",
    "    \n",
    "    approaches = ([[\"0-shot Gemma\"]]+[f\"LLMA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES] +\n",
    "                 base_approaches * 2 +  # For 10 and 50 shots\n",
    "                 FT_APPROACHES )\n",
    "    \n",
    "    # Training columns\n",
    "    def build_train_column(task):\n",
    "        column = [\"0\", \"full\", \"full\"] \n",
    "        for fs in N_SHOTS:\n",
    "            column.extend([fs,\n",
    "                *([fs] * len(FT_APPROACHES)),\n",
    "                *([\"full\"] * len(FT_APPROACHES)),\n",
    "                *([fs + n * fs for _ in FT_APPROACHES for n in N_TRAIN_EDA]),\n",
    "                get_mean_n_train_qaie(task, fs),\n",
    "                get_mean_n_train_ds2(task, fs)\n",
    "            ])\n",
    "        column.extend([\"full\"] * len(FT_APPROACHES))\n",
    "        return column\n",
    "    \n",
    "    return n_annotated, approaches, build_train_column(\"tasd\"), build_train_column(\"asqp\")\n",
    "\n",
    "def collect_performance_scores(tasks, metrics):\n",
    "    \"\"\"Collect all performance scores from different score dictionaries.\"\"\"\n",
    "    scores = {dataset: {task: {metric: [] for metric in metrics} for task in tasks} \n",
    "              for dataset in DATASETS}\n",
    "    \n",
    "    for dataset in DATASETS:\n",
    "        for task in tasks:\n",
    "            for metric in metrics:\n",
    "                task_scores = scores[dataset][task][metric]\n",
    "\n",
    "                task_scores.extend([\n",
    "                    scores_zeroshot[f\"{task}_{fs}_{dataset}_sc\"][metric]\n",
    "                    for fs in [0]\n",
    "                ])\n",
    "                \n",
    "                # Zero-shot scores\n",
    "                task_scores.extend([\n",
    "                    scores_llm_ann_train[f\"{method}_full_{task}_0_{dataset}\"][metric]\n",
    "                    for method in METHODS\n",
    "                ])\n",
    "                \n",
    "                # Few-shot scores (10, 50)\n",
    "                for fs in N_SHOTS:\n",
    "                    # Baseline scores\n",
    "\n",
    "                    task_scores.extend([\n",
    "                      scores_zeroshot[f\"{task}_{k}_{dataset}_sc\"][metric]\n",
    "                      for k in [fs]\n",
    "                    ])\n",
    "                \n",
    "                    task_scores.extend([\n",
    "                        scores_00_baseline[f\"{method}_{fs}_{task}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                    ])\n",
    "                    \n",
    "                    # LLM annotation scores\n",
    "                    task_scores.extend([\n",
    "                        scores_llm_ann_train[f\"{method}_full_{task}_{fs}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                    ])\n",
    "                    \n",
    "                    # Traditional augmentation scores\n",
    "                    task_scores.extend([\n",
    "                        scores_traditional_aug[f\"{method}_eda_{n_train}_{task}_{fs}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                        for n_train in N_TRAIN_EDA\n",
    "                    ])\n",
    "                    \n",
    "                    # QAIE scores\n",
    "                    task_scores.append(\n",
    "                        scores_traditional_aug[f\"qaie_{task}_{fs}_{dataset}\"][metric]\n",
    "                    )\n",
    "                    \n",
    "                    # DS2 scores\n",
    "                    task_scores.append(\n",
    "                        scores_llm_ann_train[f\"ds2_{task}_{fs}_{dataset}\"][metric]\n",
    "                    )\n",
    "                \n",
    "                # Full training scores\n",
    "                task_scores.extend([\n",
    "                    scores_00_baseline[f\"{method}_full_{task}_{dataset}\"][metric]\n",
    "                    for method in METHODS\n",
    "                ])\n",
    "            \n",
    "    \n",
    "    return scores\n",
    "\n",
    "def create_f1_plot_with_avg(table_out):\n",
    "    tasd_columns = [col for col in table_out.columns if \"tasd\" in col and col != \"\\\\# n_train_column_tasd\"]\n",
    "    asqp_columns = [col for col in table_out.columns if \"asqp\" in col and col != \"\\\\# n_train_column_asqp\"]\n",
    "    \n",
    "    # Für tasd: \"-\" ignorieren, ohne Originalwerte zu überschreiben\n",
    "    tasd_numeric = table_out[tasd_columns].apply(\n",
    "        lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "    )\n",
    "    tasd_avg = tasd_numeric.mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Für asqp: \"-\" ignorieren, ohne Originalwerte zu überschreiben\n",
    "    asqp_numeric = table_out[asqp_columns].apply(\n",
    "        lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "    )\n",
    "    asqp_avg = asqp_numeric.mean(axis=1, skipna=True)\n",
    "    \n",
    "    table_out[\"tasd_avg\"] = tasd_avg\n",
    "    table_out[\"asqp_avg\"] = asqp_avg\n",
    "    return table_out\n",
    "\n",
    "\n",
    "def create_f1_plot(tasks=[\"tasd\"], metrics=[\"f1\"]):\n",
    "    \"\"\"Create F1 plot DataFrame with simplified logic.\"\"\"\n",
    "    \n",
    "    # Get all column data\n",
    "    n_annotated, approaches, n_train_tasd, n_train_asqp = create_columns()\n",
    "    \n",
    "    # Collect performance scores\n",
    "    performance_scores = collect_performance_scores(tasks, metrics)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_data = {\n",
    "        \"\\# Annotated examples\": n_annotated,\n",
    "        \"Approach\": approaches,\n",
    "        \"\\# n_train_column_tasd\": n_train_tasd,\n",
    "        \"\\# n_train_column_asqp\": n_train_asqp,\n",
    "    }\n",
    "    \n",
    "    # Add performance columns\n",
    "    for dataset in DATASETS:\n",
    "        for task in tasks:\n",
    "            for metric in metrics:\n",
    "                df_data[f\"{dataset}_{task}_{metric}\"] = performance_scores[dataset][task][metric]\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    \n",
    "    # Round numbers in performance columns\n",
    "    performance_columns = [f\"{dataset}_{task}_{metric}\" \n",
    "                          for dataset in DATASETS \n",
    "                          for task in tasks \n",
    "                          for metric in metrics]\n",
    "    \n",
    "    performance_columns += [\"tasd_avg\", \"asqp_avg\"]\n",
    "    \n",
    "    df = create_f1_plot_with_avg(df)\n",
    "    df_raw = df.copy()\n",
    "    df = round_numbers(df, performance_columns, n_rest=2)\n",
    "\n",
    "    return df, df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f6a136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def extract_raw_value(formatted_value):\n",
    "    if pd.isna(formatted_value):\n",
    "        return formatted_value\n",
    "    \n",
    "    value_str = str(formatted_value)\n",
    "    \n",
    "    # Entferne alle LaTeX-Formatierungen\n",
    "    # Muster für \\textbf{...}, \\underline{...} und verschachtelte Kombinationen\n",
    "    clean_value = value_str\n",
    "    \n",
    "    # Iterativ alle Formatierungen entfernen\n",
    "    while True:\n",
    "        old_value = clean_value\n",
    "        # Entferne \\textbf{...}\n",
    "        clean_value = re.sub(r'\\\\textbf\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}', r'\\1', clean_value)\n",
    "        # Entferne \\underline{...}\n",
    "        clean_value = re.sub(r'\\\\underline\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}', r'\\1', clean_value)\n",
    "        \n",
    "        if clean_value == old_value:\n",
    "            break\n",
    "    \n",
    "    return clean_value\n",
    "\n",
    "def apply_formatting(value, bold=False, underline=False):\n",
    "    result = str(value)\n",
    "    \n",
    "    if underline:\n",
    "        result = f\"\\\\underline{{{result}}}\"\n",
    "    if bold:\n",
    "        result = f\"\\\\textbf{{{result}}}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_current_formatting(formatted_value):\n",
    "    if pd.isna(formatted_value):\n",
    "        return False, False\n",
    "    \n",
    "    value_str = str(formatted_value)\n",
    "    is_bold = '\\\\textbf{' in value_str\n",
    "    is_underlined = '\\\\underline{' in value_str\n",
    "    \n",
    "    return is_bold, is_underlined\n",
    "\n",
    "def highlight(df, start_column, end_column, groups, type=\"underline\"):\n",
    "    # Kopie des DataFrames erstellen\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Formatierungsoptionen bestimmen\n",
    "    if type == \"both\" or (isinstance(type, list) and \"bold\" in type and \"underline\" in type):\n",
    "        apply_bold = True\n",
    "        apply_underline = True\n",
    "    elif type == \"bold\" or (isinstance(type, list) and \"bold\" in type):\n",
    "        apply_bold = True\n",
    "        apply_underline = False\n",
    "    elif type == \"underline\" or (isinstance(type, list) and \"underline\" in type):\n",
    "        apply_bold = False\n",
    "        apply_underline = True\n",
    "    else:\n",
    "        apply_bold = False\n",
    "        apply_underline = True  # Default\n",
    "    \n",
    "    # Durch alle betroffenen Spalten iterieren\n",
    "    for col_idx in range(start_column, end_column + 1):\n",
    "        col_name = df.columns[col_idx]\n",
    "        \n",
    "        # Durch alle Gruppen iterieren\n",
    "        for group in groups:\n",
    "            # Werte der aktuellen Gruppe in der aktuellen Spalte\n",
    "            group_series = df.iloc[group, col_idx]\n",
    "            \n",
    "            # Rohe Werte extrahieren für numerischen Vergleich\n",
    "            raw_values = []\n",
    "            for idx in group:\n",
    "                raw_val = extract_raw_value(df.iloc[idx, col_idx])\n",
    "                raw_values.append(raw_val)\n",
    "            \n",
    "            # Versuche, die rohen Werte in float zu konvertieren\n",
    "            numeric_values = pd.to_numeric(raw_values, errors='coerce')\n",
    "            \n",
    "            # remove values from numpy array numeric_values that are not numeric\n",
    "            numeric_values = [val for val in numeric_values if not pd.isna(val)]\n",
    "            \n",
    "            try:\n",
    "              max_value = max(numeric_values)\n",
    "            except ValueError:\n",
    "              max_value = None\n",
    "                \n",
    "            # Finde alle Indizes mit dem Maximalwert\n",
    "            for i, (idx, raw_val, numeric_val) in enumerate(zip(group, raw_values, numeric_values)):\n",
    "                    if numeric_val == max_value:\n",
    "                        # Aktuelle Formatierung ermitteln\n",
    "                        current_value = result_df.iloc[idx, col_idx]\n",
    "                        is_bold, is_underlined = get_current_formatting(current_value)\n",
    "                        \n",
    "                        # Neue Formatierung bestimmen\n",
    "                        new_bold = is_bold or apply_bold\n",
    "                        new_underline = is_underlined or apply_underline\n",
    "                        \n",
    "                        # Rohen Wert extrahieren und neue Formatierung anwenden\n",
    "                        raw_value = extract_raw_value(current_value)\n",
    "                        formatted_value = apply_formatting(raw_value, bold=new_bold, underline=new_underline)\n",
    "                        \n",
    "                        result_df.iloc[idx, col_idx] = formatted_value\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfb9ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file in 01_muster_tex/performance.txt\n",
    "with open(\"01_muster_tex/performance.txt\", \"r\") as f:\n",
    "    template = f.read()\n",
    "\n",
    "for metric in [\"f1\", \"precision\", \"recall\", \"f1_macro\"]:\n",
    "    table_out, table_out_raw = create_f1_plot(tasks=[\"tasd\", \"asqp\"], metrics=[metric])\n",
    "    \n",
    "    mask = pd.Series(True, index=table_out.index)\n",
    "    \n",
    "    for idx, row in table_out.iterrows():\n",
    "        approach = str(row['Approach'])\n",
    "        n_train_tasd = row['\\\\# n_train_column_tasd']\n",
    "        \n",
    "        # Check if approach contains \"EDA\"\n",
    "        if 'EDA' in approach:\n",
    "            # If it also contains \"Paraphrase\", remove it\n",
    "            if 'Paraphrase' in approach:\n",
    "                mask[idx] = False\n",
    "            # If it contains only \"EDA\" but n_train_column_tasd is not 110 or 550, remove it\n",
    "            elif n_train_tasd not in [110, 550]:\n",
    "                mask[idx] = False\n",
    "    \n",
    "    # Apply the mask to filter the dataframes\n",
    "    table_out = table_out[mask].copy()\n",
    "    table_out_raw = table_out_raw[mask].copy()\n",
    "    \n",
    "    # Reset index for proper highlighting\n",
    "    table_out.reset_index(drop=True, inplace=True)\n",
    "    table_out_raw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    table_out = highlight(table_out, start_column=4, end_column=15, groups=[[0, 1, 2], [k for k in range(3, 10)], [k for k in range(11, 18)], [19, 20]], type=\"bold\")\n",
    "    table_out = highlight(table_out, start_column=4, end_column=15, groups=[[i for i in range(0, 21)]], type=\"underline\")\n",
    "    \n",
    "    table_out_list = table_out.iloc[:, 2:].astype(str).values.tolist()\n",
    "    table_out_list = [item for sublist in table_out_list for item in sublist]\n",
    "\n",
    "    table_with_values = template\n",
    "    for i in range(len(table_out_list)):\n",
    "        table_with_values = table_with_values.replace(\"xxxx\", table_out_list[i], 1)\n",
    "    \n",
    "    # Write the final table to a file\n",
    "    with open(f\"_out_table/{metric}_table.txt\", \"w\") as f_out:\n",
    "        f_out.write(table_with_values)\n",
    "        \n",
    "    # store df table_out_raw as csv\n",
    "    table_out_raw.to_csv(f\"_out_table/{metric}_table_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e7e90c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\# Annotated examples</th>\n",
       "      <th>Approach</th>\n",
       "      <th>\\# n_train_column_tasd</th>\n",
       "      <th>\\# n_train_column_asqp</th>\n",
       "      <th>rest15_tasd_f1_macro</th>\n",
       "      <th>rest15_asqp_f1_macro</th>\n",
       "      <th>rest16_tasd_f1_macro</th>\n",
       "      <th>rest16_asqp_f1_macro</th>\n",
       "      <th>flightabsa_tasd_f1_macro</th>\n",
       "      <th>flightabsa_asqp_f1_macro</th>\n",
       "      <th>coursera_tasd_f1_macro</th>\n",
       "      <th>coursera_asqp_f1_macro</th>\n",
       "      <th>hotels_tasd_f1_macro</th>\n",
       "      <th>hotels_asqp_f1_macro</th>\n",
       "      <th>tasd_avg</th>\n",
       "      <th>asqp_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0-shot Gemma]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.682965</td>\n",
       "      <td>23.639517</td>\n",
       "      <td>45.935407</td>\n",
       "      <td>23.636457</td>\n",
       "      <td>55.239551</td>\n",
       "      <td>39.500646</td>\n",
       "      <td>33.783261</td>\n",
       "      <td>13.229913</td>\n",
       "      <td>29.696821</td>\n",
       "      <td>18.492406</td>\n",
       "      <td>39.667601</td>\n",
       "      <td>23.699788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LLMA \\textbackslash w Paraphrase</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>22.87668</td>\n",
       "      <td>19.933547</td>\n",
       "      <td>35.836568</td>\n",
       "      <td>26.201357</td>\n",
       "      <td>45.947851</td>\n",
       "      <td>33.610097</td>\n",
       "      <td>11.850261</td>\n",
       "      <td>4.087686</td>\n",
       "      <td>16.203254</td>\n",
       "      <td>12.436418</td>\n",
       "      <td>26.542923</td>\n",
       "      <td>19.253821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>LLMA \\textbackslash w DLO</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>24.121302</td>\n",
       "      <td>21.020939</td>\n",
       "      <td>36.116571</td>\n",
       "      <td>29.162906</td>\n",
       "      <td>45.368816</td>\n",
       "      <td>36.315586</td>\n",
       "      <td>12.100186</td>\n",
       "      <td>3.704135</td>\n",
       "      <td>17.175781</td>\n",
       "      <td>13.104287</td>\n",
       "      <td>26.976531</td>\n",
       "      <td>20.661570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[k-shot Gemma]</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>54.533423</td>\n",
       "      <td>38.667507</td>\n",
       "      <td>64.330219</td>\n",
       "      <td>43.213794</td>\n",
       "      <td>56.321010</td>\n",
       "      <td>36.583710</td>\n",
       "      <td>41.749528</td>\n",
       "      <td>20.441145</td>\n",
       "      <td>31.154214</td>\n",
       "      <td>18.053876</td>\n",
       "      <td>49.617679</td>\n",
       "      <td>31.392006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Paraphrase</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3.471115</td>\n",
       "      <td>0.46161</td>\n",
       "      <td>2.590951</td>\n",
       "      <td>0.872893</td>\n",
       "      <td>2.379838</td>\n",
       "      <td>1.026658</td>\n",
       "      <td>2.168499</td>\n",
       "      <td>0.664533</td>\n",
       "      <td>2.645445</td>\n",
       "      <td>0.469529</td>\n",
       "      <td>2.651170</td>\n",
       "      <td>0.699045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>DLO</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6.095804</td>\n",
       "      <td>1.419034</td>\n",
       "      <td>6.012032</td>\n",
       "      <td>1.253818</td>\n",
       "      <td>4.739594</td>\n",
       "      <td>1.353251</td>\n",
       "      <td>3.330280</td>\n",
       "      <td>0.604962</td>\n",
       "      <td>4.098271</td>\n",
       "      <td>0.827046</td>\n",
       "      <td>4.855196</td>\n",
       "      <td>1.091622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>LLMA \\textbackslash w Paraphrase</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>34.16905</td>\n",
       "      <td>23.983296</td>\n",
       "      <td>48.585244</td>\n",
       "      <td>34.590739</td>\n",
       "      <td>51.195601</td>\n",
       "      <td>36.292755</td>\n",
       "      <td>17.006538</td>\n",
       "      <td>8.536387</td>\n",
       "      <td>26.904822</td>\n",
       "      <td>19.189234</td>\n",
       "      <td>35.572251</td>\n",
       "      <td>24.518482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>LLMA \\textbackslash w DLO</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>35.02917</td>\n",
       "      <td>26.767017</td>\n",
       "      <td>50.386103</td>\n",
       "      <td>36.245368</td>\n",
       "      <td>53.187757</td>\n",
       "      <td>39.011394</td>\n",
       "      <td>17.136884</td>\n",
       "      <td>9.376324</td>\n",
       "      <td>29.017109</td>\n",
       "      <td>18.180098</td>\n",
       "      <td>36.951404</td>\n",
       "      <td>25.916040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>EDA \\textbackslash w DLO</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>11.326772</td>\n",
       "      <td>5.565499</td>\n",
       "      <td>7.940834</td>\n",
       "      <td>2.222501</td>\n",
       "      <td>8.048876</td>\n",
       "      <td>3.644090</td>\n",
       "      <td>4.218857</td>\n",
       "      <td>2.021759</td>\n",
       "      <td>5.485840</td>\n",
       "      <td>2.272988</td>\n",
       "      <td>7.404236</td>\n",
       "      <td>3.145367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>QAIE</td>\n",
       "      <td>26.4</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.855063</td>\n",
       "      <td>5.373985</td>\n",
       "      <td>7.842294</td>\n",
       "      <td>14.289805</td>\n",
       "      <td>12.018949</td>\n",
       "      <td>6.998877</td>\n",
       "      <td>4.300442</td>\n",
       "      <td>1.899235</td>\n",
       "      <td>3.518001</td>\n",
       "      <td>2.856744</td>\n",
       "      <td>8.506950</td>\n",
       "      <td>6.283729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>DS2</td>\n",
       "      <td>21,1k</td>\n",
       "      <td>21,1k</td>\n",
       "      <td>18.825999</td>\n",
       "      <td>12.17129</td>\n",
       "      <td>26.681253</td>\n",
       "      <td>15.59748</td>\n",
       "      <td>22.662025</td>\n",
       "      <td>13.038150</td>\n",
       "      <td>9.651657</td>\n",
       "      <td>3.166712</td>\n",
       "      <td>16.974053</td>\n",
       "      <td>7.886233</td>\n",
       "      <td>18.958997</td>\n",
       "      <td>10.371973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>[k-shot Gemma]</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>56.008004</td>\n",
       "      <td>36.006438</td>\n",
       "      <td>64.813742</td>\n",
       "      <td>44.564631</td>\n",
       "      <td>54.061764</td>\n",
       "      <td>36.666579</td>\n",
       "      <td>38.239726</td>\n",
       "      <td>17.803927</td>\n",
       "      <td>35.470040</td>\n",
       "      <td>25.243182</td>\n",
       "      <td>49.718655</td>\n",
       "      <td>32.056951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>Paraphrase</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>19.753549</td>\n",
       "      <td>14.048335</td>\n",
       "      <td>16.35104</td>\n",
       "      <td>8.348968</td>\n",
       "      <td>12.431129</td>\n",
       "      <td>7.227886</td>\n",
       "      <td>9.586769</td>\n",
       "      <td>2.994512</td>\n",
       "      <td>13.874347</td>\n",
       "      <td>7.544793</td>\n",
       "      <td>14.399367</td>\n",
       "      <td>8.032899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>DLO</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>27.775301</td>\n",
       "      <td>18.098542</td>\n",
       "      <td>22.463731</td>\n",
       "      <td>13.051945</td>\n",
       "      <td>28.895840</td>\n",
       "      <td>19.713303</td>\n",
       "      <td>8.678341</td>\n",
       "      <td>3.106348</td>\n",
       "      <td>16.495915</td>\n",
       "      <td>9.743340</td>\n",
       "      <td>20.861826</td>\n",
       "      <td>12.742696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>LLMA \\textbackslash w Paraphrase</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>35.738846</td>\n",
       "      <td>26.567967</td>\n",
       "      <td>48.337799</td>\n",
       "      <td>31.008575</td>\n",
       "      <td>52.879457</td>\n",
       "      <td>36.652661</td>\n",
       "      <td>17.955465</td>\n",
       "      <td>7.365153</td>\n",
       "      <td>28.200947</td>\n",
       "      <td>19.788086</td>\n",
       "      <td>36.622503</td>\n",
       "      <td>24.276488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>LLMA \\textbackslash w DLO</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>41.640356</td>\n",
       "      <td>28.421088</td>\n",
       "      <td>49.36667</td>\n",
       "      <td>37.368517</td>\n",
       "      <td>52.168613</td>\n",
       "      <td>40.875363</td>\n",
       "      <td>18.074303</td>\n",
       "      <td>8.099663</td>\n",
       "      <td>30.192051</td>\n",
       "      <td>22.590836</td>\n",
       "      <td>38.288399</td>\n",
       "      <td>27.471093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>EDA \\textbackslash w DLO</td>\n",
       "      <td>550</td>\n",
       "      <td>550</td>\n",
       "      <td>27.351029</td>\n",
       "      <td>17.607299</td>\n",
       "      <td>22.377999</td>\n",
       "      <td>16.124642</td>\n",
       "      <td>33.707157</td>\n",
       "      <td>24.743871</td>\n",
       "      <td>12.221974</td>\n",
       "      <td>5.715381</td>\n",
       "      <td>15.849559</td>\n",
       "      <td>13.072016</td>\n",
       "      <td>22.301544</td>\n",
       "      <td>15.452642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>QAIE</td>\n",
       "      <td>141.8</td>\n",
       "      <td>248.8</td>\n",
       "      <td>44.808635</td>\n",
       "      <td>30.844816</td>\n",
       "      <td>45.498069</td>\n",
       "      <td>32.233524</td>\n",
       "      <td>37.409262</td>\n",
       "      <td>22.293801</td>\n",
       "      <td>20.785344</td>\n",
       "      <td>10.203490</td>\n",
       "      <td>24.193516</td>\n",
       "      <td>18.509205</td>\n",
       "      <td>34.538965</td>\n",
       "      <td>22.816967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>DS2</td>\n",
       "      <td>21,7k</td>\n",
       "      <td>21,6k</td>\n",
       "      <td>24.953627</td>\n",
       "      <td>18.138274</td>\n",
       "      <td>31.428822</td>\n",
       "      <td>21.809065</td>\n",
       "      <td>28.516281</td>\n",
       "      <td>17.922683</td>\n",
       "      <td>11.856641</td>\n",
       "      <td>4.688094</td>\n",
       "      <td>18.349025</td>\n",
       "      <td>13.056934</td>\n",
       "      <td>23.020879</td>\n",
       "      <td>15.123010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>full</td>\n",
       "      <td>Paraphrase</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>58.477900</td>\n",
       "      <td>48.471935</td>\n",
       "      <td>30.669789</td>\n",
       "      <td>15.662225</td>\n",
       "      <td>37.489917</td>\n",
       "      <td>30.313160</td>\n",
       "      <td>42.212535</td>\n",
       "      <td>31.482440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>full</td>\n",
       "      <td>DLO</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>57.240923</td>\n",
       "      <td>49.406815</td>\n",
       "      <td>32.245319</td>\n",
       "      <td>14.912463</td>\n",
       "      <td>38.142935</td>\n",
       "      <td>33.035522</td>\n",
       "      <td>42.543059</td>\n",
       "      <td>32.451600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   \\# Annotated examples                          Approach  \\\n",
       "0                      0                    [0-shot Gemma]   \n",
       "1                      0  LLMA \\textbackslash w Paraphrase   \n",
       "2                      0         LLMA \\textbackslash w DLO   \n",
       "3                     10                    [k-shot Gemma]   \n",
       "4                     10                        Paraphrase   \n",
       "5                     10                               DLO   \n",
       "6                     10  LLMA \\textbackslash w Paraphrase   \n",
       "7                     10         LLMA \\textbackslash w DLO   \n",
       "8                     10          EDA \\textbackslash w DLO   \n",
       "9                     10                              QAIE   \n",
       "10                    10                               DS2   \n",
       "11                    50                    [k-shot Gemma]   \n",
       "12                    50                        Paraphrase   \n",
       "13                    50                               DLO   \n",
       "14                    50  LLMA \\textbackslash w Paraphrase   \n",
       "15                    50         LLMA \\textbackslash w DLO   \n",
       "16                    50          EDA \\textbackslash w DLO   \n",
       "17                    50                              QAIE   \n",
       "18                    50                               DS2   \n",
       "19                  full                        Paraphrase   \n",
       "20                  full                               DLO   \n",
       "\n",
       "   \\# n_train_column_tasd \\# n_train_column_asqp rest15_tasd_f1_macro  \\\n",
       "0                       0                      0            33.682965   \n",
       "1                    full                   full             22.87668   \n",
       "2                    full                   full            24.121302   \n",
       "3                      10                     10            54.533423   \n",
       "4                      10                     10             3.471115   \n",
       "5                      10                     10             6.095804   \n",
       "6                    full                   full             34.16905   \n",
       "7                    full                   full             35.02917   \n",
       "8                     110                    110            11.326772   \n",
       "9                    26.4                   45.2            14.855063   \n",
       "10                  21,1k                  21,1k            18.825999   \n",
       "11                     50                     50            56.008004   \n",
       "12                     50                     50            19.753549   \n",
       "13                     50                     50            27.775301   \n",
       "14                   full                   full            35.738846   \n",
       "15                   full                   full            41.640356   \n",
       "16                    550                    550            27.351029   \n",
       "17                  141.8                  248.8            44.808635   \n",
       "18                  21,7k                  21,6k            24.953627   \n",
       "19                   full                   full                    -   \n",
       "20                   full                   full                    -   \n",
       "\n",
       "   rest15_asqp_f1_macro rest16_tasd_f1_macro rest16_asqp_f1_macro  \\\n",
       "0             23.639517            45.935407            23.636457   \n",
       "1             19.933547            35.836568            26.201357   \n",
       "2             21.020939            36.116571            29.162906   \n",
       "3             38.667507            64.330219            43.213794   \n",
       "4               0.46161             2.590951             0.872893   \n",
       "5              1.419034             6.012032             1.253818   \n",
       "6             23.983296            48.585244            34.590739   \n",
       "7             26.767017            50.386103            36.245368   \n",
       "8              5.565499             7.940834             2.222501   \n",
       "9              5.373985             7.842294            14.289805   \n",
       "10             12.17129            26.681253             15.59748   \n",
       "11            36.006438            64.813742            44.564631   \n",
       "12            14.048335             16.35104             8.348968   \n",
       "13            18.098542            22.463731            13.051945   \n",
       "14            26.567967            48.337799            31.008575   \n",
       "15            28.421088             49.36667            37.368517   \n",
       "16            17.607299            22.377999            16.124642   \n",
       "17            30.844816            45.498069            32.233524   \n",
       "18            18.138274            31.428822            21.809065   \n",
       "19                    -                    -                    -   \n",
       "20                    -                    -                    -   \n",
       "\n",
       "    flightabsa_tasd_f1_macro  flightabsa_asqp_f1_macro  \\\n",
       "0                  55.239551                 39.500646   \n",
       "1                  45.947851                 33.610097   \n",
       "2                  45.368816                 36.315586   \n",
       "3                  56.321010                 36.583710   \n",
       "4                   2.379838                  1.026658   \n",
       "5                   4.739594                  1.353251   \n",
       "6                  51.195601                 36.292755   \n",
       "7                  53.187757                 39.011394   \n",
       "8                   8.048876                  3.644090   \n",
       "9                  12.018949                  6.998877   \n",
       "10                 22.662025                 13.038150   \n",
       "11                 54.061764                 36.666579   \n",
       "12                 12.431129                  7.227886   \n",
       "13                 28.895840                 19.713303   \n",
       "14                 52.879457                 36.652661   \n",
       "15                 52.168613                 40.875363   \n",
       "16                 33.707157                 24.743871   \n",
       "17                 37.409262                 22.293801   \n",
       "18                 28.516281                 17.922683   \n",
       "19                 58.477900                 48.471935   \n",
       "20                 57.240923                 49.406815   \n",
       "\n",
       "    coursera_tasd_f1_macro  coursera_asqp_f1_macro  hotels_tasd_f1_macro  \\\n",
       "0                33.783261               13.229913             29.696821   \n",
       "1                11.850261                4.087686             16.203254   \n",
       "2                12.100186                3.704135             17.175781   \n",
       "3                41.749528               20.441145             31.154214   \n",
       "4                 2.168499                0.664533              2.645445   \n",
       "5                 3.330280                0.604962              4.098271   \n",
       "6                17.006538                8.536387             26.904822   \n",
       "7                17.136884                9.376324             29.017109   \n",
       "8                 4.218857                2.021759              5.485840   \n",
       "9                 4.300442                1.899235              3.518001   \n",
       "10                9.651657                3.166712             16.974053   \n",
       "11               38.239726               17.803927             35.470040   \n",
       "12                9.586769                2.994512             13.874347   \n",
       "13                8.678341                3.106348             16.495915   \n",
       "14               17.955465                7.365153             28.200947   \n",
       "15               18.074303                8.099663             30.192051   \n",
       "16               12.221974                5.715381             15.849559   \n",
       "17               20.785344               10.203490             24.193516   \n",
       "18               11.856641                4.688094             18.349025   \n",
       "19               30.669789               15.662225             37.489917   \n",
       "20               32.245319               14.912463             38.142935   \n",
       "\n",
       "    hotels_asqp_f1_macro   tasd_avg   asqp_avg  \n",
       "0              18.492406  39.667601  23.699788  \n",
       "1              12.436418  26.542923  19.253821  \n",
       "2              13.104287  26.976531  20.661570  \n",
       "3              18.053876  49.617679  31.392006  \n",
       "4               0.469529   2.651170   0.699045  \n",
       "5               0.827046   4.855196   1.091622  \n",
       "6              19.189234  35.572251  24.518482  \n",
       "7              18.180098  36.951404  25.916040  \n",
       "8               2.272988   7.404236   3.145367  \n",
       "9               2.856744   8.506950   6.283729  \n",
       "10              7.886233  18.958997  10.371973  \n",
       "11             25.243182  49.718655  32.056951  \n",
       "12              7.544793  14.399367   8.032899  \n",
       "13              9.743340  20.861826  12.742696  \n",
       "14             19.788086  36.622503  24.276488  \n",
       "15             22.590836  38.288399  27.471093  \n",
       "16             13.072016  22.301544  15.452642  \n",
       "17             18.509205  34.538965  22.816967  \n",
       "18             13.056934  23.020879  15.123010  \n",
       "19             30.313160  42.212535  31.482440  \n",
       "20             33.035522  42.543059  32.451600  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_out_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e4ced42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA TABLE\n",
    "with open(\"01_muster_tex/ablation_eda.txt\", \"r\") as f:\n",
    "    template = f.read()\n",
    "\n",
    "for metric in [\"f1\"]:\n",
    "    table_out, table_out_raw = create_f1_plot(tasks=[\"tasd\", \"asqp\"], metrics=[metric])\n",
    "    table_out = table_out[table_out[\"Approach\"].str.contains(\"EDA\", na=False)].copy()\n",
    "    table_out_raw = table_out_raw[table_out_raw[\"Approach\"].str.contains(\"EDA\", na=False)].copy()\n",
    "    \n",
    "    table_out = highlight(table_out, start_column=4, end_column=15, groups=[[k for k in range(0, 8)], [k for k in range(9, 16)]], type=\"bold\")\n",
    "    \n",
    "    table_out_list = table_out.iloc[:, 2:].astype(str).values.tolist()\n",
    "    table_out_list = [item for sublist in table_out_list for item in sublist]\n",
    "\n",
    "    table_with_values = template\n",
    "    for i in range(len(table_out_list)):\n",
    "        table_with_values = table_with_values.replace(\"xxxx\", table_out_list[i], 1)\n",
    "    \n",
    "    # Write the final table to a file\n",
    "    with open(f\"_out_table/{metric}_table_eda_ablation.txt\", \"w\") as f_out:\n",
    "        f_out.write(table_with_values)\n",
    "        \n",
    "    # store df table_out_raw as csv\n",
    "    table_out_raw.to_csv(f\"_out_table/{metric}_table_raw_eda_ablation.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
