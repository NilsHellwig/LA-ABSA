{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "99b6dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Add paths for custom modules\n",
    "sys.path.append(os.path.abspath(\"../../zero-shot-absa-quad\"))\n",
    "sys.path.append(os.path.abspath(\"../../zero-shot-absa-quad/plots\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc8d51",
   "metadata": {},
   "source": [
    "* nur 5 bis 10 \n",
    "* gemma umstrukturieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0dd97a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "from performance_helper import compute_f1_scores_quad, compute_scores_single, merge_aspect_lists\n",
    "from table_tool import round_numbers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import itertools\n",
    "# import shutil\n",
    "# import io, re\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6bb6d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEEDS = 5\n",
    "TASKS = [\"tasd\", \"asqp\"]\n",
    "DATASETS = [\"rest15\", \"rest16\", \"flightabsa\", \"coursera\", \"hotels\"]\n",
    "METHODS = [\"paraphrase\", \"dlo\"]\n",
    "AUG_TECHNIQUES = [\"eda\", \"qaie\"]\n",
    "\n",
    "raw_dataset_to_formatted = {\"rest16\": \"Rest16\", \"rest15\": \"Rest15\", \"flightabsa\": \"FlightABSA\", \"coursera\": \"OATS Coursera\", \"hotels\": \"OATS Hotels\"}\n",
    "format_dataset_to_raw = {\"Rest16\": \"rest16\", \"Rest15\": \"rest15\", \"FlightABSA\": \"flightabsa\", \"coursera\": \"OATS Coursera\", \"OATS Hotels\": \"hotels\"}\n",
    "raw_method_to_formatted = {\"paraphrase\": \"Paraphrase\", \"dlo\": \"DLO \\citep{hu2022improving}\"}\n",
    "format_method_to_raw = {\"Paraphrase\": \"paraphrase\", \"DLO \\citep{hu2022improving}\": \"dlo\"}\n",
    "raw_aug_to_formatted = {\"eda\": \"EDA\", \"QAIE\": \"QAIE\", \"llm_annotator\": \"LLM-Annotator\"}\n",
    "format_aug_to_raw = {\"EDA\": \"eda\", \"-\": \"-\", \"LLM-Annotator\": \"llm_annotator\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e504f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_element_scores(loaded_json, task):\n",
    "    labels = loaded_json[\"all_labels\"]\n",
    "    preds = loaded_json[\"all_preds\"]\n",
    "    seed_scores = compute_f1_scores_quad(preds, labels)\n",
    "    seed_scores_ac = compute_scores_single(preds, labels, \"single_ac\")\n",
    "    seed_scores_at = compute_scores_single(preds, labels, \"single_at\")\n",
    "    seed_scores_pol = compute_scores_single(preds, labels, \"single_pol\")\n",
    "\n",
    "    seed_scores[\"ac\"] = seed_scores_ac\n",
    "    seed_scores[\"at\"] = seed_scores_at\n",
    "    seed_scores[\"pol\"] = seed_scores_pol\n",
    "    if task == \"asqp\":\n",
    "        seed_scores_ot = compute_scores_single(preds, labels, \"single_ot\")\n",
    "        seed_scores[\"ot\"] = seed_scores_ot\n",
    "    return seed_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e108dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(scores):\n",
    "    averages = {}\n",
    "    for key in scores[0].keys():\n",
    "        if isinstance(scores[0][key], dict):  # Falls geschachtelte Dicts vorhanden sind\n",
    "            averages[key] = {subkey: np.mean([s[key][subkey] for s in scores]) for subkey in scores[0][key]}\n",
    "        else:\n",
    "            averages[key] = np.mean([s[key] for s in scores])\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6d542179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load LLM-annotated fine-tuned scores\n",
    "scores_llm_ann_train = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for fs in [0, 10, 50]:\n",
    "                for n_ann_ex in [\"full\"]:\n",
    "\n",
    "                    scores = []\n",
    "                    for seed in range(N_SEEDS):\n",
    "                        with open(\n",
    "                            f\"../_out_fine_tunings/01_llm_annotate_train/{method}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                        ) as f:\n",
    "                            loaded_json = json.load(f)\n",
    "                            seed_scores = add_element_scores(loaded_json, task)\n",
    "                            scores.append(seed_scores)\n",
    "                    scores_llm_ann_train[\n",
    "                        f\"{method}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                    ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d08fc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paraphrase_full_tasd_0_rest15', 'paraphrase_full_tasd_10_rest15', 'paraphrase_full_tasd_50_rest15', 'dlo_full_tasd_0_rest15', 'dlo_full_tasd_10_rest15', 'dlo_full_tasd_50_rest15', 'paraphrase_full_asqp_0_rest15', 'paraphrase_full_asqp_10_rest15', 'paraphrase_full_asqp_50_rest15', 'dlo_full_asqp_0_rest15', 'dlo_full_asqp_10_rest15', 'dlo_full_asqp_50_rest15', 'paraphrase_full_tasd_0_rest16', 'paraphrase_full_tasd_10_rest16', 'paraphrase_full_tasd_50_rest16', 'dlo_full_tasd_0_rest16', 'dlo_full_tasd_10_rest16', 'dlo_full_tasd_50_rest16', 'paraphrase_full_asqp_0_rest16', 'paraphrase_full_asqp_10_rest16', 'paraphrase_full_asqp_50_rest16', 'dlo_full_asqp_0_rest16', 'dlo_full_asqp_10_rest16', 'dlo_full_asqp_50_rest16', 'paraphrase_full_tasd_0_flightabsa', 'paraphrase_full_tasd_10_flightabsa', 'paraphrase_full_tasd_50_flightabsa', 'dlo_full_tasd_0_flightabsa', 'dlo_full_tasd_10_flightabsa', 'dlo_full_tasd_50_flightabsa', 'paraphrase_full_asqp_0_flightabsa', 'paraphrase_full_asqp_10_flightabsa', 'paraphrase_full_asqp_50_flightabsa', 'dlo_full_asqp_0_flightabsa', 'dlo_full_asqp_10_flightabsa', 'dlo_full_asqp_50_flightabsa', 'paraphrase_full_tasd_0_coursera', 'paraphrase_full_tasd_10_coursera', 'paraphrase_full_tasd_50_coursera', 'dlo_full_tasd_0_coursera', 'dlo_full_tasd_10_coursera', 'dlo_full_tasd_50_coursera', 'paraphrase_full_asqp_0_coursera', 'paraphrase_full_asqp_10_coursera', 'paraphrase_full_asqp_50_coursera', 'dlo_full_asqp_0_coursera', 'dlo_full_asqp_10_coursera', 'dlo_full_asqp_50_coursera', 'paraphrase_full_tasd_0_hotels', 'paraphrase_full_tasd_10_hotels', 'paraphrase_full_tasd_50_hotels', 'dlo_full_tasd_0_hotels', 'dlo_full_tasd_10_hotels', 'dlo_full_tasd_50_hotels', 'paraphrase_full_asqp_0_hotels', 'paraphrase_full_asqp_10_hotels', 'paraphrase_full_asqp_50_hotels', 'dlo_full_asqp_0_hotels', 'dlo_full_asqp_10_hotels', 'dlo_full_asqp_50_hotels'])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_llm_ann_train.keys(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b3b699c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Augmented fine-tuned scores\n",
    "scores_traditional_aug = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [10, 50]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    path = f\"../../QAIE-ABSA-2025-adaption/03_results/{task}_{dataset}_fs_{fs}_{seed}.json\"\n",
    "\n",
    "                    with open(path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_traditional_aug[\n",
    "                    f\"qaie_{task}_{fs}_{dataset}\"\n",
    "                ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b2130bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for aug in [\"eda\"]:\n",
    "            for method in METHODS:\n",
    "                for fs in [10, 50]:\n",
    "                    for n_ann_ex in [2, 5, 10]:\n",
    "                        scores = []\n",
    "                        for seed in range(N_SEEDS):\n",
    "                            path = f\"../_out_fine_tunings/03_traditional_augmentation/{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                            with open(\n",
    "                                path\n",
    "                            ) as f:\n",
    "                                loaded_json = json.load(f)\n",
    "                                seed_scores = add_element_scores(loaded_json, task)\n",
    "                                scores.append(seed_scores)\n",
    "                        scores_traditional_aug[\n",
    "                            f\"{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                        ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "70bdcef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded past results for paraphrase_full_tasd_rest15_f1: 63.06\n",
      "successfully loaded past results for paraphrase_full_tasd_rest15_precision: -\n",
      "successfully loaded past results for paraphrase_full_tasd_rest15_recall: -\n",
      "successfully loaded past results for dlo_full_tasd_rest15_f1: 62.95\n",
      "successfully loaded past results for dlo_full_tasd_rest15_precision: -\n",
      "successfully loaded past results for dlo_full_tasd_rest15_recall: -\n",
      "successfully loaded past results for paraphrase_full_asqp_rest15_f1: 46.93\n",
      "successfully loaded past results for paraphrase_full_asqp_rest15_precision: 46.16\n",
      "successfully loaded past results for paraphrase_full_asqp_rest15_recall: 47.72\n",
      "successfully loaded past results for dlo_full_asqp_rest15_f1: 48.18\n",
      "successfully loaded past results for dlo_full_asqp_rest15_precision: 47.08\n",
      "successfully loaded past results for dlo_full_asqp_rest15_recall: 49.33\n",
      "successfully loaded past results for paraphrase_full_tasd_rest16_f1: 71.97\n",
      "successfully loaded past results for paraphrase_full_tasd_rest16_precision: -\n",
      "successfully loaded past results for paraphrase_full_tasd_rest16_recall: -\n",
      "successfully loaded past results for dlo_full_tasd_rest16_f1: 71.79\n",
      "successfully loaded past results for dlo_full_tasd_rest16_precision: -\n",
      "successfully loaded past results for dlo_full_tasd_rest16_recall: -\n",
      "successfully loaded past results for paraphrase_full_asqp_rest16_f1: 57.93\n",
      "successfully loaded past results for paraphrase_full_asqp_rest16_precision: 56.63\n",
      "successfully loaded past results for paraphrase_full_asqp_rest16_recall: 59.3\n",
      "successfully loaded past results for dlo_full_asqp_rest16_f1: 59.79\n",
      "successfully loaded past results for dlo_full_asqp_rest16_precision: 57.92\n",
      "successfully loaded past results for dlo_full_asqp_rest16_recall: 61.8\n"
     ]
    }
   ],
   "source": [
    "# 4. Load methods baselines\n",
    "scores_00_baseline = {}\n",
    "\n",
    "with open(\"../../zero-shot-absa-quad/plots/past_results.json\") as f:\n",
    "    past_results = json.load(f)\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for n_ann_ex in [10, 50, \"full\"]:\n",
    "\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    if n_ann_ex == \"full\":\n",
    "                        file_path = f\"../../zero-shot-absa-quad/generations/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}.json\"\n",
    "                    else:\n",
    "                        file_path = f\"../../zero-shot-absa-quad/generations/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}_{n_ann_ex}.json\"\n",
    "                    with open(file_path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_mean = calc_mean(scores)\n",
    "\n",
    "                scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"] = (\n",
    "                    scores_mean\n",
    "                )\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for n_ann_ex in [\"full\"]:\n",
    "                for metric in [\"f1\", \"precision\", \"recall\"]:\n",
    "                    try:\n",
    "                            scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"] = (past_results[task][method][dataset])\n",
    "                            print(\"successfully loaded past results for\",\n",
    "                                  f\"{method}_{n_ann_ex}_{task}_{dataset}_{metric}:\", past_results[task][method][dataset][metric])\n",
    "                    except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "acaf7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load zero-shot scores\n",
    "scores_zeroshot = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 20, 30, 40, 50]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../../zero-shot-absa-quad/generations/zeroshot/{task}_{dataset}_test_gemma3:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "\n",
    "                        scores.append(seed_scores)\n",
    "                scores_zeroshot[f\"{task}_{fs}_{dataset}\"] = calc_mean(scores)\n",
    "\n",
    "# WITH SELF-Consistency\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 20, 30, 40, 50]:\n",
    "                all_example_data = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../../zero-shot-absa-quad/generations/zeroshot/{task}_{dataset}_test_gemma3:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        all_example_data.append(loaded_json)\n",
    "\n",
    "                all_labels = all_example_data[0][\"all_labels\"]\n",
    "                all_preds = [[] for _ in range(len(all_labels))]\n",
    "                for seed in range(0, N_SEEDS):\n",
    "                    for idx in range(len(all_labels)):\n",
    "                        all_preds[idx].append(all_example_data[seed][\"all_preds\"][idx])\n",
    "                        if seed == N_SEEDS - 1:\n",
    "                            all_preds[idx] = merge_aspect_lists(all_preds[idx])\n",
    "                            all_preds[idx] = [list(p) for p in all_preds[idx]]\n",
    "\n",
    "                loaded_json = {\n",
    "                    \"all_preds\": all_preds,\n",
    "                    \"all_labels\": all_labels,\n",
    "                }\n",
    "\n",
    "                scores = add_element_scores(loaded_json, task)\n",
    "                scores_zeroshot[f\"{task}_{fs}_{dataset}_sc\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aca7989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_train_qaie(task=\"tasd\", dataset=\"rest16\", fs=2):\n",
    "    path = f\"../../QAIE-ABSA-2025-adaption/01_augmentations/fs_examples/{task}/{dataset}/fs_{fs}/aug.txt\"\n",
    "    # count number of lines in the file\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        n_train = len(lines)\n",
    "    return n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "72668d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tasd_0_rest15', 'tasd_10_rest15', 'tasd_20_rest15', 'tasd_30_rest15', 'tasd_40_rest15', 'tasd_50_rest15', 'asqp_0_rest15', 'asqp_10_rest15', 'asqp_20_rest15', 'asqp_30_rest15', 'asqp_40_rest15', 'asqp_50_rest15', 'tasd_0_rest16', 'tasd_10_rest16', 'tasd_20_rest16', 'tasd_30_rest16', 'tasd_40_rest16', 'tasd_50_rest16', 'asqp_0_rest16', 'asqp_10_rest16', 'asqp_20_rest16', 'asqp_30_rest16', 'asqp_40_rest16', 'asqp_50_rest16', 'tasd_0_flightabsa', 'tasd_10_flightabsa', 'tasd_20_flightabsa', 'tasd_30_flightabsa', 'tasd_40_flightabsa', 'tasd_50_flightabsa', 'asqp_0_flightabsa', 'asqp_10_flightabsa', 'asqp_20_flightabsa', 'asqp_30_flightabsa', 'asqp_40_flightabsa', 'asqp_50_flightabsa', 'tasd_0_coursera', 'tasd_10_coursera', 'tasd_20_coursera', 'tasd_30_coursera', 'tasd_40_coursera', 'tasd_50_coursera', 'asqp_0_coursera', 'asqp_10_coursera', 'asqp_20_coursera', 'asqp_30_coursera', 'asqp_40_coursera', 'asqp_50_coursera', 'tasd_0_hotels', 'tasd_10_hotels', 'tasd_20_hotels', 'tasd_30_hotels', 'tasd_40_hotels', 'tasd_50_hotels', 'asqp_0_hotels', 'asqp_10_hotels', 'asqp_20_hotels', 'asqp_30_hotels', 'asqp_40_hotels', 'asqp_50_hotels', 'tasd_0_rest15_sc', 'tasd_10_rest15_sc', 'tasd_20_rest15_sc', 'tasd_30_rest15_sc', 'tasd_40_rest15_sc', 'tasd_50_rest15_sc', 'asqp_0_rest15_sc', 'asqp_10_rest15_sc', 'asqp_20_rest15_sc', 'asqp_30_rest15_sc', 'asqp_40_rest15_sc', 'asqp_50_rest15_sc', 'tasd_0_rest16_sc', 'tasd_10_rest16_sc', 'tasd_20_rest16_sc', 'tasd_30_rest16_sc', 'tasd_40_rest16_sc', 'tasd_50_rest16_sc', 'asqp_0_rest16_sc', 'asqp_10_rest16_sc', 'asqp_20_rest16_sc', 'asqp_30_rest16_sc', 'asqp_40_rest16_sc', 'asqp_50_rest16_sc', 'tasd_0_flightabsa_sc', 'tasd_10_flightabsa_sc', 'tasd_20_flightabsa_sc', 'tasd_30_flightabsa_sc', 'tasd_40_flightabsa_sc', 'tasd_50_flightabsa_sc', 'asqp_0_flightabsa_sc', 'asqp_10_flightabsa_sc', 'asqp_20_flightabsa_sc', 'asqp_30_flightabsa_sc', 'asqp_40_flightabsa_sc', 'asqp_50_flightabsa_sc', 'tasd_0_coursera_sc', 'tasd_10_coursera_sc', 'tasd_20_coursera_sc', 'tasd_30_coursera_sc', 'tasd_40_coursera_sc', 'tasd_50_coursera_sc', 'asqp_0_coursera_sc', 'asqp_10_coursera_sc', 'asqp_20_coursera_sc', 'asqp_30_coursera_sc', 'asqp_40_coursera_sc', 'asqp_50_coursera_sc', 'tasd_0_hotels_sc', 'tasd_10_hotels_sc', 'tasd_20_hotels_sc', 'tasd_30_hotels_sc', 'tasd_40_hotels_sc', 'tasd_50_hotels_sc', 'asqp_0_hotels_sc', 'asqp_10_hotels_sc', 'asqp_20_hotels_sc', 'asqp_30_hotels_sc', 'asqp_40_hotels_sc', 'asqp_50_hotels_sc'])\n",
      "dict_keys(['paraphrase_10_tasd_rest15', 'paraphrase_50_tasd_rest15', 'paraphrase_full_tasd_rest15', 'dlo_10_tasd_rest15', 'dlo_50_tasd_rest15', 'dlo_full_tasd_rest15', 'paraphrase_10_asqp_rest15', 'paraphrase_50_asqp_rest15', 'paraphrase_full_asqp_rest15', 'dlo_10_asqp_rest15', 'dlo_50_asqp_rest15', 'dlo_full_asqp_rest15', 'paraphrase_10_tasd_rest16', 'paraphrase_50_tasd_rest16', 'paraphrase_full_tasd_rest16', 'dlo_10_tasd_rest16', 'dlo_50_tasd_rest16', 'dlo_full_tasd_rest16', 'paraphrase_10_asqp_rest16', 'paraphrase_50_asqp_rest16', 'paraphrase_full_asqp_rest16', 'dlo_10_asqp_rest16', 'dlo_50_asqp_rest16', 'dlo_full_asqp_rest16', 'paraphrase_10_tasd_flightabsa', 'paraphrase_50_tasd_flightabsa', 'paraphrase_full_tasd_flightabsa', 'dlo_10_tasd_flightabsa', 'dlo_50_tasd_flightabsa', 'dlo_full_tasd_flightabsa', 'paraphrase_10_asqp_flightabsa', 'paraphrase_50_asqp_flightabsa', 'paraphrase_full_asqp_flightabsa', 'dlo_10_asqp_flightabsa', 'dlo_50_asqp_flightabsa', 'dlo_full_asqp_flightabsa', 'paraphrase_10_tasd_coursera', 'paraphrase_50_tasd_coursera', 'paraphrase_full_tasd_coursera', 'dlo_10_tasd_coursera', 'dlo_50_tasd_coursera', 'dlo_full_tasd_coursera', 'paraphrase_10_asqp_coursera', 'paraphrase_50_asqp_coursera', 'paraphrase_full_asqp_coursera', 'dlo_10_asqp_coursera', 'dlo_50_asqp_coursera', 'dlo_full_asqp_coursera', 'paraphrase_10_tasd_hotels', 'paraphrase_50_tasd_hotels', 'paraphrase_full_tasd_hotels', 'dlo_10_tasd_hotels', 'dlo_50_tasd_hotels', 'dlo_full_tasd_hotels', 'paraphrase_10_asqp_hotels', 'paraphrase_50_asqp_hotels', 'paraphrase_full_asqp_hotels', 'dlo_10_asqp_hotels', 'dlo_50_asqp_hotels', 'dlo_full_asqp_hotels'])\n",
      "dict_keys(['paraphrase_full_tasd_0_rest15', 'paraphrase_full_tasd_10_rest15', 'paraphrase_full_tasd_50_rest15', 'dlo_full_tasd_0_rest15', 'dlo_full_tasd_10_rest15', 'dlo_full_tasd_50_rest15', 'paraphrase_full_asqp_0_rest15', 'paraphrase_full_asqp_10_rest15', 'paraphrase_full_asqp_50_rest15', 'dlo_full_asqp_0_rest15', 'dlo_full_asqp_10_rest15', 'dlo_full_asqp_50_rest15', 'paraphrase_full_tasd_0_rest16', 'paraphrase_full_tasd_10_rest16', 'paraphrase_full_tasd_50_rest16', 'dlo_full_tasd_0_rest16', 'dlo_full_tasd_10_rest16', 'dlo_full_tasd_50_rest16', 'paraphrase_full_asqp_0_rest16', 'paraphrase_full_asqp_10_rest16', 'paraphrase_full_asqp_50_rest16', 'dlo_full_asqp_0_rest16', 'dlo_full_asqp_10_rest16', 'dlo_full_asqp_50_rest16', 'paraphrase_full_tasd_0_flightabsa', 'paraphrase_full_tasd_10_flightabsa', 'paraphrase_full_tasd_50_flightabsa', 'dlo_full_tasd_0_flightabsa', 'dlo_full_tasd_10_flightabsa', 'dlo_full_tasd_50_flightabsa', 'paraphrase_full_asqp_0_flightabsa', 'paraphrase_full_asqp_10_flightabsa', 'paraphrase_full_asqp_50_flightabsa', 'dlo_full_asqp_0_flightabsa', 'dlo_full_asqp_10_flightabsa', 'dlo_full_asqp_50_flightabsa', 'paraphrase_full_tasd_0_coursera', 'paraphrase_full_tasd_10_coursera', 'paraphrase_full_tasd_50_coursera', 'dlo_full_tasd_0_coursera', 'dlo_full_tasd_10_coursera', 'dlo_full_tasd_50_coursera', 'paraphrase_full_asqp_0_coursera', 'paraphrase_full_asqp_10_coursera', 'paraphrase_full_asqp_50_coursera', 'dlo_full_asqp_0_coursera', 'dlo_full_asqp_10_coursera', 'dlo_full_asqp_50_coursera', 'paraphrase_full_tasd_0_hotels', 'paraphrase_full_tasd_10_hotels', 'paraphrase_full_tasd_50_hotels', 'dlo_full_tasd_0_hotels', 'dlo_full_tasd_10_hotels', 'dlo_full_tasd_50_hotels', 'paraphrase_full_asqp_0_hotels', 'paraphrase_full_asqp_10_hotels', 'paraphrase_full_asqp_50_hotels', 'dlo_full_asqp_0_hotels', 'dlo_full_asqp_10_hotels', 'dlo_full_asqp_50_hotels'])\n",
      "dict_keys(['qaie_tasd_10_rest15', 'qaie_tasd_50_rest15', 'qaie_asqp_10_rest15', 'qaie_asqp_50_rest15', 'qaie_tasd_10_rest16', 'qaie_tasd_50_rest16', 'qaie_asqp_10_rest16', 'qaie_asqp_50_rest16', 'qaie_tasd_10_flightabsa', 'qaie_tasd_50_flightabsa', 'qaie_asqp_10_flightabsa', 'qaie_asqp_50_flightabsa', 'qaie_tasd_10_coursera', 'qaie_tasd_50_coursera', 'qaie_asqp_10_coursera', 'qaie_asqp_50_coursera', 'qaie_tasd_10_hotels', 'qaie_tasd_50_hotels', 'qaie_asqp_10_hotels', 'qaie_asqp_50_hotels', 'paraphrase_eda_2_tasd_10_rest15', 'paraphrase_eda_5_tasd_10_rest15', 'paraphrase_eda_10_tasd_10_rest15', 'paraphrase_eda_2_tasd_50_rest15', 'paraphrase_eda_5_tasd_50_rest15', 'paraphrase_eda_10_tasd_50_rest15', 'dlo_eda_2_tasd_10_rest15', 'dlo_eda_5_tasd_10_rest15', 'dlo_eda_10_tasd_10_rest15', 'dlo_eda_2_tasd_50_rest15', 'dlo_eda_5_tasd_50_rest15', 'dlo_eda_10_tasd_50_rest15', 'paraphrase_eda_2_asqp_10_rest15', 'paraphrase_eda_5_asqp_10_rest15', 'paraphrase_eda_10_asqp_10_rest15', 'paraphrase_eda_2_asqp_50_rest15', 'paraphrase_eda_5_asqp_50_rest15', 'paraphrase_eda_10_asqp_50_rest15', 'dlo_eda_2_asqp_10_rest15', 'dlo_eda_5_asqp_10_rest15', 'dlo_eda_10_asqp_10_rest15', 'dlo_eda_2_asqp_50_rest15', 'dlo_eda_5_asqp_50_rest15', 'dlo_eda_10_asqp_50_rest15', 'paraphrase_eda_2_tasd_10_rest16', 'paraphrase_eda_5_tasd_10_rest16', 'paraphrase_eda_10_tasd_10_rest16', 'paraphrase_eda_2_tasd_50_rest16', 'paraphrase_eda_5_tasd_50_rest16', 'paraphrase_eda_10_tasd_50_rest16', 'dlo_eda_2_tasd_10_rest16', 'dlo_eda_5_tasd_10_rest16', 'dlo_eda_10_tasd_10_rest16', 'dlo_eda_2_tasd_50_rest16', 'dlo_eda_5_tasd_50_rest16', 'dlo_eda_10_tasd_50_rest16', 'paraphrase_eda_2_asqp_10_rest16', 'paraphrase_eda_5_asqp_10_rest16', 'paraphrase_eda_10_asqp_10_rest16', 'paraphrase_eda_2_asqp_50_rest16', 'paraphrase_eda_5_asqp_50_rest16', 'paraphrase_eda_10_asqp_50_rest16', 'dlo_eda_2_asqp_10_rest16', 'dlo_eda_5_asqp_10_rest16', 'dlo_eda_10_asqp_10_rest16', 'dlo_eda_2_asqp_50_rest16', 'dlo_eda_5_asqp_50_rest16', 'dlo_eda_10_asqp_50_rest16', 'paraphrase_eda_2_tasd_10_flightabsa', 'paraphrase_eda_5_tasd_10_flightabsa', 'paraphrase_eda_10_tasd_10_flightabsa', 'paraphrase_eda_2_tasd_50_flightabsa', 'paraphrase_eda_5_tasd_50_flightabsa', 'paraphrase_eda_10_tasd_50_flightabsa', 'dlo_eda_2_tasd_10_flightabsa', 'dlo_eda_5_tasd_10_flightabsa', 'dlo_eda_10_tasd_10_flightabsa', 'dlo_eda_2_tasd_50_flightabsa', 'dlo_eda_5_tasd_50_flightabsa', 'dlo_eda_10_tasd_50_flightabsa', 'paraphrase_eda_2_asqp_10_flightabsa', 'paraphrase_eda_5_asqp_10_flightabsa', 'paraphrase_eda_10_asqp_10_flightabsa', 'paraphrase_eda_2_asqp_50_flightabsa', 'paraphrase_eda_5_asqp_50_flightabsa', 'paraphrase_eda_10_asqp_50_flightabsa', 'dlo_eda_2_asqp_10_flightabsa', 'dlo_eda_5_asqp_10_flightabsa', 'dlo_eda_10_asqp_10_flightabsa', 'dlo_eda_2_asqp_50_flightabsa', 'dlo_eda_5_asqp_50_flightabsa', 'dlo_eda_10_asqp_50_flightabsa', 'paraphrase_eda_2_tasd_10_coursera', 'paraphrase_eda_5_tasd_10_coursera', 'paraphrase_eda_10_tasd_10_coursera', 'paraphrase_eda_2_tasd_50_coursera', 'paraphrase_eda_5_tasd_50_coursera', 'paraphrase_eda_10_tasd_50_coursera', 'dlo_eda_2_tasd_10_coursera', 'dlo_eda_5_tasd_10_coursera', 'dlo_eda_10_tasd_10_coursera', 'dlo_eda_2_tasd_50_coursera', 'dlo_eda_5_tasd_50_coursera', 'dlo_eda_10_tasd_50_coursera', 'paraphrase_eda_2_asqp_10_coursera', 'paraphrase_eda_5_asqp_10_coursera', 'paraphrase_eda_10_asqp_10_coursera', 'paraphrase_eda_2_asqp_50_coursera', 'paraphrase_eda_5_asqp_50_coursera', 'paraphrase_eda_10_asqp_50_coursera', 'dlo_eda_2_asqp_10_coursera', 'dlo_eda_5_asqp_10_coursera', 'dlo_eda_10_asqp_10_coursera', 'dlo_eda_2_asqp_50_coursera', 'dlo_eda_5_asqp_50_coursera', 'dlo_eda_10_asqp_50_coursera', 'paraphrase_eda_2_tasd_10_hotels', 'paraphrase_eda_5_tasd_10_hotels', 'paraphrase_eda_10_tasd_10_hotels', 'paraphrase_eda_2_tasd_50_hotels', 'paraphrase_eda_5_tasd_50_hotels', 'paraphrase_eda_10_tasd_50_hotels', 'dlo_eda_2_tasd_10_hotels', 'dlo_eda_5_tasd_10_hotels', 'dlo_eda_10_tasd_10_hotels', 'dlo_eda_2_tasd_50_hotels', 'dlo_eda_5_tasd_50_hotels', 'dlo_eda_10_tasd_50_hotels', 'paraphrase_eda_2_asqp_10_hotels', 'paraphrase_eda_5_asqp_10_hotels', 'paraphrase_eda_10_asqp_10_hotels', 'paraphrase_eda_2_asqp_50_hotels', 'paraphrase_eda_5_asqp_50_hotels', 'paraphrase_eda_10_asqp_50_hotels', 'dlo_eda_2_asqp_10_hotels', 'dlo_eda_5_asqp_10_hotels', 'dlo_eda_10_asqp_10_hotels', 'dlo_eda_2_asqp_50_hotels', 'dlo_eda_5_asqp_50_hotels', 'dlo_eda_10_asqp_50_hotels'])\n"
     ]
    }
   ],
   "source": [
    "print(scores_zeroshot.keys())\n",
    "print(scores_00_baseline.keys())\n",
    "print(scores_llm_ann_train.keys())\n",
    "print(scores_traditional_aug.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9cf4baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FT_APPROACHES = [\"Paraphrase\", \"DLO\"]\n",
    "FT_ENCODING = {\"Paraphrase\": \"paraphrase\", \"DLO\": \"dlo\"}\n",
    "FT_ENCODING_REVERSE = {v: k for k, v in FT_ENCODING.items()}\n",
    "\n",
    "N_TRAIN_EDA = [2, 5, 10]\n",
    "N_SHOTS = [10, 50]\n",
    "\n",
    "def get_mean_n_train(task, fs):\n",
    "    \"\"\"Calculate mean n_train across datasets for a given task and fs.\"\"\"\n",
    "    return str(np.round(np.mean([\n",
    "        get_n_train_qaie(task=task, dataset=ds, fs=fs) \n",
    "        for ds in DATASETS\n",
    "    ]), 1))\n",
    "\n",
    "def create_columns():\n",
    "    \"\"\"Create all column data for the DataFrame.\"\"\"\n",
    "    # Base pattern for one shot value\n",
    "    base_pattern_size = len(FT_APPROACHES) * 2 + len(N_TRAIN_EDA) * len(FT_APPROACHES) + 1\n",
    "    \n",
    "    # Annotated examples column\n",
    "    n_annotated = ([0] * 3 + \n",
    "                  [10] * (1 + base_pattern_size) + \n",
    "                  [50] * (1 + base_pattern_size) + \n",
    "                  [\"full\"] * len(FT_APPROACHES))\n",
    "    \n",
    "    # Approaches column - base pattern\n",
    "    base_approaches = ([[\"k-shot Gemma\"]] + FT_APPROACHES + \n",
    "                      [f\"LLMA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES] +\n",
    "                      [f\"EDA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES for _ in N_TRAIN_EDA] +\n",
    "                      [\"QAIE\"])\n",
    "    \n",
    "    approaches = ([[\"0-shot Gemma\"]]+[f\"LLMA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES] +\n",
    "                 base_approaches * 2 +  # For 10 and 50 shots\n",
    "                 FT_APPROACHES )\n",
    "    \n",
    "    # Training columns\n",
    "    def build_train_column(task):\n",
    "        column = [\"0\", \"full\", \"full\"] \n",
    "        for fs in N_SHOTS:\n",
    "            column.extend([fs,\n",
    "                *([fs] * len(FT_APPROACHES)),\n",
    "                *([\"full\"] * len(FT_APPROACHES)),\n",
    "                *([fs + n * fs for _ in FT_APPROACHES for n in N_TRAIN_EDA]),\n",
    "                get_mean_n_train(task, fs)\n",
    "            ])\n",
    "        column.extend([\"full\"] * len(FT_APPROACHES))\n",
    "        return column\n",
    "    \n",
    "    return n_annotated, approaches, build_train_column(\"tasd\"), build_train_column(\"asqp\")\n",
    "\n",
    "def collect_performance_scores(tasks, metrics):\n",
    "    \"\"\"Collect all performance scores from different score dictionaries.\"\"\"\n",
    "    scores = {dataset: {task: {metric: [] for metric in metrics} for task in tasks} \n",
    "              for dataset in DATASETS}\n",
    "    \n",
    "    for dataset in DATASETS:\n",
    "        for task in tasks:\n",
    "            for metric in metrics:\n",
    "                task_scores = scores[dataset][task][metric]\n",
    "\n",
    "                task_scores.extend([\n",
    "                    scores_zeroshot[f\"{task}_{fs}_{dataset}_sc\"][metric]\n",
    "                    for fs in [0]\n",
    "                ])\n",
    "                \n",
    "                # Zero-shot scores\n",
    "                task_scores.extend([\n",
    "                    scores_llm_ann_train[f\"{method}_full_{task}_0_{dataset}\"][metric]\n",
    "                    for method in METHODS\n",
    "                ])\n",
    "                \n",
    "                # Few-shot scores (10, 50)\n",
    "                for fs in N_SHOTS:\n",
    "                    # Baseline scores\n",
    "\n",
    "                    task_scores.extend([\n",
    "                      scores_zeroshot[f\"{task}_{k}_{dataset}_sc\"][metric]\n",
    "                      for k in [fs]\n",
    "                    ])\n",
    "                \n",
    "                    task_scores.extend([\n",
    "                        scores_00_baseline[f\"{method}_{fs}_{task}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                    ])\n",
    "                    \n",
    "                    # LLM annotation scores\n",
    "                    task_scores.extend([\n",
    "                        scores_llm_ann_train[f\"{method}_full_{task}_{fs}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                    ])\n",
    "                    \n",
    "                    # Traditional augmentation scores\n",
    "                    task_scores.extend([\n",
    "                        scores_traditional_aug[f\"{method}_eda_{n_train}_{task}_{fs}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                        for n_train in N_TRAIN_EDA\n",
    "                    ])\n",
    "                    \n",
    "                    # QAIE scores\n",
    "                    task_scores.append(\n",
    "                        scores_traditional_aug[f\"qaie_{task}_{fs}_{dataset}\"][metric]\n",
    "                    )\n",
    "                \n",
    "                # Full training scores\n",
    "                task_scores.extend([\n",
    "                    scores_00_baseline[f\"{method}_full_{task}_{dataset}\"][metric]\n",
    "                    for method in METHODS\n",
    "                ])\n",
    "            \n",
    "    \n",
    "    return scores\n",
    "\n",
    "def create_f1_plot_with_avg(table_out):\n",
    "    tasd_columns = [col for col in table_out.columns if \"tasd\" in col and col != \"\\\\# n_train_column_tasd\"]\n",
    "    asqp_columns = [col for col in table_out.columns if \"asqp\" in col and col != \"\\\\# n_train_column_asqp\"]\n",
    "    \n",
    "    # Für tasd: \"-\" ignorieren, ohne Originalwerte zu überschreiben\n",
    "    tasd_numeric = table_out[tasd_columns].apply(\n",
    "        lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "    )\n",
    "    tasd_avg = tasd_numeric.mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Für asqp: \"-\" ignorieren, ohne Originalwerte zu überschreiben\n",
    "    asqp_numeric = table_out[asqp_columns].apply(\n",
    "        lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "    )\n",
    "    asqp_avg = asqp_numeric.mean(axis=1, skipna=True)\n",
    "    \n",
    "    table_out[\"tasd_avg\"] = tasd_avg\n",
    "    table_out[\"asqp_avg\"] = asqp_avg\n",
    "    return table_out\n",
    "\n",
    "\n",
    "def create_f1_plot(tasks=[\"tasd\"], metrics=[\"f1\"]):\n",
    "    \"\"\"Create F1 plot DataFrame with simplified logic.\"\"\"\n",
    "    \n",
    "    # Get all column data\n",
    "    n_annotated, approaches, n_train_tasd, n_train_asqp = create_columns()\n",
    "    \n",
    "    # Collect performance scores\n",
    "    performance_scores = collect_performance_scores(tasks, metrics)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_data = {\n",
    "        \"\\# Annotated examples\": n_annotated,\n",
    "        \"Approach\": approaches,\n",
    "        \"\\# n_train_column_tasd\": n_train_tasd,\n",
    "        \"\\# n_train_column_asqp\": n_train_asqp,\n",
    "    }\n",
    "    \n",
    "    # Add performance columns\n",
    "    for dataset in DATASETS:\n",
    "        for task in tasks:\n",
    "            for metric in metrics:\n",
    "                df_data[f\"{dataset}_{task}_{metric}\"] = performance_scores[dataset][task][metric]\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    \n",
    "    # Round numbers in performance columns\n",
    "    performance_columns = [f\"{dataset}_{task}_{metric}\" \n",
    "                          for dataset in DATASETS \n",
    "                          for task in tasks \n",
    "                          for metric in metrics]\n",
    "    \n",
    "    performance_columns += [\"tasd_avg\", \"asqp_avg\"]\n",
    "    \n",
    "    df = create_f1_plot_with_avg(df)\n",
    "    df_raw = df.copy()\n",
    "    df = round_numbers(df, performance_columns, n_rest=2)\n",
    "\n",
    "    return df, df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6f6a136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def extract_raw_value(formatted_value):\n",
    "    if pd.isna(formatted_value):\n",
    "        return formatted_value\n",
    "    \n",
    "    value_str = str(formatted_value)\n",
    "    \n",
    "    # Entferne alle LaTeX-Formatierungen\n",
    "    # Muster für \\textbf{...}, \\underline{...} und verschachtelte Kombinationen\n",
    "    clean_value = value_str\n",
    "    \n",
    "    # Iterativ alle Formatierungen entfernen\n",
    "    while True:\n",
    "        old_value = clean_value\n",
    "        # Entferne \\textbf{...}\n",
    "        clean_value = re.sub(r'\\\\textbf\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}', r'\\1', clean_value)\n",
    "        # Entferne \\underline{...}\n",
    "        clean_value = re.sub(r'\\\\underline\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}', r'\\1', clean_value)\n",
    "        \n",
    "        if clean_value == old_value:\n",
    "            break\n",
    "    \n",
    "    return clean_value\n",
    "\n",
    "def apply_formatting(value, bold=False, underline=False):\n",
    "    result = str(value)\n",
    "    \n",
    "    if underline:\n",
    "        result = f\"\\\\underline{{{result}}}\"\n",
    "    if bold:\n",
    "        result = f\"\\\\textbf{{{result}}}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_current_formatting(formatted_value):\n",
    "    if pd.isna(formatted_value):\n",
    "        return False, False\n",
    "    \n",
    "    value_str = str(formatted_value)\n",
    "    is_bold = '\\\\textbf{' in value_str\n",
    "    is_underlined = '\\\\underline{' in value_str\n",
    "    \n",
    "    return is_bold, is_underlined\n",
    "\n",
    "def highlight(df, start_column, end_column, groups, type=\"underline\"):\n",
    "    # Kopie des DataFrames erstellen\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Formatierungsoptionen bestimmen\n",
    "    if type == \"both\" or (isinstance(type, list) and \"bold\" in type and \"underline\" in type):\n",
    "        apply_bold = True\n",
    "        apply_underline = True\n",
    "    elif type == \"bold\" or (isinstance(type, list) and \"bold\" in type):\n",
    "        apply_bold = True\n",
    "        apply_underline = False\n",
    "    elif type == \"underline\" or (isinstance(type, list) and \"underline\" in type):\n",
    "        apply_bold = False\n",
    "        apply_underline = True\n",
    "    else:\n",
    "        apply_bold = False\n",
    "        apply_underline = True  # Default\n",
    "    \n",
    "    # Durch alle betroffenen Spalten iterieren\n",
    "    for col_idx in range(start_column, end_column + 1):\n",
    "        col_name = df.columns[col_idx]\n",
    "        \n",
    "        # Durch alle Gruppen iterieren\n",
    "        for group in groups:\n",
    "            # Werte der aktuellen Gruppe in der aktuellen Spalte\n",
    "            group_series = df.iloc[group, col_idx]\n",
    "            \n",
    "            # Rohe Werte extrahieren für numerischen Vergleich\n",
    "            raw_values = []\n",
    "            for idx in group:\n",
    "                raw_val = extract_raw_value(df.iloc[idx, col_idx])\n",
    "                raw_values.append(raw_val)\n",
    "            \n",
    "            # Versuche, die rohen Werte in float zu konvertieren\n",
    "            numeric_values = pd.to_numeric(raw_values, errors='coerce')\n",
    "            \n",
    "            # remove values from numpy array numeric_values that are not numeric\n",
    "            numeric_values = [val for val in numeric_values if not pd.isna(val)]\n",
    "            \n",
    "            try:\n",
    "              max_value = max(numeric_values)\n",
    "            except ValueError:\n",
    "              max_value = None\n",
    "                \n",
    "            # Finde alle Indizes mit dem Maximalwert\n",
    "            for i, (idx, raw_val, numeric_val) in enumerate(zip(group, raw_values, numeric_values)):\n",
    "                    if numeric_val == max_value:\n",
    "                        # Aktuelle Formatierung ermitteln\n",
    "                        current_value = result_df.iloc[idx, col_idx]\n",
    "                        is_bold, is_underlined = get_current_formatting(current_value)\n",
    "                        \n",
    "                        # Neue Formatierung bestimmen\n",
    "                        new_bold = is_bold or apply_bold\n",
    "                        new_underline = is_underlined or apply_underline\n",
    "                        \n",
    "                        # Rohen Wert extrahieren und neue Formatierung anwenden\n",
    "                        raw_value = extract_raw_value(current_value)\n",
    "                        formatted_value = apply_formatting(raw_value, bold=new_bold, underline=new_underline)\n",
    "                        \n",
    "                        result_df.iloc[idx, col_idx] = formatted_value\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cfb9ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file in 01_muster_tex/performance.txt\n",
    "with open(\"01_muster_tex/performance.txt\", \"r\") as f:\n",
    "    template = f.read()\n",
    "\n",
    "for metric in [\"f1\", \"precision\", \"recall\"]:\n",
    "    table_out, table_out_raw = create_f1_plot(tasks=[\"tasd\", \"asqp\"], metrics=[metric])\n",
    "    \n",
    "    table_out = highlight(table_out, start_column=4, end_column=15, groups=[[0, 1, 2], [k for k in range(3, 15)], [k for k in range(15, 26)], [27, 28]], type=\"bold\")\n",
    "    table_out = highlight(table_out, start_column=4, end_column=15, groups=[[i for i in range(0, 29)]], type=\"underline\")\n",
    "    \n",
    "    table_out_list = table_out.iloc[:, 2:].astype(str).values.tolist()\n",
    "    table_out_list = [item for sublist in table_out_list for item in sublist]\n",
    "\n",
    "    table_with_values = template\n",
    "    for i in range(len(table_out_list)):\n",
    "        table_with_values = table_with_values.replace(\"xxxx\", table_out_list[i], 1)\n",
    "    \n",
    "    # Write the final table to a file\n",
    "    with open(f\"_out_table/{metric}_table.txt\", \"w\") as f_out:\n",
    "        f_out.write(table_with_values)\n",
    "        \n",
    "    # store df table_out_raw as csv\n",
    "    table_out_raw.to_csv(f\"_out_table/{metric}_table_raw.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
