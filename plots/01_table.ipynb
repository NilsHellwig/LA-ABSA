{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "99b6dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Add paths for custom modules\n",
    "sys.path.append(os.path.abspath(\"../../zero-shot-absa-quad\"))\n",
    "sys.path.append(os.path.abspath(\"../../zero-shot-absa-quad/plots\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc8d51",
   "metadata": {},
   "source": [
    "* nur 5 bis 10 \n",
    "* gemma umstrukturieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0dd97a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "from performance_helper import compute_f1_scores_quad, compute_scores_single, merge_aspect_lists\n",
    "from table_tool import round_numbers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import itertools\n",
    "# import shutil\n",
    "# import io, re\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6bb6d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEEDS = 5\n",
    "TASKS = [\"tasd\", \"asqp\"]\n",
    "DATASETS = [\"rest15\", \"rest16\", \"flightabsa\", \"coursera\", \"hotels\"]\n",
    "METHODS = [\"paraphrase\", \"dlo\"]\n",
    "AUG_TECHNIQUES = [\"eda\", \"qaie\"]\n",
    "\n",
    "raw_dataset_to_formatted = {\"rest16\": \"Rest16\", \"rest15\": \"Rest15\", \"flightabsa\": \"FlightABSA\", \"coursera\": \"OATS Coursera\", \"hotels\": \"OATS Hotels\"}\n",
    "format_dataset_to_raw = {\"Rest16\": \"rest16\", \"Rest15\": \"rest15\", \"FlightABSA\": \"flightabsa\", \"coursera\": \"OATS Coursera\", \"OATS Hotels\": \"hotels\"}\n",
    "raw_method_to_formatted = {\"paraphrase\": \"Paraphrase\", \"dlo\": \"DLO \\citep{hu2022improving}\"}\n",
    "format_method_to_raw = {\"Paraphrase\": \"paraphrase\", \"DLO \\citep{hu2022improving}\": \"dlo\"}\n",
    "raw_aug_to_formatted = {\"eda\": \"EDA\", \"QAIE\": \"QAIE\", \"llm_annotator\": \"LLM-Annotator\"}\n",
    "format_aug_to_raw = {\"EDA\": \"eda\", \"-\": \"-\", \"LLM-Annotator\": \"llm_annotator\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e504f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_element_scores(loaded_json, task):\n",
    "    labels = loaded_json[\"all_labels\"]\n",
    "    preds = loaded_json[\"all_preds\"]\n",
    "    seed_scores = compute_f1_scores_quad(preds, labels)\n",
    "    seed_scores_ac = compute_scores_single(preds, labels, \"single_ac\")\n",
    "    seed_scores_at = compute_scores_single(preds, labels, \"single_at\")\n",
    "    seed_scores_pol = compute_scores_single(preds, labels, \"single_pol\")\n",
    "\n",
    "    seed_scores[\"ac\"] = seed_scores_ac\n",
    "    seed_scores[\"at\"] = seed_scores_at\n",
    "    seed_scores[\"pol\"] = seed_scores_pol\n",
    "    if task == \"asqp\":\n",
    "        seed_scores_ot = compute_scores_single(preds, labels, \"single_ot\")\n",
    "        seed_scores[\"ot\"] = seed_scores_ot\n",
    "    return seed_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e108dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(scores):\n",
    "    averages = {}\n",
    "    for key in scores[0].keys():\n",
    "        if isinstance(scores[0][key], dict):  # Falls geschachtelte Dicts vorhanden sind\n",
    "            averages[key] = {subkey: np.mean([s[key][subkey] for s in scores]) for subkey in scores[0][key]}\n",
    "        else:\n",
    "            averages[key] = np.mean([s[key] for s in scores])\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d542179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load LLM-annotated fine-tuned scores\n",
    "scores_llm_ann_train = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for fs in [0, 10, 50]:\n",
    "                for n_ann_ex in [\"full\"]:\n",
    "\n",
    "                    scores = []\n",
    "                    for seed in range(N_SEEDS):\n",
    "                        with open(\n",
    "                            f\"../_out_fine_tunings/01_llm_annotate_train/{method}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                        ) as f:\n",
    "                            loaded_json = json.load(f)\n",
    "                            seed_scores = add_element_scores(loaded_json, task)\n",
    "                            scores.append(seed_scores)\n",
    "                    scores_llm_ann_train[\n",
    "                        f\"{method}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                    ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1d08fc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paraphrase_full_tasd_0_rest15', 'paraphrase_full_tasd_10_rest15', 'paraphrase_full_tasd_50_rest15', 'dlo_full_tasd_0_rest15', 'dlo_full_tasd_10_rest15', 'dlo_full_tasd_50_rest15', 'paraphrase_full_asqp_0_rest15', 'paraphrase_full_asqp_10_rest15', 'paraphrase_full_asqp_50_rest15', 'dlo_full_asqp_0_rest15', 'dlo_full_asqp_10_rest15', 'dlo_full_asqp_50_rest15', 'paraphrase_full_tasd_0_rest16', 'paraphrase_full_tasd_10_rest16', 'paraphrase_full_tasd_50_rest16', 'dlo_full_tasd_0_rest16', 'dlo_full_tasd_10_rest16', 'dlo_full_tasd_50_rest16', 'paraphrase_full_asqp_0_rest16', 'paraphrase_full_asqp_10_rest16', 'paraphrase_full_asqp_50_rest16', 'dlo_full_asqp_0_rest16', 'dlo_full_asqp_10_rest16', 'dlo_full_asqp_50_rest16', 'paraphrase_full_tasd_0_flightabsa', 'paraphrase_full_tasd_10_flightabsa', 'paraphrase_full_tasd_50_flightabsa', 'dlo_full_tasd_0_flightabsa', 'dlo_full_tasd_10_flightabsa', 'dlo_full_tasd_50_flightabsa', 'paraphrase_full_asqp_0_flightabsa', 'paraphrase_full_asqp_10_flightabsa', 'paraphrase_full_asqp_50_flightabsa', 'dlo_full_asqp_0_flightabsa', 'dlo_full_asqp_10_flightabsa', 'dlo_full_asqp_50_flightabsa', 'paraphrase_full_tasd_0_coursera', 'paraphrase_full_tasd_10_coursera', 'paraphrase_full_tasd_50_coursera', 'dlo_full_tasd_0_coursera', 'dlo_full_tasd_10_coursera', 'dlo_full_tasd_50_coursera', 'paraphrase_full_asqp_0_coursera', 'paraphrase_full_asqp_10_coursera', 'paraphrase_full_asqp_50_coursera', 'dlo_full_asqp_0_coursera', 'dlo_full_asqp_10_coursera', 'dlo_full_asqp_50_coursera', 'paraphrase_full_tasd_0_hotels', 'paraphrase_full_tasd_10_hotels', 'paraphrase_full_tasd_50_hotels', 'dlo_full_tasd_0_hotels', 'dlo_full_tasd_10_hotels', 'dlo_full_tasd_50_hotels', 'paraphrase_full_asqp_0_hotels', 'paraphrase_full_asqp_10_hotels', 'paraphrase_full_asqp_50_hotels', 'dlo_full_asqp_0_hotels', 'dlo_full_asqp_10_hotels', 'dlo_full_asqp_50_hotels'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_llm_ann_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b3b699c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAIE\n",
    "scores_traditional_aug = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [10, 50]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    path = f\"../../QAIE-ABSA-2025-adaption/03_results/{task}_{dataset}_fs_{fs}_{seed}.json\"\n",
    "\n",
    "                    with open(path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_traditional_aug[\n",
    "                    f\"qaie_{task}_{fs}_{dataset}\"\n",
    "                ] = calc_mean(scores)\n",
    "                \n",
    "# DS2\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [10, 50]:\n",
    "            scores = []\n",
    "            for seed in range(3):\n",
    "                path = f\"../../SelfGen-ABSA/generations/trainings/paraphrase/{dataset}/fs_{fs}/{task}/training_{seed}.json\"\n",
    "                with open(path, \"r\") as f:\n",
    "                    loaded_json = json.load(f)\n",
    "                    seed_scores = add_element_scores(loaded_json, task)\n",
    "                    scores.append(seed_scores)\n",
    "            scores_llm_ann_train[\n",
    "                f\"ds2_{task}_{fs}_{dataset}\"\n",
    "            ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b2130bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for aug in [\"eda\"]:\n",
    "            for method in METHODS:\n",
    "                for fs in [10, 50]:\n",
    "                    for n_ann_ex in [2, 5, 10, 15]:\n",
    "                        scores = []\n",
    "                        for seed in range(N_SEEDS):\n",
    "                            path = f\"../_out_fine_tunings/03_traditional_augmentation/{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                            with open(\n",
    "                                path\n",
    "                            ) as f:\n",
    "                                loaded_json = json.load(f)\n",
    "                                seed_scores = add_element_scores(loaded_json, task)\n",
    "                                scores.append(seed_scores)\n",
    "                        scores_traditional_aug[\n",
    "                            f\"{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                        ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "70bdcef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded past results for paraphrase_full_tasd_rest15_f1: 63.06\n",
      "successfully loaded past results for paraphrase_full_tasd_rest15_precision: -\n",
      "successfully loaded past results for paraphrase_full_tasd_rest15_recall: -\n",
      "successfully loaded past results for dlo_full_tasd_rest15_f1: 62.95\n",
      "successfully loaded past results for dlo_full_tasd_rest15_precision: -\n",
      "successfully loaded past results for dlo_full_tasd_rest15_recall: -\n",
      "successfully loaded past results for paraphrase_full_asqp_rest15_f1: 46.93\n",
      "successfully loaded past results for paraphrase_full_asqp_rest15_precision: 46.16\n",
      "successfully loaded past results for paraphrase_full_asqp_rest15_recall: 47.72\n",
      "successfully loaded past results for dlo_full_asqp_rest15_f1: 48.18\n",
      "successfully loaded past results for dlo_full_asqp_rest15_precision: 47.08\n",
      "successfully loaded past results for dlo_full_asqp_rest15_recall: 49.33\n",
      "successfully loaded past results for paraphrase_full_tasd_rest16_f1: 71.97\n",
      "successfully loaded past results for paraphrase_full_tasd_rest16_precision: -\n",
      "successfully loaded past results for paraphrase_full_tasd_rest16_recall: -\n",
      "successfully loaded past results for dlo_full_tasd_rest16_f1: 71.79\n",
      "successfully loaded past results for dlo_full_tasd_rest16_precision: -\n",
      "successfully loaded past results for dlo_full_tasd_rest16_recall: -\n",
      "successfully loaded past results for paraphrase_full_asqp_rest16_f1: 57.93\n",
      "successfully loaded past results for paraphrase_full_asqp_rest16_precision: 56.63\n",
      "successfully loaded past results for paraphrase_full_asqp_rest16_recall: 59.3\n",
      "successfully loaded past results for dlo_full_asqp_rest16_f1: 59.79\n",
      "successfully loaded past results for dlo_full_asqp_rest16_precision: 57.92\n",
      "successfully loaded past results for dlo_full_asqp_rest16_recall: 61.8\n"
     ]
    }
   ],
   "source": [
    "# 4. Load methods baselines\n",
    "scores_00_baseline = {}\n",
    "\n",
    "with open(\"../../zero-shot-absa-quad/plots/past_results.json\") as f:\n",
    "    past_results = json.load(f)\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for n_ann_ex in [10, 50, \"full\"]:\n",
    "\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    if n_ann_ex == \"full\":\n",
    "                        file_path = f\"../../zero-shot-absa-quad/generations/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}.json\"\n",
    "                    else:\n",
    "                        file_path = f\"../../zero-shot-absa-quad/generations/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}_{n_ann_ex}.json\"\n",
    "                    with open(file_path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_mean = calc_mean(scores)\n",
    "\n",
    "                scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"] = (\n",
    "                    scores_mean\n",
    "                )\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for n_ann_ex in [\"full\"]:\n",
    "                for metric in [\"f1\", \"precision\", \"recall\"]:\n",
    "                    try:\n",
    "                            scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"] = (past_results[task][method][dataset])\n",
    "                            print(\"successfully loaded past results for\",\n",
    "                                  f\"{method}_{n_ann_ex}_{task}_{dataset}_{metric}:\", past_results[task][method][dataset][metric])\n",
    "                    except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acaf7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load zero-shot scores\n",
    "scores_zeroshot = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 20, 30, 40, 50]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../../zero-shot-absa-quad/generations/zeroshot/{task}_{dataset}_test_gemma3:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "\n",
    "                        scores.append(seed_scores)\n",
    "                scores_zeroshot[f\"{task}_{fs}_{dataset}\"] = calc_mean(scores)\n",
    "\n",
    "# WITH SELF-Consistency\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 20, 30, 40, 50]:\n",
    "                all_example_data = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../../zero-shot-absa-quad/generations/zeroshot/{task}_{dataset}_test_gemma3:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        all_example_data.append(loaded_json)\n",
    "\n",
    "                all_labels = all_example_data[0][\"all_labels\"]\n",
    "                all_preds = [[] for _ in range(len(all_labels))]\n",
    "                for seed in range(0, N_SEEDS):\n",
    "                    for idx in range(len(all_labels)):\n",
    "                        all_preds[idx].append(all_example_data[seed][\"all_preds\"][idx])\n",
    "                        if seed == N_SEEDS - 1:\n",
    "                            all_preds[idx] = merge_aspect_lists(all_preds[idx])\n",
    "                            all_preds[idx] = [list(p) for p in all_preds[idx]]\n",
    "\n",
    "                loaded_json = {\n",
    "                    \"all_preds\": all_preds,\n",
    "                    \"all_labels\": all_labels,\n",
    "                }\n",
    "\n",
    "                scores = add_element_scores(loaded_json, task)\n",
    "                scores_zeroshot[f\"{task}_{fs}_{dataset}_sc\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aca7989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_train_qaie(task=\"tasd\", dataset=\"rest16\", fs=2):\n",
    "    path = f\"../../QAIE-ABSA-2025-adaption/01_augmentations/fs_examples/{task}/{dataset}/fs_{fs}/aug.txt\"\n",
    "    # count number of lines in the file\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        n_train = len(lines)\n",
    "    return n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "88fce981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_train_ds2(task=\"tasd\", dataset=\"rest16\", fs=2):\n",
    "    path = f\"../../SelfGen-ABSA/generations/trainings/paraphrase/{dataset}/fs_{fs}/{task}/training_0.json\"\n",
    "    # load json and get key n_train_samples\n",
    "    with open(path, \"r\") as f:\n",
    "        loaded_json = json.load(f)\n",
    "        n_train = loaded_json[\"n_train_samples\"]\n",
    "    return n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "72668d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tasd_0_rest15', 'tasd_10_rest15', 'tasd_20_rest15', 'tasd_30_rest15', 'tasd_40_rest15', 'tasd_50_rest15', 'asqp_0_rest15', 'asqp_10_rest15', 'asqp_20_rest15', 'asqp_30_rest15', 'asqp_40_rest15', 'asqp_50_rest15', 'tasd_0_rest16', 'tasd_10_rest16', 'tasd_20_rest16', 'tasd_30_rest16', 'tasd_40_rest16', 'tasd_50_rest16', 'asqp_0_rest16', 'asqp_10_rest16', 'asqp_20_rest16', 'asqp_30_rest16', 'asqp_40_rest16', 'asqp_50_rest16', 'tasd_0_flightabsa', 'tasd_10_flightabsa', 'tasd_20_flightabsa', 'tasd_30_flightabsa', 'tasd_40_flightabsa', 'tasd_50_flightabsa', 'asqp_0_flightabsa', 'asqp_10_flightabsa', 'asqp_20_flightabsa', 'asqp_30_flightabsa', 'asqp_40_flightabsa', 'asqp_50_flightabsa', 'tasd_0_coursera', 'tasd_10_coursera', 'tasd_20_coursera', 'tasd_30_coursera', 'tasd_40_coursera', 'tasd_50_coursera', 'asqp_0_coursera', 'asqp_10_coursera', 'asqp_20_coursera', 'asqp_30_coursera', 'asqp_40_coursera', 'asqp_50_coursera', 'tasd_0_hotels', 'tasd_10_hotels', 'tasd_20_hotels', 'tasd_30_hotels', 'tasd_40_hotels', 'tasd_50_hotels', 'asqp_0_hotels', 'asqp_10_hotels', 'asqp_20_hotels', 'asqp_30_hotels', 'asqp_40_hotels', 'asqp_50_hotels', 'tasd_0_rest15_sc', 'tasd_10_rest15_sc', 'tasd_20_rest15_sc', 'tasd_30_rest15_sc', 'tasd_40_rest15_sc', 'tasd_50_rest15_sc', 'asqp_0_rest15_sc', 'asqp_10_rest15_sc', 'asqp_20_rest15_sc', 'asqp_30_rest15_sc', 'asqp_40_rest15_sc', 'asqp_50_rest15_sc', 'tasd_0_rest16_sc', 'tasd_10_rest16_sc', 'tasd_20_rest16_sc', 'tasd_30_rest16_sc', 'tasd_40_rest16_sc', 'tasd_50_rest16_sc', 'asqp_0_rest16_sc', 'asqp_10_rest16_sc', 'asqp_20_rest16_sc', 'asqp_30_rest16_sc', 'asqp_40_rest16_sc', 'asqp_50_rest16_sc', 'tasd_0_flightabsa_sc', 'tasd_10_flightabsa_sc', 'tasd_20_flightabsa_sc', 'tasd_30_flightabsa_sc', 'tasd_40_flightabsa_sc', 'tasd_50_flightabsa_sc', 'asqp_0_flightabsa_sc', 'asqp_10_flightabsa_sc', 'asqp_20_flightabsa_sc', 'asqp_30_flightabsa_sc', 'asqp_40_flightabsa_sc', 'asqp_50_flightabsa_sc', 'tasd_0_coursera_sc', 'tasd_10_coursera_sc', 'tasd_20_coursera_sc', 'tasd_30_coursera_sc', 'tasd_40_coursera_sc', 'tasd_50_coursera_sc', 'asqp_0_coursera_sc', 'asqp_10_coursera_sc', 'asqp_20_coursera_sc', 'asqp_30_coursera_sc', 'asqp_40_coursera_sc', 'asqp_50_coursera_sc', 'tasd_0_hotels_sc', 'tasd_10_hotels_sc', 'tasd_20_hotels_sc', 'tasd_30_hotels_sc', 'tasd_40_hotels_sc', 'tasd_50_hotels_sc', 'asqp_0_hotels_sc', 'asqp_10_hotels_sc', 'asqp_20_hotels_sc', 'asqp_30_hotels_sc', 'asqp_40_hotels_sc', 'asqp_50_hotels_sc'])\n",
      "dict_keys(['paraphrase_10_tasd_rest15', 'paraphrase_50_tasd_rest15', 'paraphrase_full_tasd_rest15', 'dlo_10_tasd_rest15', 'dlo_50_tasd_rest15', 'dlo_full_tasd_rest15', 'paraphrase_10_asqp_rest15', 'paraphrase_50_asqp_rest15', 'paraphrase_full_asqp_rest15', 'dlo_10_asqp_rest15', 'dlo_50_asqp_rest15', 'dlo_full_asqp_rest15', 'paraphrase_10_tasd_rest16', 'paraphrase_50_tasd_rest16', 'paraphrase_full_tasd_rest16', 'dlo_10_tasd_rest16', 'dlo_50_tasd_rest16', 'dlo_full_tasd_rest16', 'paraphrase_10_asqp_rest16', 'paraphrase_50_asqp_rest16', 'paraphrase_full_asqp_rest16', 'dlo_10_asqp_rest16', 'dlo_50_asqp_rest16', 'dlo_full_asqp_rest16', 'paraphrase_10_tasd_flightabsa', 'paraphrase_50_tasd_flightabsa', 'paraphrase_full_tasd_flightabsa', 'dlo_10_tasd_flightabsa', 'dlo_50_tasd_flightabsa', 'dlo_full_tasd_flightabsa', 'paraphrase_10_asqp_flightabsa', 'paraphrase_50_asqp_flightabsa', 'paraphrase_full_asqp_flightabsa', 'dlo_10_asqp_flightabsa', 'dlo_50_asqp_flightabsa', 'dlo_full_asqp_flightabsa', 'paraphrase_10_tasd_coursera', 'paraphrase_50_tasd_coursera', 'paraphrase_full_tasd_coursera', 'dlo_10_tasd_coursera', 'dlo_50_tasd_coursera', 'dlo_full_tasd_coursera', 'paraphrase_10_asqp_coursera', 'paraphrase_50_asqp_coursera', 'paraphrase_full_asqp_coursera', 'dlo_10_asqp_coursera', 'dlo_50_asqp_coursera', 'dlo_full_asqp_coursera', 'paraphrase_10_tasd_hotels', 'paraphrase_50_tasd_hotels', 'paraphrase_full_tasd_hotels', 'dlo_10_tasd_hotels', 'dlo_50_tasd_hotels', 'dlo_full_tasd_hotels', 'paraphrase_10_asqp_hotels', 'paraphrase_50_asqp_hotels', 'paraphrase_full_asqp_hotels', 'dlo_10_asqp_hotels', 'dlo_50_asqp_hotels', 'dlo_full_asqp_hotels'])\n",
      "dict_keys(['paraphrase_full_tasd_0_rest15', 'paraphrase_full_tasd_10_rest15', 'paraphrase_full_tasd_50_rest15', 'dlo_full_tasd_0_rest15', 'dlo_full_tasd_10_rest15', 'dlo_full_tasd_50_rest15', 'paraphrase_full_asqp_0_rest15', 'paraphrase_full_asqp_10_rest15', 'paraphrase_full_asqp_50_rest15', 'dlo_full_asqp_0_rest15', 'dlo_full_asqp_10_rest15', 'dlo_full_asqp_50_rest15', 'paraphrase_full_tasd_0_rest16', 'paraphrase_full_tasd_10_rest16', 'paraphrase_full_tasd_50_rest16', 'dlo_full_tasd_0_rest16', 'dlo_full_tasd_10_rest16', 'dlo_full_tasd_50_rest16', 'paraphrase_full_asqp_0_rest16', 'paraphrase_full_asqp_10_rest16', 'paraphrase_full_asqp_50_rest16', 'dlo_full_asqp_0_rest16', 'dlo_full_asqp_10_rest16', 'dlo_full_asqp_50_rest16', 'paraphrase_full_tasd_0_flightabsa', 'paraphrase_full_tasd_10_flightabsa', 'paraphrase_full_tasd_50_flightabsa', 'dlo_full_tasd_0_flightabsa', 'dlo_full_tasd_10_flightabsa', 'dlo_full_tasd_50_flightabsa', 'paraphrase_full_asqp_0_flightabsa', 'paraphrase_full_asqp_10_flightabsa', 'paraphrase_full_asqp_50_flightabsa', 'dlo_full_asqp_0_flightabsa', 'dlo_full_asqp_10_flightabsa', 'dlo_full_asqp_50_flightabsa', 'paraphrase_full_tasd_0_coursera', 'paraphrase_full_tasd_10_coursera', 'paraphrase_full_tasd_50_coursera', 'dlo_full_tasd_0_coursera', 'dlo_full_tasd_10_coursera', 'dlo_full_tasd_50_coursera', 'paraphrase_full_asqp_0_coursera', 'paraphrase_full_asqp_10_coursera', 'paraphrase_full_asqp_50_coursera', 'dlo_full_asqp_0_coursera', 'dlo_full_asqp_10_coursera', 'dlo_full_asqp_50_coursera', 'paraphrase_full_tasd_0_hotels', 'paraphrase_full_tasd_10_hotels', 'paraphrase_full_tasd_50_hotels', 'dlo_full_tasd_0_hotels', 'dlo_full_tasd_10_hotels', 'dlo_full_tasd_50_hotels', 'paraphrase_full_asqp_0_hotels', 'paraphrase_full_asqp_10_hotels', 'paraphrase_full_asqp_50_hotels', 'dlo_full_asqp_0_hotels', 'dlo_full_asqp_10_hotels', 'dlo_full_asqp_50_hotels', 'ds2_tasd_10_rest15', 'ds2_tasd_50_rest15', 'ds2_asqp_10_rest15', 'ds2_asqp_50_rest15', 'ds2_tasd_10_rest16', 'ds2_tasd_50_rest16', 'ds2_asqp_10_rest16', 'ds2_asqp_50_rest16', 'ds2_tasd_10_flightabsa', 'ds2_tasd_50_flightabsa', 'ds2_asqp_10_flightabsa', 'ds2_asqp_50_flightabsa', 'ds2_tasd_10_coursera', 'ds2_tasd_50_coursera', 'ds2_asqp_10_coursera', 'ds2_asqp_50_coursera', 'ds2_tasd_10_hotels', 'ds2_tasd_50_hotels', 'ds2_asqp_10_hotels', 'ds2_asqp_50_hotels'])\n",
      "dict_keys(['qaie_tasd_10_rest15', 'qaie_tasd_50_rest15', 'qaie_asqp_10_rest15', 'qaie_asqp_50_rest15', 'qaie_tasd_10_rest16', 'qaie_tasd_50_rest16', 'qaie_asqp_10_rest16', 'qaie_asqp_50_rest16', 'qaie_tasd_10_flightabsa', 'qaie_tasd_50_flightabsa', 'qaie_asqp_10_flightabsa', 'qaie_asqp_50_flightabsa', 'qaie_tasd_10_coursera', 'qaie_tasd_50_coursera', 'qaie_asqp_10_coursera', 'qaie_asqp_50_coursera', 'qaie_tasd_10_hotels', 'qaie_tasd_50_hotels', 'qaie_asqp_10_hotels', 'qaie_asqp_50_hotels', 'paraphrase_eda_2_tasd_10_rest15', 'paraphrase_eda_5_tasd_10_rest15', 'paraphrase_eda_10_tasd_10_rest15', 'paraphrase_eda_15_tasd_10_rest15', 'paraphrase_eda_2_tasd_50_rest15', 'paraphrase_eda_5_tasd_50_rest15', 'paraphrase_eda_10_tasd_50_rest15', 'paraphrase_eda_15_tasd_50_rest15', 'dlo_eda_2_tasd_10_rest15', 'dlo_eda_5_tasd_10_rest15', 'dlo_eda_10_tasd_10_rest15', 'dlo_eda_15_tasd_10_rest15', 'dlo_eda_2_tasd_50_rest15', 'dlo_eda_5_tasd_50_rest15', 'dlo_eda_10_tasd_50_rest15', 'dlo_eda_15_tasd_50_rest15', 'paraphrase_eda_2_asqp_10_rest15', 'paraphrase_eda_5_asqp_10_rest15', 'paraphrase_eda_10_asqp_10_rest15', 'paraphrase_eda_15_asqp_10_rest15', 'paraphrase_eda_2_asqp_50_rest15', 'paraphrase_eda_5_asqp_50_rest15', 'paraphrase_eda_10_asqp_50_rest15', 'paraphrase_eda_15_asqp_50_rest15', 'dlo_eda_2_asqp_10_rest15', 'dlo_eda_5_asqp_10_rest15', 'dlo_eda_10_asqp_10_rest15', 'dlo_eda_15_asqp_10_rest15', 'dlo_eda_2_asqp_50_rest15', 'dlo_eda_5_asqp_50_rest15', 'dlo_eda_10_asqp_50_rest15', 'dlo_eda_15_asqp_50_rest15', 'paraphrase_eda_2_tasd_10_rest16', 'paraphrase_eda_5_tasd_10_rest16', 'paraphrase_eda_10_tasd_10_rest16', 'paraphrase_eda_15_tasd_10_rest16', 'paraphrase_eda_2_tasd_50_rest16', 'paraphrase_eda_5_tasd_50_rest16', 'paraphrase_eda_10_tasd_50_rest16', 'paraphrase_eda_15_tasd_50_rest16', 'dlo_eda_2_tasd_10_rest16', 'dlo_eda_5_tasd_10_rest16', 'dlo_eda_10_tasd_10_rest16', 'dlo_eda_15_tasd_10_rest16', 'dlo_eda_2_tasd_50_rest16', 'dlo_eda_5_tasd_50_rest16', 'dlo_eda_10_tasd_50_rest16', 'dlo_eda_15_tasd_50_rest16', 'paraphrase_eda_2_asqp_10_rest16', 'paraphrase_eda_5_asqp_10_rest16', 'paraphrase_eda_10_asqp_10_rest16', 'paraphrase_eda_15_asqp_10_rest16', 'paraphrase_eda_2_asqp_50_rest16', 'paraphrase_eda_5_asqp_50_rest16', 'paraphrase_eda_10_asqp_50_rest16', 'paraphrase_eda_15_asqp_50_rest16', 'dlo_eda_2_asqp_10_rest16', 'dlo_eda_5_asqp_10_rest16', 'dlo_eda_10_asqp_10_rest16', 'dlo_eda_15_asqp_10_rest16', 'dlo_eda_2_asqp_50_rest16', 'dlo_eda_5_asqp_50_rest16', 'dlo_eda_10_asqp_50_rest16', 'dlo_eda_15_asqp_50_rest16', 'paraphrase_eda_2_tasd_10_flightabsa', 'paraphrase_eda_5_tasd_10_flightabsa', 'paraphrase_eda_10_tasd_10_flightabsa', 'paraphrase_eda_15_tasd_10_flightabsa', 'paraphrase_eda_2_tasd_50_flightabsa', 'paraphrase_eda_5_tasd_50_flightabsa', 'paraphrase_eda_10_tasd_50_flightabsa', 'paraphrase_eda_15_tasd_50_flightabsa', 'dlo_eda_2_tasd_10_flightabsa', 'dlo_eda_5_tasd_10_flightabsa', 'dlo_eda_10_tasd_10_flightabsa', 'dlo_eda_15_tasd_10_flightabsa', 'dlo_eda_2_tasd_50_flightabsa', 'dlo_eda_5_tasd_50_flightabsa', 'dlo_eda_10_tasd_50_flightabsa', 'dlo_eda_15_tasd_50_flightabsa', 'paraphrase_eda_2_asqp_10_flightabsa', 'paraphrase_eda_5_asqp_10_flightabsa', 'paraphrase_eda_10_asqp_10_flightabsa', 'paraphrase_eda_15_asqp_10_flightabsa', 'paraphrase_eda_2_asqp_50_flightabsa', 'paraphrase_eda_5_asqp_50_flightabsa', 'paraphrase_eda_10_asqp_50_flightabsa', 'paraphrase_eda_15_asqp_50_flightabsa', 'dlo_eda_2_asqp_10_flightabsa', 'dlo_eda_5_asqp_10_flightabsa', 'dlo_eda_10_asqp_10_flightabsa', 'dlo_eda_15_asqp_10_flightabsa', 'dlo_eda_2_asqp_50_flightabsa', 'dlo_eda_5_asqp_50_flightabsa', 'dlo_eda_10_asqp_50_flightabsa', 'dlo_eda_15_asqp_50_flightabsa', 'paraphrase_eda_2_tasd_10_coursera', 'paraphrase_eda_5_tasd_10_coursera', 'paraphrase_eda_10_tasd_10_coursera', 'paraphrase_eda_15_tasd_10_coursera', 'paraphrase_eda_2_tasd_50_coursera', 'paraphrase_eda_5_tasd_50_coursera', 'paraphrase_eda_10_tasd_50_coursera', 'paraphrase_eda_15_tasd_50_coursera', 'dlo_eda_2_tasd_10_coursera', 'dlo_eda_5_tasd_10_coursera', 'dlo_eda_10_tasd_10_coursera', 'dlo_eda_15_tasd_10_coursera', 'dlo_eda_2_tasd_50_coursera', 'dlo_eda_5_tasd_50_coursera', 'dlo_eda_10_tasd_50_coursera', 'dlo_eda_15_tasd_50_coursera', 'paraphrase_eda_2_asqp_10_coursera', 'paraphrase_eda_5_asqp_10_coursera', 'paraphrase_eda_10_asqp_10_coursera', 'paraphrase_eda_15_asqp_10_coursera', 'paraphrase_eda_2_asqp_50_coursera', 'paraphrase_eda_5_asqp_50_coursera', 'paraphrase_eda_10_asqp_50_coursera', 'paraphrase_eda_15_asqp_50_coursera', 'dlo_eda_2_asqp_10_coursera', 'dlo_eda_5_asqp_10_coursera', 'dlo_eda_10_asqp_10_coursera', 'dlo_eda_15_asqp_10_coursera', 'dlo_eda_2_asqp_50_coursera', 'dlo_eda_5_asqp_50_coursera', 'dlo_eda_10_asqp_50_coursera', 'dlo_eda_15_asqp_50_coursera', 'paraphrase_eda_2_tasd_10_hotels', 'paraphrase_eda_5_tasd_10_hotels', 'paraphrase_eda_10_tasd_10_hotels', 'paraphrase_eda_15_tasd_10_hotels', 'paraphrase_eda_2_tasd_50_hotels', 'paraphrase_eda_5_tasd_50_hotels', 'paraphrase_eda_10_tasd_50_hotels', 'paraphrase_eda_15_tasd_50_hotels', 'dlo_eda_2_tasd_10_hotels', 'dlo_eda_5_tasd_10_hotels', 'dlo_eda_10_tasd_10_hotels', 'dlo_eda_15_tasd_10_hotels', 'dlo_eda_2_tasd_50_hotels', 'dlo_eda_5_tasd_50_hotels', 'dlo_eda_10_tasd_50_hotels', 'dlo_eda_15_tasd_50_hotels', 'paraphrase_eda_2_asqp_10_hotels', 'paraphrase_eda_5_asqp_10_hotels', 'paraphrase_eda_10_asqp_10_hotels', 'paraphrase_eda_15_asqp_10_hotels', 'paraphrase_eda_2_asqp_50_hotels', 'paraphrase_eda_5_asqp_50_hotels', 'paraphrase_eda_10_asqp_50_hotels', 'paraphrase_eda_15_asqp_50_hotels', 'dlo_eda_2_asqp_10_hotels', 'dlo_eda_5_asqp_10_hotels', 'dlo_eda_10_asqp_10_hotels', 'dlo_eda_15_asqp_10_hotels', 'dlo_eda_2_asqp_50_hotels', 'dlo_eda_5_asqp_50_hotels', 'dlo_eda_10_asqp_50_hotels', 'dlo_eda_15_asqp_50_hotels'])\n"
     ]
    }
   ],
   "source": [
    "print(scores_zeroshot.keys())\n",
    "print(scores_00_baseline.keys())\n",
    "print(scores_llm_ann_train.keys())\n",
    "print(scores_traditional_aug.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9cf4baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FT_APPROACHES = [\"Paraphrase\", \"DLO\"]\n",
    "FT_ENCODING = {\"Paraphrase\": \"paraphrase\", \"DLO\": \"dlo\"}\n",
    "FT_ENCODING_REVERSE = {v: k for k, v in FT_ENCODING.items()}\n",
    "\n",
    "N_TRAIN_EDA = [2, 5, 10, 15]\n",
    "N_SHOTS = [10, 50]\n",
    "\n",
    "def get_mean_n_train_qaie(task, fs):\n",
    "    \"\"\"Calculate mean n_train across datasets for a given task and fs.\"\"\"\n",
    "    return str(np.round(np.mean([\n",
    "        get_n_train_qaie(task=task, dataset=ds, fs=fs) \n",
    "        for ds in DATASETS\n",
    "    ]), 1))\n",
    "    \n",
    "def to_k(num_str):\n",
    "    \"\"\"\n",
    "    Convert a European number string (comma decimal) into k-format.\n",
    "    Example: \"23343,54\" -> \"23,3k\"\n",
    "    \"\"\"\n",
    "    # Replace comma with dot for float conversion\n",
    "    num = float(str(num_str).replace(\",\", \".\"))\n",
    "\n",
    "    # Convert to k with 1 decimal\n",
    "    result = f\"{num / 1000:.1f}k\"\n",
    "\n",
    "    # Use comma instead of dot for decimal\n",
    "    result = result.replace(\".\", \",\")\n",
    "\n",
    "    # Remove ,0 if no decimal is needed\n",
    "    if result.endswith(\",0k\"):\n",
    "        result = result.replace(\",0k\", \"k\")\n",
    "\n",
    "    return result\n",
    "\n",
    "    \n",
    "def get_mean_n_train_ds2(task, fs):\n",
    "    \"\"\"Calculate mean n_train across datasets for a given task and fs.\"\"\"\n",
    "    return to_k(str(np.round(np.mean([\n",
    "        get_n_train_ds2(task=task, dataset=ds, fs=fs) \n",
    "        for ds in DATASETS\n",
    "    ]), 1)))\n",
    "\n",
    "def create_columns():\n",
    "    \"\"\"Create all column data for the DataFrame.\"\"\"\n",
    "    # Base pattern for one shot value\n",
    "    base_pattern_size = len(FT_APPROACHES) * 2 + len(N_TRAIN_EDA) * len(FT_APPROACHES) + 2 # 2 = qaie and ds2\n",
    "    \n",
    "    # Annotated examples column\n",
    "    n_annotated = ([0] * 3 + \n",
    "                  [10] * (1 + base_pattern_size) + \n",
    "                  [50] * (1 + base_pattern_size) + \n",
    "                  [\"full\"] * len(FT_APPROACHES))\n",
    "    \n",
    "    # Approaches column - base pattern\n",
    "    base_approaches = ([[\"k-shot Gemma\"]] + FT_APPROACHES + \n",
    "                      [f\"LLMA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES] +\n",
    "                      [f\"EDA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES for _ in N_TRAIN_EDA] +\n",
    "                      [\"QAIE\", \"DS2\"])\n",
    "    \n",
    "    approaches = ([[\"0-shot Gemma\"]]+[f\"LLMA \\\\textbackslash w {approach}\" for approach in FT_APPROACHES] +\n",
    "                 base_approaches * 2 +  # For 10 and 50 shots\n",
    "                 FT_APPROACHES )\n",
    "    \n",
    "    # Training columns\n",
    "    def build_train_column(task):\n",
    "        column = [\"0\", \"full\", \"full\"] \n",
    "        for fs in N_SHOTS:\n",
    "            column.extend([fs,\n",
    "                *([fs] * len(FT_APPROACHES)),\n",
    "                *([\"full\"] * len(FT_APPROACHES)),\n",
    "                *([fs + n * fs for _ in FT_APPROACHES for n in N_TRAIN_EDA]),\n",
    "                get_mean_n_train_qaie(task, fs),\n",
    "                get_mean_n_train_ds2(task, fs)\n",
    "            ])\n",
    "        column.extend([\"full\"] * len(FT_APPROACHES))\n",
    "        return column\n",
    "    \n",
    "    return n_annotated, approaches, build_train_column(\"tasd\"), build_train_column(\"asqp\")\n",
    "\n",
    "def collect_performance_scores(tasks, metrics):\n",
    "    \"\"\"Collect all performance scores from different score dictionaries.\"\"\"\n",
    "    scores = {dataset: {task: {metric: [] for metric in metrics} for task in tasks} \n",
    "              for dataset in DATASETS}\n",
    "    \n",
    "    for dataset in DATASETS:\n",
    "        for task in tasks:\n",
    "            for metric in metrics:\n",
    "                task_scores = scores[dataset][task][metric]\n",
    "\n",
    "                task_scores.extend([\n",
    "                    scores_zeroshot[f\"{task}_{fs}_{dataset}_sc\"][metric]\n",
    "                    for fs in [0]\n",
    "                ])\n",
    "                \n",
    "                # Zero-shot scores\n",
    "                task_scores.extend([\n",
    "                    scores_llm_ann_train[f\"{method}_full_{task}_0_{dataset}\"][metric]\n",
    "                    for method in METHODS\n",
    "                ])\n",
    "                \n",
    "                # Few-shot scores (10, 50)\n",
    "                for fs in N_SHOTS:\n",
    "                    # Baseline scores\n",
    "\n",
    "                    task_scores.extend([\n",
    "                      scores_zeroshot[f\"{task}_{k}_{dataset}_sc\"][metric]\n",
    "                      for k in [fs]\n",
    "                    ])\n",
    "                \n",
    "                    task_scores.extend([\n",
    "                        scores_00_baseline[f\"{method}_{fs}_{task}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                    ])\n",
    "                    \n",
    "                    # LLM annotation scores\n",
    "                    task_scores.extend([\n",
    "                        scores_llm_ann_train[f\"{method}_full_{task}_{fs}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                    ])\n",
    "                    \n",
    "                    # Traditional augmentation scores\n",
    "                    task_scores.extend([\n",
    "                        scores_traditional_aug[f\"{method}_eda_{n_train}_{task}_{fs}_{dataset}\"][metric]\n",
    "                        for method in METHODS\n",
    "                        for n_train in N_TRAIN_EDA\n",
    "                    ])\n",
    "                    \n",
    "                    # QAIE scores\n",
    "                    task_scores.append(\n",
    "                        scores_traditional_aug[f\"qaie_{task}_{fs}_{dataset}\"][metric]\n",
    "                    )\n",
    "                    \n",
    "                    # DS2 scores\n",
    "                    task_scores.append(\n",
    "                        scores_llm_ann_train[f\"ds2_{task}_{fs}_{dataset}\"][metric]\n",
    "                    )\n",
    "                \n",
    "                # Full training scores\n",
    "                task_scores.extend([\n",
    "                    scores_00_baseline[f\"{method}_full_{task}_{dataset}\"][metric]\n",
    "                    for method in METHODS\n",
    "                ])\n",
    "            \n",
    "    \n",
    "    return scores\n",
    "\n",
    "def create_f1_plot_with_avg(table_out):\n",
    "    tasd_columns = [col for col in table_out.columns if \"tasd\" in col and col != \"\\\\# n_train_column_tasd\"]\n",
    "    asqp_columns = [col for col in table_out.columns if \"asqp\" in col and col != \"\\\\# n_train_column_asqp\"]\n",
    "    \n",
    "    # Für tasd: \"-\" ignorieren, ohne Originalwerte zu überschreiben\n",
    "    tasd_numeric = table_out[tasd_columns].apply(\n",
    "        lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "    )\n",
    "    tasd_avg = tasd_numeric.mean(axis=1, skipna=True)\n",
    "    \n",
    "    # Für asqp: \"-\" ignorieren, ohne Originalwerte zu überschreiben\n",
    "    asqp_numeric = table_out[asqp_columns].apply(\n",
    "        lambda x: pd.to_numeric(x, errors=\"coerce\")\n",
    "    )\n",
    "    asqp_avg = asqp_numeric.mean(axis=1, skipna=True)\n",
    "    \n",
    "    table_out[\"tasd_avg\"] = tasd_avg\n",
    "    table_out[\"asqp_avg\"] = asqp_avg\n",
    "    return table_out\n",
    "\n",
    "\n",
    "def create_f1_plot(tasks=[\"tasd\"], metrics=[\"f1\"]):\n",
    "    \"\"\"Create F1 plot DataFrame with simplified logic.\"\"\"\n",
    "    \n",
    "    # Get all column data\n",
    "    n_annotated, approaches, n_train_tasd, n_train_asqp = create_columns()\n",
    "    \n",
    "    # Collect performance scores\n",
    "    performance_scores = collect_performance_scores(tasks, metrics)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_data = {\n",
    "        \"\\# Annotated examples\": n_annotated,\n",
    "        \"Approach\": approaches,\n",
    "        \"\\# n_train_column_tasd\": n_train_tasd,\n",
    "        \"\\# n_train_column_asqp\": n_train_asqp,\n",
    "    }\n",
    "    \n",
    "    # Add performance columns\n",
    "    for dataset in DATASETS:\n",
    "        for task in tasks:\n",
    "            for metric in metrics:\n",
    "                df_data[f\"{dataset}_{task}_{metric}\"] = performance_scores[dataset][task][metric]\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    \n",
    "    # Round numbers in performance columns\n",
    "    performance_columns = [f\"{dataset}_{task}_{metric}\" \n",
    "                          for dataset in DATASETS \n",
    "                          for task in tasks \n",
    "                          for metric in metrics]\n",
    "    \n",
    "    performance_columns += [\"tasd_avg\", \"asqp_avg\"]\n",
    "    \n",
    "    df = create_f1_plot_with_avg(df)\n",
    "    df_raw = df.copy()\n",
    "    df = round_numbers(df, performance_columns, n_rest=2)\n",
    "\n",
    "    return df, df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6f6a136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def extract_raw_value(formatted_value):\n",
    "    if pd.isna(formatted_value):\n",
    "        return formatted_value\n",
    "    \n",
    "    value_str = str(formatted_value)\n",
    "    \n",
    "    # Entferne alle LaTeX-Formatierungen\n",
    "    # Muster für \\textbf{...}, \\underline{...} und verschachtelte Kombinationen\n",
    "    clean_value = value_str\n",
    "    \n",
    "    # Iterativ alle Formatierungen entfernen\n",
    "    while True:\n",
    "        old_value = clean_value\n",
    "        # Entferne \\textbf{...}\n",
    "        clean_value = re.sub(r'\\\\textbf\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}', r'\\1', clean_value)\n",
    "        # Entferne \\underline{...}\n",
    "        clean_value = re.sub(r'\\\\underline\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}', r'\\1', clean_value)\n",
    "        \n",
    "        if clean_value == old_value:\n",
    "            break\n",
    "    \n",
    "    return clean_value\n",
    "\n",
    "def apply_formatting(value, bold=False, underline=False):\n",
    "    result = str(value)\n",
    "    \n",
    "    if underline:\n",
    "        result = f\"\\\\underline{{{result}}}\"\n",
    "    if bold:\n",
    "        result = f\"\\\\textbf{{{result}}}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_current_formatting(formatted_value):\n",
    "    if pd.isna(formatted_value):\n",
    "        return False, False\n",
    "    \n",
    "    value_str = str(formatted_value)\n",
    "    is_bold = '\\\\textbf{' in value_str\n",
    "    is_underlined = '\\\\underline{' in value_str\n",
    "    \n",
    "    return is_bold, is_underlined\n",
    "\n",
    "def highlight(df, start_column, end_column, groups, type=\"underline\"):\n",
    "    # Kopie des DataFrames erstellen\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Formatierungsoptionen bestimmen\n",
    "    if type == \"both\" or (isinstance(type, list) and \"bold\" in type and \"underline\" in type):\n",
    "        apply_bold = True\n",
    "        apply_underline = True\n",
    "    elif type == \"bold\" or (isinstance(type, list) and \"bold\" in type):\n",
    "        apply_bold = True\n",
    "        apply_underline = False\n",
    "    elif type == \"underline\" or (isinstance(type, list) and \"underline\" in type):\n",
    "        apply_bold = False\n",
    "        apply_underline = True\n",
    "    else:\n",
    "        apply_bold = False\n",
    "        apply_underline = True  # Default\n",
    "    \n",
    "    # Durch alle betroffenen Spalten iterieren\n",
    "    for col_idx in range(start_column, end_column + 1):\n",
    "        col_name = df.columns[col_idx]\n",
    "        \n",
    "        # Durch alle Gruppen iterieren\n",
    "        for group in groups:\n",
    "            # Werte der aktuellen Gruppe in der aktuellen Spalte\n",
    "            group_series = df.iloc[group, col_idx]\n",
    "            \n",
    "            # Rohe Werte extrahieren für numerischen Vergleich\n",
    "            raw_values = []\n",
    "            for idx in group:\n",
    "                raw_val = extract_raw_value(df.iloc[idx, col_idx])\n",
    "                raw_values.append(raw_val)\n",
    "            \n",
    "            # Versuche, die rohen Werte in float zu konvertieren\n",
    "            numeric_values = pd.to_numeric(raw_values, errors='coerce')\n",
    "            \n",
    "            # remove values from numpy array numeric_values that are not numeric\n",
    "            numeric_values = [val for val in numeric_values if not pd.isna(val)]\n",
    "            \n",
    "            try:\n",
    "              max_value = max(numeric_values)\n",
    "            except ValueError:\n",
    "              max_value = None\n",
    "                \n",
    "            # Finde alle Indizes mit dem Maximalwert\n",
    "            for i, (idx, raw_val, numeric_val) in enumerate(zip(group, raw_values, numeric_values)):\n",
    "                    if numeric_val == max_value:\n",
    "                        # Aktuelle Formatierung ermitteln\n",
    "                        current_value = result_df.iloc[idx, col_idx]\n",
    "                        is_bold, is_underlined = get_current_formatting(current_value)\n",
    "                        \n",
    "                        # Neue Formatierung bestimmen\n",
    "                        new_bold = is_bold or apply_bold\n",
    "                        new_underline = is_underlined or apply_underline\n",
    "                        \n",
    "                        # Rohen Wert extrahieren und neue Formatierung anwenden\n",
    "                        raw_value = extract_raw_value(current_value)\n",
    "                        formatted_value = apply_formatting(raw_value, bold=new_bold, underline=new_underline)\n",
    "                        \n",
    "                        result_df.iloc[idx, col_idx] = formatted_value\n",
    "    \n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cfb9ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file in 01_muster_tex/performance.txt\n",
    "with open(\"01_muster_tex/performance.txt\", \"r\") as f:\n",
    "    template = f.read()\n",
    "\n",
    "for metric in [\"f1\", \"precision\", \"recall\"]:\n",
    "    table_out, table_out_raw = create_f1_plot(tasks=[\"tasd\", \"asqp\"], metrics=[metric])\n",
    "    \n",
    "    mask = pd.Series(True, index=table_out.index)\n",
    "    \n",
    "    for idx, row in table_out.iterrows():\n",
    "        approach = str(row['Approach'])\n",
    "        n_train_tasd = row['\\\\# n_train_column_tasd']\n",
    "        \n",
    "        # Check if approach contains \"EDA\"\n",
    "        if 'EDA' in approach:\n",
    "            # If it also contains \"Paraphrase\", remove it\n",
    "            if 'Paraphrase' in approach:\n",
    "                mask[idx] = False\n",
    "            # If it contains only \"EDA\" but n_train_column_tasd is not 110 or 550, remove it\n",
    "            elif n_train_tasd not in [110, 550]:\n",
    "                mask[idx] = False\n",
    "    \n",
    "    # Apply the mask to filter the dataframes\n",
    "    table_out = table_out[mask].copy()\n",
    "    table_out_raw = table_out_raw[mask].copy()\n",
    "    \n",
    "    # Reset index for proper highlighting\n",
    "    table_out.reset_index(drop=True, inplace=True)\n",
    "    table_out_raw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    table_out = highlight(table_out, start_column=4, end_column=15, groups=[[0, 1, 2], [k for k in range(3, 10)], [k for k in range(11, 18)], [19, 20]], type=\"bold\")\n",
    "    table_out = highlight(table_out, start_column=4, end_column=15, groups=[[i for i in range(0, 21)]], type=\"underline\")\n",
    "    \n",
    "    table_out_list = table_out.iloc[:, 2:].astype(str).values.tolist()\n",
    "    table_out_list = [item for sublist in table_out_list for item in sublist]\n",
    "\n",
    "    table_with_values = template\n",
    "    for i in range(len(table_out_list)):\n",
    "        table_with_values = table_with_values.replace(\"xxxx\", table_out_list[i], 1)\n",
    "    \n",
    "    # Write the final table to a file\n",
    "    with open(f\"_out_table/{metric}_table.txt\", \"w\") as f_out:\n",
    "        f_out.write(table_with_values)\n",
    "        \n",
    "    # store df table_out_raw as csv\n",
    "    table_out_raw.to_csv(f\"_out_table/{metric}_table_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1e7e90c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\# Annotated examples</th>\n",
       "      <th>Approach</th>\n",
       "      <th>\\# n_train_column_tasd</th>\n",
       "      <th>\\# n_train_column_asqp</th>\n",
       "      <th>rest15_tasd_recall</th>\n",
       "      <th>rest15_asqp_recall</th>\n",
       "      <th>rest16_tasd_recall</th>\n",
       "      <th>rest16_asqp_recall</th>\n",
       "      <th>flightabsa_tasd_recall</th>\n",
       "      <th>flightabsa_asqp_recall</th>\n",
       "      <th>coursera_tasd_recall</th>\n",
       "      <th>coursera_asqp_recall</th>\n",
       "      <th>hotels_tasd_recall</th>\n",
       "      <th>hotels_asqp_recall</th>\n",
       "      <th>tasd_avg</th>\n",
       "      <th>asqp_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[0-shot Gemma]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.360947</td>\n",
       "      <td>26.289308</td>\n",
       "      <td>46.565774</td>\n",
       "      <td>30.287860</td>\n",
       "      <td>56.899811</td>\n",
       "      <td>45.423729</td>\n",
       "      <td>32.581967</td>\n",
       "      <td>15.139442</td>\n",
       "      <td>41.017488</td>\n",
       "      <td>23.162275</td>\n",
       "      <td>41.685197</td>\n",
       "      <td>28.060523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>LLMA \\textbackslash w Paraphrase</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>28.544379</td>\n",
       "      <td>20.251572</td>\n",
       "      <td>49.679715</td>\n",
       "      <td>28.535670</td>\n",
       "      <td>55.689981</td>\n",
       "      <td>46.305085</td>\n",
       "      <td>34.057377</td>\n",
       "      <td>15.737052</td>\n",
       "      <td>43.216561</td>\n",
       "      <td>27.176634</td>\n",
       "      <td>42.237603</td>\n",
       "      <td>27.601203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>LLMA \\textbackslash w DLO</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>27.360947</td>\n",
       "      <td>20.905660</td>\n",
       "      <td>49.266589</td>\n",
       "      <td>29.812265</td>\n",
       "      <td>56.975425</td>\n",
       "      <td>47.389831</td>\n",
       "      <td>34.467213</td>\n",
       "      <td>16.015936</td>\n",
       "      <td>43.847377</td>\n",
       "      <td>26.213592</td>\n",
       "      <td>42.383510</td>\n",
       "      <td>28.067457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>[k-shot Gemma]</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>52.662722</td>\n",
       "      <td>40.503145</td>\n",
       "      <td>65.192084</td>\n",
       "      <td>47.934919</td>\n",
       "      <td>60.869565</td>\n",
       "      <td>45.084746</td>\n",
       "      <td>40.368852</td>\n",
       "      <td>21.314741</td>\n",
       "      <td>55.166932</td>\n",
       "      <td>28.294036</td>\n",
       "      <td>54.852031</td>\n",
       "      <td>36.626317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Paraphrase</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7.384615</td>\n",
       "      <td>1.106918</td>\n",
       "      <td>5.931198</td>\n",
       "      <td>3.229036</td>\n",
       "      <td>7.637051</td>\n",
       "      <td>2.847458</td>\n",
       "      <td>14.508197</td>\n",
       "      <td>4.262948</td>\n",
       "      <td>12.388535</td>\n",
       "      <td>2.058414</td>\n",
       "      <td>9.569919</td>\n",
       "      <td>2.700955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>DLO</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>13.467456</td>\n",
       "      <td>4.125786</td>\n",
       "      <td>13.946449</td>\n",
       "      <td>4.906133</td>\n",
       "      <td>13.913043</td>\n",
       "      <td>4.033898</td>\n",
       "      <td>20.860656</td>\n",
       "      <td>4.023904</td>\n",
       "      <td>17.392687</td>\n",
       "      <td>3.411928</td>\n",
       "      <td>15.916058</td>\n",
       "      <td>4.100330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>LLMA \\textbackslash w Paraphrase</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>46.982249</td>\n",
       "      <td>36.427673</td>\n",
       "      <td>61.755635</td>\n",
       "      <td>45.907384</td>\n",
       "      <td>58.676749</td>\n",
       "      <td>45.932203</td>\n",
       "      <td>38.647541</td>\n",
       "      <td>22.988048</td>\n",
       "      <td>53.821656</td>\n",
       "      <td>31.070932</td>\n",
       "      <td>51.976766</td>\n",
       "      <td>36.465248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>LLMA \\textbackslash w DLO</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>48.189349</td>\n",
       "      <td>38.993711</td>\n",
       "      <td>61.280559</td>\n",
       "      <td>48.811014</td>\n",
       "      <td>61.512287</td>\n",
       "      <td>47.355932</td>\n",
       "      <td>39.631148</td>\n",
       "      <td>23.984064</td>\n",
       "      <td>54.499205</td>\n",
       "      <td>29.930652</td>\n",
       "      <td>53.022510</td>\n",
       "      <td>37.815074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>EDA \\textbackslash w DLO</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>28.189349</td>\n",
       "      <td>9.534591</td>\n",
       "      <td>19.022119</td>\n",
       "      <td>11.689612</td>\n",
       "      <td>19.621928</td>\n",
       "      <td>10.372881</td>\n",
       "      <td>26.885246</td>\n",
       "      <td>13.067729</td>\n",
       "      <td>25.182830</td>\n",
       "      <td>7.267684</td>\n",
       "      <td>23.780294</td>\n",
       "      <td>10.386499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>QAIE</td>\n",
       "      <td>26.4</td>\n",
       "      <td>45.2</td>\n",
       "      <td>16.244019</td>\n",
       "      <td>8.194622</td>\n",
       "      <td>10.239808</td>\n",
       "      <td>12.836601</td>\n",
       "      <td>14.734848</td>\n",
       "      <td>12.423208</td>\n",
       "      <td>22.563025</td>\n",
       "      <td>15.813953</td>\n",
       "      <td>17.188498</td>\n",
       "      <td>8.188737</td>\n",
       "      <td>16.194040</td>\n",
       "      <td>11.491424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>DS2</td>\n",
       "      <td>21,1k</td>\n",
       "      <td>21,1k</td>\n",
       "      <td>28.481262</td>\n",
       "      <td>17.987421</td>\n",
       "      <td>31.198102</td>\n",
       "      <td>24.697539</td>\n",
       "      <td>26.906112</td>\n",
       "      <td>16.101695</td>\n",
       "      <td>18.510929</td>\n",
       "      <td>7.503320</td>\n",
       "      <td>31.953291</td>\n",
       "      <td>11.404729</td>\n",
       "      <td>27.409939</td>\n",
       "      <td>15.538941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>[k-shot Gemma]</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>57.159763</td>\n",
       "      <td>39.245283</td>\n",
       "      <td>65.774156</td>\n",
       "      <td>48.060075</td>\n",
       "      <td>62.948960</td>\n",
       "      <td>45.254237</td>\n",
       "      <td>39.754098</td>\n",
       "      <td>21.713147</td>\n",
       "      <td>56.915739</td>\n",
       "      <td>37.170596</td>\n",
       "      <td>56.510543</td>\n",
       "      <td>38.288668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>Paraphrase</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>34.60355</td>\n",
       "      <td>26.616352</td>\n",
       "      <td>34.661922</td>\n",
       "      <td>23.254068</td>\n",
       "      <td>31.379962</td>\n",
       "      <td>17.423729</td>\n",
       "      <td>31.434426</td>\n",
       "      <td>18.207171</td>\n",
       "      <td>36.050955</td>\n",
       "      <td>22.586926</td>\n",
       "      <td>33.626163</td>\n",
       "      <td>21.617649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>DLO</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>38.650888</td>\n",
       "      <td>28.603774</td>\n",
       "      <td>43.329453</td>\n",
       "      <td>30.062578</td>\n",
       "      <td>43.894140</td>\n",
       "      <td>29.220339</td>\n",
       "      <td>33.319672</td>\n",
       "      <td>17.888446</td>\n",
       "      <td>41.017488</td>\n",
       "      <td>25.991678</td>\n",
       "      <td>40.042328</td>\n",
       "      <td>26.353363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>LLMA \\textbackslash w Paraphrase</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>52.497041</td>\n",
       "      <td>37.006289</td>\n",
       "      <td>61.115065</td>\n",
       "      <td>46.157697</td>\n",
       "      <td>60.756144</td>\n",
       "      <td>46.305085</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>24.422311</td>\n",
       "      <td>56.401274</td>\n",
       "      <td>40.751043</td>\n",
       "      <td>54.653905</td>\n",
       "      <td>38.928485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>LLMA \\textbackslash w DLO</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>55.147929</td>\n",
       "      <td>40.528302</td>\n",
       "      <td>60.651921</td>\n",
       "      <td>50.062578</td>\n",
       "      <td>62.268431</td>\n",
       "      <td>48.949153</td>\n",
       "      <td>42.459016</td>\n",
       "      <td>24.501992</td>\n",
       "      <td>57.774245</td>\n",
       "      <td>42.108183</td>\n",
       "      <td>55.660308</td>\n",
       "      <td>41.230042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>EDA \\textbackslash w DLO</td>\n",
       "      <td>550</td>\n",
       "      <td>550</td>\n",
       "      <td>42.485207</td>\n",
       "      <td>30.742138</td>\n",
       "      <td>44.656577</td>\n",
       "      <td>34.317897</td>\n",
       "      <td>44.536862</td>\n",
       "      <td>35.389831</td>\n",
       "      <td>36.024590</td>\n",
       "      <td>23.067729</td>\n",
       "      <td>42.448331</td>\n",
       "      <td>31.595007</td>\n",
       "      <td>42.030313</td>\n",
       "      <td>31.022520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>QAIE</td>\n",
       "      <td>141.8</td>\n",
       "      <td>248.8</td>\n",
       "      <td>41.698565</td>\n",
       "      <td>32.778489</td>\n",
       "      <td>42.302158</td>\n",
       "      <td>33.464052</td>\n",
       "      <td>45.568182</td>\n",
       "      <td>31.331058</td>\n",
       "      <td>34.873950</td>\n",
       "      <td>21.441860</td>\n",
       "      <td>44.600639</td>\n",
       "      <td>33.515982</td>\n",
       "      <td>41.808699</td>\n",
       "      <td>30.506288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50</td>\n",
       "      <td>DS2</td>\n",
       "      <td>21,7k</td>\n",
       "      <td>21,6k</td>\n",
       "      <td>37.830375</td>\n",
       "      <td>29.811321</td>\n",
       "      <td>43.851325</td>\n",
       "      <td>36.837714</td>\n",
       "      <td>34.593573</td>\n",
       "      <td>23.785311</td>\n",
       "      <td>29.781421</td>\n",
       "      <td>16.733068</td>\n",
       "      <td>38.322718</td>\n",
       "      <td>23.365786</td>\n",
       "      <td>36.875882</td>\n",
       "      <td>26.106640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>full</td>\n",
       "      <td>Paraphrase</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>-</td>\n",
       "      <td>47.720000</td>\n",
       "      <td>-</td>\n",
       "      <td>59.300000</td>\n",
       "      <td>69.262760</td>\n",
       "      <td>58.169492</td>\n",
       "      <td>51.024590</td>\n",
       "      <td>32.629482</td>\n",
       "      <td>67.006369</td>\n",
       "      <td>55.187761</td>\n",
       "      <td>62.431240</td>\n",
       "      <td>50.601347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>full</td>\n",
       "      <td>DLO</td>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>-</td>\n",
       "      <td>49.330000</td>\n",
       "      <td>-</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>69.300567</td>\n",
       "      <td>60.101695</td>\n",
       "      <td>52.377049</td>\n",
       "      <td>33.067729</td>\n",
       "      <td>68.712242</td>\n",
       "      <td>56.560333</td>\n",
       "      <td>63.463286</td>\n",
       "      <td>52.171951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   \\# Annotated examples                          Approach  \\\n",
       "0                      0                    [0-shot Gemma]   \n",
       "1                      0  LLMA \\textbackslash w Paraphrase   \n",
       "2                      0         LLMA \\textbackslash w DLO   \n",
       "3                     10                    [k-shot Gemma]   \n",
       "4                     10                        Paraphrase   \n",
       "5                     10                               DLO   \n",
       "6                     10  LLMA \\textbackslash w Paraphrase   \n",
       "7                     10         LLMA \\textbackslash w DLO   \n",
       "8                     10          EDA \\textbackslash w DLO   \n",
       "9                     10                              QAIE   \n",
       "10                    10                               DS2   \n",
       "11                    50                    [k-shot Gemma]   \n",
       "12                    50                        Paraphrase   \n",
       "13                    50                               DLO   \n",
       "14                    50  LLMA \\textbackslash w Paraphrase   \n",
       "15                    50         LLMA \\textbackslash w DLO   \n",
       "16                    50          EDA \\textbackslash w DLO   \n",
       "17                    50                              QAIE   \n",
       "18                    50                               DS2   \n",
       "19                  full                        Paraphrase   \n",
       "20                  full                               DLO   \n",
       "\n",
       "   \\# n_train_column_tasd \\# n_train_column_asqp rest15_tasd_recall  \\\n",
       "0                       0                      0          31.360947   \n",
       "1                    full                   full          28.544379   \n",
       "2                    full                   full          27.360947   \n",
       "3                      10                     10          52.662722   \n",
       "4                      10                     10           7.384615   \n",
       "5                      10                     10          13.467456   \n",
       "6                    full                   full          46.982249   \n",
       "7                    full                   full          48.189349   \n",
       "8                     110                    110          28.189349   \n",
       "9                    26.4                   45.2          16.244019   \n",
       "10                  21,1k                  21,1k          28.481262   \n",
       "11                     50                     50          57.159763   \n",
       "12                     50                     50           34.60355   \n",
       "13                     50                     50          38.650888   \n",
       "14                   full                   full          52.497041   \n",
       "15                   full                   full          55.147929   \n",
       "16                    550                    550          42.485207   \n",
       "17                  141.8                  248.8          41.698565   \n",
       "18                  21,7k                  21,6k          37.830375   \n",
       "19                   full                   full                  -   \n",
       "20                   full                   full                  -   \n",
       "\n",
       "    rest15_asqp_recall rest16_tasd_recall  rest16_asqp_recall  \\\n",
       "0            26.289308          46.565774           30.287860   \n",
       "1            20.251572          49.679715           28.535670   \n",
       "2            20.905660          49.266589           29.812265   \n",
       "3            40.503145          65.192084           47.934919   \n",
       "4             1.106918           5.931198            3.229036   \n",
       "5             4.125786          13.946449            4.906133   \n",
       "6            36.427673          61.755635           45.907384   \n",
       "7            38.993711          61.280559           48.811014   \n",
       "8             9.534591          19.022119           11.689612   \n",
       "9             8.194622          10.239808           12.836601   \n",
       "10           17.987421          31.198102           24.697539   \n",
       "11           39.245283          65.774156           48.060075   \n",
       "12           26.616352          34.661922           23.254068   \n",
       "13           28.603774          43.329453           30.062578   \n",
       "14           37.006289          61.115065           46.157697   \n",
       "15           40.528302          60.651921           50.062578   \n",
       "16           30.742138          44.656577           34.317897   \n",
       "17           32.778489          42.302158           33.464052   \n",
       "18           29.811321          43.851325           36.837714   \n",
       "19           47.720000                  -           59.300000   \n",
       "20           49.330000                  -           61.800000   \n",
       "\n",
       "    flightabsa_tasd_recall  flightabsa_asqp_recall  coursera_tasd_recall  \\\n",
       "0                56.899811               45.423729             32.581967   \n",
       "1                55.689981               46.305085             34.057377   \n",
       "2                56.975425               47.389831             34.467213   \n",
       "3                60.869565               45.084746             40.368852   \n",
       "4                 7.637051                2.847458             14.508197   \n",
       "5                13.913043                4.033898             20.860656   \n",
       "6                58.676749               45.932203             38.647541   \n",
       "7                61.512287               47.355932             39.631148   \n",
       "8                19.621928               10.372881             26.885246   \n",
       "9                14.734848               12.423208             22.563025   \n",
       "10               26.906112               16.101695             18.510929   \n",
       "11               62.948960               45.254237             39.754098   \n",
       "12               31.379962               17.423729             31.434426   \n",
       "13               43.894140               29.220339             33.319672   \n",
       "14               60.756144               46.305085             42.500000   \n",
       "15               62.268431               48.949153             42.459016   \n",
       "16               44.536862               35.389831             36.024590   \n",
       "17               45.568182               31.331058             34.873950   \n",
       "18               34.593573               23.785311             29.781421   \n",
       "19               69.262760               58.169492             51.024590   \n",
       "20               69.300567               60.101695             52.377049   \n",
       "\n",
       "    coursera_asqp_recall  hotels_tasd_recall  hotels_asqp_recall   tasd_avg  \\\n",
       "0              15.139442           41.017488           23.162275  41.685197   \n",
       "1              15.737052           43.216561           27.176634  42.237603   \n",
       "2              16.015936           43.847377           26.213592  42.383510   \n",
       "3              21.314741           55.166932           28.294036  54.852031   \n",
       "4               4.262948           12.388535            2.058414   9.569919   \n",
       "5               4.023904           17.392687            3.411928  15.916058   \n",
       "6              22.988048           53.821656           31.070932  51.976766   \n",
       "7              23.984064           54.499205           29.930652  53.022510   \n",
       "8              13.067729           25.182830            7.267684  23.780294   \n",
       "9              15.813953           17.188498            8.188737  16.194040   \n",
       "10              7.503320           31.953291           11.404729  27.409939   \n",
       "11             21.713147           56.915739           37.170596  56.510543   \n",
       "12             18.207171           36.050955           22.586926  33.626163   \n",
       "13             17.888446           41.017488           25.991678  40.042328   \n",
       "14             24.422311           56.401274           40.751043  54.653905   \n",
       "15             24.501992           57.774245           42.108183  55.660308   \n",
       "16             23.067729           42.448331           31.595007  42.030313   \n",
       "17             21.441860           44.600639           33.515982  41.808699   \n",
       "18             16.733068           38.322718           23.365786  36.875882   \n",
       "19             32.629482           67.006369           55.187761  62.431240   \n",
       "20             33.067729           68.712242           56.560333  63.463286   \n",
       "\n",
       "     asqp_avg  \n",
       "0   28.060523  \n",
       "1   27.601203  \n",
       "2   28.067457  \n",
       "3   36.626317  \n",
       "4    2.700955  \n",
       "5    4.100330  \n",
       "6   36.465248  \n",
       "7   37.815074  \n",
       "8   10.386499  \n",
       "9   11.491424  \n",
       "10  15.538941  \n",
       "11  38.288668  \n",
       "12  21.617649  \n",
       "13  26.353363  \n",
       "14  38.928485  \n",
       "15  41.230042  \n",
       "16  31.022520  \n",
       "17  30.506288  \n",
       "18  26.106640  \n",
       "19  50.601347  \n",
       "20  52.171951  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_out_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3e4ced42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA TABLE\n",
    "with open(\"01_muster_tex/ablation_eda.txt\", \"r\") as f:\n",
    "    template = f.read()\n",
    "\n",
    "for metric in [\"f1\"]:\n",
    "    table_out, table_out_raw = create_f1_plot(tasks=[\"tasd\", \"asqp\"], metrics=[metric])\n",
    "    table_out = table_out[table_out[\"Approach\"].str.contains(\"EDA\", na=False)].copy()\n",
    "    table_out_raw = table_out_raw[table_out_raw[\"Approach\"].str.contains(\"EDA\", na=False)].copy()\n",
    "    \n",
    "    table_out = highlight(table_out, start_column=4, end_column=15, groups=[[k for k in range(0, 8)], [k for k in range(9, 16)]], type=\"bold\")\n",
    "    \n",
    "    table_out_list = table_out.iloc[:, 2:].astype(str).values.tolist()\n",
    "    table_out_list = [item for sublist in table_out_list for item in sublist]\n",
    "\n",
    "    table_with_values = template\n",
    "    for i in range(len(table_out_list)):\n",
    "        table_with_values = table_with_values.replace(\"xxxx\", table_out_list[i], 1)\n",
    "    \n",
    "    # Write the final table to a file\n",
    "    with open(f\"_out_table/{metric}_table_eda_ablation.txt\", \"w\") as f_out:\n",
    "        f_out.write(table_with_values)\n",
    "        \n",
    "    # store df table_out_raw as csv\n",
    "    table_out_raw.to_csv(f\"_out_table/{metric}_table_raw_eda_ablation.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_tuner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
