{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99b6dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../zero-shot-absa-quad\"))\n",
    "sys.path.append(os.path.abspath(\"../../zero-shot-absa-quad/plots\"))\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbbdeea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../zero-shot-asba-quad/plots'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('../../zero-shot-asba-quad/plots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d73125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_zeroshot.ipynb\t\t\t    multilingual_fs.json\n",
      "02_classwise.ipynb\t\t\t    past_results.json\n",
      "03_regeneration_statistic.ipynb\t\t    performance_helper.py\n",
      "04_significance_tester.ipynb\t\t    plot.pdf\n",
      "05_time_analysis.ipynb\t\t\t    plot_progress.pdf\n",
      "corpus_statistics.ipynb\t\t\t    __pycache__\n",
      "get_performance_language_adaption_fs.ipynb  table_boldener.py\n",
      "line_plots.ipynb\t\t\t    table_helper.py\n",
      "manrope_regular.ttf\n"
     ]
    }
   ],
   "source": [
    "!ls ../../zero-shot-absa-quad/plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dd97a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "from performance_helper import get_performance_scores, get_finetuned_scores, compute_f1_scores_quad, compute_scores_single, merge_aspect_lists\n",
    "from table_helper import create_tabular\n",
    "from table_boldener import bolden_table_max_values_with_hline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import itertools\n",
    "# import shutil\n",
    "# import io, re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bb6d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SEEDS = 5\n",
    "TASKS = [\"tasd\", \"asqp\"]\n",
    "DATASETS = [\"rest15\", \"rest16\", \"flightabsa\", \"coursera\", \"hotels\"]\n",
    "METHODS = [\"paraphrase\", \"dlo\"]\n",
    "AUG_TECHNIQUES = [\"eda\", \"qaie\"]\n",
    "\n",
    "raw_dataset_to_formatted = {\"rest16\": \"Rest16\", \"rest15\": \"Rest15\", \"flightabsa\": \"FlightABSA\", \"gerest\": \"GERest\", \"hotels\": \"OATS Hotels\"}\n",
    "format_dataset_to_raw = {\"Rest16\": \"rest16\", \"Rest15\": \"rest15\", \"FlightABSA\": \"flightabsa\", \"GERest\": \"gerest\", \"OATS Hotels\": \"hotels\"}\n",
    "raw_method_to_formatted = {\"paraphrase\": \"Paraphrase \\citep{zhang2021aspect}\", \"dlo\": \"DLO \\citep{hu2022improving}\", \"mvp\": \"MVP \\citep{gou2023mvp}\"}\n",
    "format_method_to_raw = {\"Paraphrase \\citep{zhang2021aspect}\": \"paraphrase\", \"DLO \\citep{hu2022improving}\": \"dlo\", \"MVP \\citep{gou2023mvp}\": \"mvp\"}\n",
    "raw_aug_to_formatted = {\"eda\": \"EDA\", \"QAIE\": \"QAIE\", \"llm_annotator\": \"LLM-Annotator\"}\n",
    "format_aug_to_raw = {\"EDA\": \"eda\", \"-\": \"-\", \"LLM-Annotator\": \"llm_annotator\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e504f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_element_scores(loaded_json, task):\n",
    "    labels = loaded_json[\"all_labels\"]\n",
    "    preds = loaded_json[\"all_preds\"]\n",
    "    seed_scores = compute_f1_scores_quad(preds, labels)\n",
    "    seed_scores_ac = compute_scores_single(preds, labels, \"single_ac\")\n",
    "    seed_scores_at = compute_scores_single(preds, labels, \"single_at\")\n",
    "    seed_scores_pol = compute_scores_single(preds, labels, \"single_pol\")\n",
    "\n",
    "    seed_scores[\"ac\"] = seed_scores_ac\n",
    "    seed_scores[\"at\"] = seed_scores_at\n",
    "    seed_scores[\"pol\"] = seed_scores_pol\n",
    "    if task == \"asqp\":\n",
    "        seed_scores_ot = compute_scores_single(preds, labels, \"single_ot\")\n",
    "        seed_scores[\"ot\"] = seed_scores_ot\n",
    "    return seed_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e108dd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean(scores):\n",
    "    averages = {}\n",
    "    for key in scores[0].keys():\n",
    "        if isinstance(scores[0][key], dict):  # Falls geschachtelte Dicts vorhanden sind\n",
    "            averages[key] = {subkey: np.mean([s[key][subkey] for s in scores]) for subkey in scores[0][key]}\n",
    "        else:\n",
    "            averages[key] = np.mean([s[key] for s in scores])\n",
    "    return averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d542179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load LLM-annotated fine-tuned scores\n",
    "scores_llm_ann_train = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for fs in [0, 10, 50]:\n",
    "                for n_ann_ex in [800, \"full\"]:\n",
    "\n",
    "                    scores = []\n",
    "                    for seed in range(N_SEEDS):\n",
    "                        with open(\n",
    "                            f\"../_out_fine_tunings/01_llm_annotate_train/{method}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                        ) as f:\n",
    "                            loaded_json = json.load(f)\n",
    "                            seed_scores = add_element_scores(loaded_json, task)\n",
    "                            scores.append(seed_scores)\n",
    "                    scores_llm_ann_train[\n",
    "                        f\"{method}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                    ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d08fc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['paraphrase_800_tasd_0_rest15', 'paraphrase_full_tasd_0_rest15', 'paraphrase_800_tasd_10_rest15', 'paraphrase_full_tasd_10_rest15', 'paraphrase_800_tasd_50_rest15', 'paraphrase_full_tasd_50_rest15', 'dlo_800_tasd_0_rest15', 'dlo_full_tasd_0_rest15', 'dlo_800_tasd_10_rest15', 'dlo_full_tasd_10_rest15', 'dlo_800_tasd_50_rest15', 'dlo_full_tasd_50_rest15', 'paraphrase_800_asqp_0_rest15', 'paraphrase_full_asqp_0_rest15', 'paraphrase_800_asqp_10_rest15', 'paraphrase_full_asqp_10_rest15', 'paraphrase_800_asqp_50_rest15', 'paraphrase_full_asqp_50_rest15', 'dlo_800_asqp_0_rest15', 'dlo_full_asqp_0_rest15', 'dlo_800_asqp_10_rest15', 'dlo_full_asqp_10_rest15', 'dlo_800_asqp_50_rest15', 'dlo_full_asqp_50_rest15', 'paraphrase_800_tasd_0_rest16', 'paraphrase_full_tasd_0_rest16', 'paraphrase_800_tasd_10_rest16', 'paraphrase_full_tasd_10_rest16', 'paraphrase_800_tasd_50_rest16', 'paraphrase_full_tasd_50_rest16', 'dlo_800_tasd_0_rest16', 'dlo_full_tasd_0_rest16', 'dlo_800_tasd_10_rest16', 'dlo_full_tasd_10_rest16', 'dlo_800_tasd_50_rest16', 'dlo_full_tasd_50_rest16', 'paraphrase_800_asqp_0_rest16', 'paraphrase_full_asqp_0_rest16', 'paraphrase_800_asqp_10_rest16', 'paraphrase_full_asqp_10_rest16', 'paraphrase_800_asqp_50_rest16', 'paraphrase_full_asqp_50_rest16', 'dlo_800_asqp_0_rest16', 'dlo_full_asqp_0_rest16', 'dlo_800_asqp_10_rest16', 'dlo_full_asqp_10_rest16', 'dlo_800_asqp_50_rest16', 'dlo_full_asqp_50_rest16', 'paraphrase_800_tasd_0_flightabsa', 'paraphrase_full_tasd_0_flightabsa', 'paraphrase_800_tasd_10_flightabsa', 'paraphrase_full_tasd_10_flightabsa', 'paraphrase_800_tasd_50_flightabsa', 'paraphrase_full_tasd_50_flightabsa', 'dlo_800_tasd_0_flightabsa', 'dlo_full_tasd_0_flightabsa', 'dlo_800_tasd_10_flightabsa', 'dlo_full_tasd_10_flightabsa', 'dlo_800_tasd_50_flightabsa', 'dlo_full_tasd_50_flightabsa', 'paraphrase_800_asqp_0_flightabsa', 'paraphrase_full_asqp_0_flightabsa', 'paraphrase_800_asqp_10_flightabsa', 'paraphrase_full_asqp_10_flightabsa', 'paraphrase_800_asqp_50_flightabsa', 'paraphrase_full_asqp_50_flightabsa', 'dlo_800_asqp_0_flightabsa', 'dlo_full_asqp_0_flightabsa', 'dlo_800_asqp_10_flightabsa', 'dlo_full_asqp_10_flightabsa', 'dlo_800_asqp_50_flightabsa', 'dlo_full_asqp_50_flightabsa', 'paraphrase_800_tasd_0_coursera', 'paraphrase_full_tasd_0_coursera', 'paraphrase_800_tasd_10_coursera', 'paraphrase_full_tasd_10_coursera', 'paraphrase_800_tasd_50_coursera', 'paraphrase_full_tasd_50_coursera', 'dlo_800_tasd_0_coursera', 'dlo_full_tasd_0_coursera', 'dlo_800_tasd_10_coursera', 'dlo_full_tasd_10_coursera', 'dlo_800_tasd_50_coursera', 'dlo_full_tasd_50_coursera', 'paraphrase_800_asqp_0_coursera', 'paraphrase_full_asqp_0_coursera', 'paraphrase_800_asqp_10_coursera', 'paraphrase_full_asqp_10_coursera', 'paraphrase_800_asqp_50_coursera', 'paraphrase_full_asqp_50_coursera', 'dlo_800_asqp_0_coursera', 'dlo_full_asqp_0_coursera', 'dlo_800_asqp_10_coursera', 'dlo_full_asqp_10_coursera', 'dlo_800_asqp_50_coursera', 'dlo_full_asqp_50_coursera', 'paraphrase_800_tasd_0_hotels', 'paraphrase_full_tasd_0_hotels', 'paraphrase_800_tasd_10_hotels', 'paraphrase_full_tasd_10_hotels', 'paraphrase_800_tasd_50_hotels', 'paraphrase_full_tasd_50_hotels', 'dlo_800_tasd_0_hotels', 'dlo_full_tasd_0_hotels', 'dlo_800_tasd_10_hotels', 'dlo_full_tasd_10_hotels', 'dlo_800_tasd_50_hotels', 'dlo_full_tasd_50_hotels', 'paraphrase_800_asqp_0_hotels', 'paraphrase_full_asqp_0_hotels', 'paraphrase_800_asqp_10_hotels', 'paraphrase_full_asqp_10_hotels', 'paraphrase_800_asqp_50_hotels', 'paraphrase_full_asqp_50_hotels', 'dlo_800_asqp_0_hotels', 'dlo_full_asqp_0_hotels', 'dlo_800_asqp_10_hotels', 'dlo_full_asqp_10_hotels', 'dlo_800_asqp_50_hotels', 'dlo_full_asqp_50_hotels'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_llm_ann_train.keys(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3b699c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Augmented fine-tuned scores\n",
    "scores_traditional_aug = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [10, 50]:\n",
    "            for n_ann_ex in [2, 5, 10]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    path = f\"../../QAIE-ABSA-2025-adaption/03_results/{task}_{dataset}_fs_{fs}_{seed}.json\"\n",
    "\n",
    "                    with open(path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_traditional_aug[\n",
    "                    f\"qaie_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2130bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for aug in [\"eda\"]:\n",
    "            for method in METHODS:\n",
    "                for fs in [10, 50]:\n",
    "                    for n_ann_ex in [2, 5, 10]:\n",
    "                        scores = []\n",
    "                        for seed in range(N_SEEDS):\n",
    "                            path = f\"../_out_fine_tunings/03_traditional_augmentation/{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}_{seed}.json\"\n",
    "                            with open(\n",
    "                                path\n",
    "                            ) as f:\n",
    "                                loaded_json = json.load(f)\n",
    "                                seed_scores = add_element_scores(loaded_json, task)\n",
    "                                scores.append(seed_scores)\n",
    "                        scores_traditional_aug[\n",
    "                            f\"{method}_{aug}_{n_ann_ex}_{task}_{fs}_{dataset}\"\n",
    "                        ] = calc_mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "70bdcef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load methods baselines\n",
    "scores_00_baseline = {}\n",
    "\n",
    "with open(\"../../zero-shot-absa-quad/plots/past_results.json\") as f:\n",
    "    past_results = json.load(f)\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for method in METHODS:\n",
    "            for n_ann_ex in [10, 50, 800, \"full\"]:\n",
    "\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    if n_ann_ex == \"full\":\n",
    "                        file_path = f\"../../zero-shot-absa-quad/generations/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}.json\"\n",
    "                    else:\n",
    "                        file_path = f\"../../zero-shot-absa-quad/generations/00_baselines/training_{task}_{dataset}_seed-{seed}_n-train_{method}_{n_ann_ex}.json\"\n",
    "                    with open(file_path) as f:\n",
    "                        loaded_json = json.load(f)\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "                        scores.append(seed_scores)\n",
    "                scores_mean = calc_mean(scores)\n",
    "\n",
    "                scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"] = (\n",
    "                    scores_mean\n",
    "                )\n",
    "\n",
    "                for metric in [\"f1\", \"precision\", \"recall\"]:\n",
    "                    if n_ann_ex == \"full\":\n",
    "                        try:\n",
    "                            scores_00_baseline[f\"{method}_{n_ann_ex}_{task}_{dataset}\"][\n",
    "                                metric\n",
    "                            ] = past_results[task][method][dataset][metric]\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c12908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Nachtr√§glicher Filter zero/few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "acaf7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load zero-shot scores\n",
    "scores_zeroshot = {}\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 20, 30, 40, 50]:\n",
    "                scores = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../../zero-shot-absa-quad/generations/zeroshot/{task}_{dataset}_test_gemma3:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        seed_scores = add_element_scores(loaded_json, task)\n",
    "\n",
    "                        scores.append(seed_scores)\n",
    "                scores_zeroshot[f\"{task}_{fs}_{dataset}\"] = calc_mean(scores)\n",
    "\n",
    "# WITH SELF-Consistency\n",
    "for dataset in DATASETS:\n",
    "    for task in TASKS:\n",
    "        for fs in [0, 10, 20, 30, 40, 50]:\n",
    "                all_example_data = []\n",
    "                for seed in range(N_SEEDS):\n",
    "                    with open(\n",
    "                        f\"../../zero-shot-absa-quad/generations/zeroshot/{task}_{dataset}_test_gemma3:27b_{seed}_label_{fs}.json\"\n",
    "                    ) as f:\n",
    "                        loaded_json_raw = json.load(f)\n",
    "\n",
    "                        loaded_json = {\n",
    "                            \"all_preds\": [j[\"pred_label\"] for j in loaded_json_raw],\n",
    "                            \"all_labels\": [j[\"tuple_list\"] for j in loaded_json_raw],\n",
    "                        }\n",
    "\n",
    "                        all_example_data.append(loaded_json)\n",
    "\n",
    "                all_labels = all_example_data[0][\"all_labels\"]\n",
    "                all_preds = [[] for _ in range(len(all_labels))]\n",
    "                for seed in range(0, N_SEEDS):\n",
    "                    for idx in range(len(all_labels)):\n",
    "                        all_preds[idx].append(all_example_data[seed][\"all_preds\"][idx])\n",
    "                        if seed == N_SEEDS - 1:\n",
    "                            all_preds[idx] = merge_aspect_lists(all_preds[idx])\n",
    "                            all_preds[idx] = [list(p) for p in all_preds[idx]]\n",
    "\n",
    "                loaded_json = {\n",
    "                    \"all_preds\": all_preds,\n",
    "                    \"all_labels\": all_labels,\n",
    "                }\n",
    "\n",
    "                scores = add_element_scores(loaded_json, task)\n",
    "                scores_zeroshot[f\"{task}_{fs}_{dataset}_sc\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4baa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nils_hellwig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
